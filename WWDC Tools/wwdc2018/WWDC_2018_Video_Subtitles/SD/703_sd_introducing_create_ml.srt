1
00:00:06,516 --> 00:00:14,500
[ Music ]


2
00:00:20,516 --> 00:00:29,046
[ Applause ]


3
00:00:29,546 --> 00:00:31,956
>> Hello. Welcome everyone.


4
00:00:32,436 --> 00:00:33,796
My name is Gaurav.


5
00:00:33,796 --> 00:00:34,936
And today we are going to talk


6
00:00:34,936 --> 00:00:36,436
about machine learning.


7
00:00:37,096 --> 00:00:40,146
Last year, we launched Core ML.


8
00:00:40,146 --> 00:00:41,986
And the response from


9
00:00:41,986 --> 00:00:44,906
developers, from you guys have


10
00:00:44,906 --> 00:00:45,766
been tremendous.


11
00:00:46,566 --> 00:00:48,456
We are just amazed by the apps


12
00:00:48,606 --> 00:00:50,436
you have made, the [inaudible]


13
00:00:50,436 --> 00:00:51,126
phenomenal.


14
00:00:52,196 --> 00:00:53,596
So let me first begin by saying


15
00:00:53,596 --> 00:00:54,086
thank you.


16
00:00:54,676 --> 00:00:56,186
Thank you for embracing Core ML.


17
00:00:56,666 --> 00:00:58,376
And we are -- we love seeing so


18
00:00:58,376 --> 00:01:01,396
many of you using it and giving


19
00:01:01,396 --> 00:01:03,306
intelligent features to our


20
00:01:03,306 --> 00:01:03,596
users.


21
00:01:04,406 --> 00:01:05,556
We are in this together.


22
00:01:05,876 --> 00:01:06,226
Thank you.


23
00:01:07,041 --> 00:01:09,041
[ Applause ]


24
00:01:09,066 --> 00:01:11,556
It's an applause for the


25
00:01:11,556 --> 00:01:12,376
devlopers.


26
00:01:13,236 --> 00:01:16,506
Okay. So if you recall, Core ML


27
00:01:16,506 --> 00:01:18,026
gives you an easy way to


28
00:01:18,026 --> 00:01:19,526
integrate an ML model in the


29
00:01:19,526 --> 00:01:19,856
app.


30
00:01:21,336 --> 00:01:22,586
The idea is very simple.


31
00:01:23,006 --> 00:01:25,066
You get an ML model, you drag


32
00:01:25,066 --> 00:01:27,746
and drop in Xcode, and with just


33
00:01:27,816 --> 00:01:29,806
three lines of code, you can run


34
00:01:30,366 --> 00:01:32,776
state-of-the-art ML model with


35
00:01:32,776 --> 00:01:34,206
millions of parameters and


36
00:01:34,206 --> 00:01:36,376
billions of calculations in real


37
00:01:36,436 --> 00:01:36,716
time.


38
00:01:36,916 --> 00:01:37,736
It's just amazing.


39
00:01:39,076 --> 00:01:40,856
And you give -- your users get


40
00:01:40,916 --> 00:01:42,606
real time machine learning as


41
00:01:42,606 --> 00:01:44,576
well as privacy-friendly machine


42
00:01:44,576 --> 00:01:44,806
learning.


43
00:01:46,066 --> 00:01:47,466
All you have to do is to drag


44
00:01:47,466 --> 00:01:49,766
and drop an ML model in Xcode


45
00:01:50,126 --> 00:01:51,546
and Core ML takes care of the


46
00:01:51,546 --> 00:01:51,756
rest.


47
00:01:51,856 --> 00:01:55,986
I think the big question remains


48
00:01:55,986 --> 00:01:57,776
is where do I get these models


49
00:01:58,626 --> 00:01:58,746
from?


50
00:01:59,936 --> 00:02:01,726
So last year, we provided you


51
00:02:01,726 --> 00:02:02,486
two options.


52
00:02:03,116 --> 00:02:05,086
The first one was you could


53
00:02:05,086 --> 00:02:06,896
download some of these models,


54
00:02:06,896 --> 00:02:09,416
popular models from our website


55
00:02:10,166 --> 00:02:13,146
but, more importantly, we also


56
00:02:13,146 --> 00:02:15,326
released Core ML tools.


57
00:02:15,896 --> 00:02:18,086
Core ML tools allow you to tap


58
00:02:18,316 --> 00:02:19,486
the work which is done by


59
00:02:19,576 --> 00:02:22,496
amazing ML community.


60
00:02:23,776 --> 00:02:25,986
So the idea is, again, simple.


61
00:02:26,446 --> 00:02:27,316
You choose your favorite


62
00:02:27,316 --> 00:02:29,226
learning library, train your


63
00:02:29,226 --> 00:02:31,326
model in that training library,


64
00:02:31,526 --> 00:02:33,426
convert it into Core ML from


65
00:02:33,426 --> 00:02:35,776
that and then just integrate it


66
00:02:35,776 --> 00:02:36,426
into your app.


67
00:02:36,426 --> 00:02:40,256
When we released Core ML, we


68
00:02:40,256 --> 00:02:42,346
released with only five or six


69
00:02:42,406 --> 00:02:43,656
training libraries support for


70
00:02:43,656 --> 00:02:47,726
five or six training library but


71
00:02:47,726 --> 00:02:48,996
within a year, we have support


72
00:02:48,996 --> 00:02:52,026
for all the famous training


73
00:02:52,026 --> 00:02:52,976
libraries out there.


74
00:02:53,966 --> 00:02:55,586
We are enhancing our tools to


75
00:02:55,586 --> 00:02:56,756
even allow you more


76
00:02:56,756 --> 00:02:57,826
customization.


77
00:02:58,266 --> 00:02:59,436
And we are going to talk about


78
00:02:59,436 --> 00:03:01,846
more about Core ML tools in


79
00:03:01,846 --> 00:03:02,786
tomorrow's session.


80
00:03:03,246 --> 00:03:07,586
Another thing we did towards the


81
00:03:07,586 --> 00:03:08,946
end of the year, we released


82
00:03:08,946 --> 00:03:10,686
Turi Create, our open source


83
00:03:10,686 --> 00:03:11,816
machine learning library.


84
00:03:11,926 --> 00:03:13,706
We are going to talk about Turi


85
00:03:13,706 --> 00:03:15,556
Create in tomorrow's session.


86
00:03:16,086 --> 00:03:18,666
But this year, we want to give


87
00:03:18,666 --> 00:03:19,636
you something even more.


88
00:03:20,046 --> 00:03:22,186
We want to continue our journey.


89
00:03:22,876 --> 00:03:24,226
We want to give you something


90
00:03:24,226 --> 00:03:27,126
native, something Swifty,


91
00:03:28,056 --> 00:03:29,276
something that harnesses the


92
00:03:29,276 --> 00:03:32,216
power of our Xcode, something


93
00:03:32,216 --> 00:03:33,726
that puts the focus on you, our


94
00:03:33,726 --> 00:03:35,916
developers, something that just


95
00:03:35,916 --> 00:03:37,396
demystify machine learning for


96
00:03:37,396 --> 00:03:37,566
you.


97
00:03:38,306 --> 00:03:40,736
Hence, we are introducing Create


98
00:03:40,736 --> 00:03:40,956
ML --


99
00:03:41,516 --> 00:03:47,636
[ Applause ]


100
00:03:48,136 --> 00:03:50,026
Our machine learning framework


101
00:03:50,716 --> 00:03:52,016
in Swift.


102
00:03:52,226 --> 00:03:55,096
So Create ML completes the


103
00:03:55,096 --> 00:03:56,616
left-hand side of the equation.


104
00:03:57,616 --> 00:03:59,836
The idea is you make a model in


105
00:03:59,836 --> 00:04:01,946
Create ML and you run it in Core


106
00:04:01,996 --> 00:04:02,216
ML.


107
00:04:02,796 --> 00:04:04,496
You do complete end-to-end


108
00:04:04,496 --> 00:04:06,956
machine learning in Swift, our


109
00:04:06,956 --> 00:04:07,776
favorite language.


110
00:04:08,346 --> 00:04:09,366
So you are not dealing with


111
00:04:09,366 --> 00:04:10,606
language oddities where you are


112
00:04:10,606 --> 00:04:12,166
training in one language and


113
00:04:12,166 --> 00:04:13,386
then running in, for instance,


114
00:04:13,386 --> 00:04:14,446
another language.


115
00:04:16,296 --> 00:04:19,736
Create ML is simple and very


116
00:04:19,736 --> 00:04:20,565
powerful.


117
00:04:20,565 --> 00:04:21,966
It is tailored to your app.


118
00:04:22,546 --> 00:04:23,996
It leverages core Apple


119
00:04:23,996 --> 00:04:27,146
technologies, and you do


120
00:04:27,146 --> 00:04:29,566
everything on your Mac.


121
00:04:31,156 --> 00:04:32,876
So for this year we are going to


122
00:04:32,876 --> 00:04:34,336
focus on three very important


123
00:04:34,336 --> 00:04:35,036
use cases.


124
00:04:35,416 --> 00:04:38,696
The first one is images, second


125
00:04:38,696 --> 00:04:40,946
is text, and the third one is


126
00:04:41,096 --> 00:04:41,646
tabular data.


127
00:04:42,886 --> 00:04:45,226
These are the top use cases that


128
00:04:45,226 --> 00:04:47,346
we believe will benefit you.


129
00:04:47,606 --> 00:04:50,946
So you can do things like custom


130
00:04:50,946 --> 00:04:52,206
image classifier.


131
00:04:52,676 --> 00:04:54,426
Idea is that you make your own


132
00:04:54,426 --> 00:04:55,696
image classifier that can


133
00:04:55,696 --> 00:04:57,606
recognize product from your


134
00:04:57,636 --> 00:04:58,316
product catalog.


135
00:04:59,536 --> 00:05:00,846
You can do things like text


136
00:05:00,986 --> 00:05:02,586
classifier so you can make your


137
00:05:02,586 --> 00:05:04,266
own sentiment analysis, topic


138
00:05:04,266 --> 00:05:05,766
analysis, domain analysis.


139
00:05:06,456 --> 00:05:09,616
And you can also do classical


140
00:05:09,656 --> 00:05:12,636
regression and classification on


141
00:05:12,636 --> 00:05:13,246
tabular data.


142
00:05:13,626 --> 00:05:15,316
For example, let's just say you


143
00:05:15,316 --> 00:05:16,726
want to predict the wine quality


144
00:05:16,726 --> 00:05:18,916
using its chemical composition.


145
00:05:19,746 --> 00:05:21,066
The possibilities are endless,


146
00:05:21,066 --> 00:05:23,286
and we are going to discuss them


147
00:05:23,286 --> 00:05:24,966
in detail in the next 30


148
00:05:24,966 --> 00:05:25,216
minutes.


149
00:05:27,976 --> 00:05:30,216
However, before we do, let's


150
00:05:30,216 --> 00:05:31,656
take a look at common workflow.


151
00:05:31,656 --> 00:05:35,246
First, let's just say you are


152
00:05:35,576 --> 00:05:37,526
trying to enable an experience


153
00:05:37,526 --> 00:05:39,726
in your app, make sure that


154
00:05:39,726 --> 00:05:40,826
machine learning is the right


155
00:05:40,876 --> 00:05:41,606
thing to do there.


156
00:05:41,866 --> 00:05:42,986
So don't just blindly apply


157
00:05:42,986 --> 00:05:43,676
machine learning.


158
00:05:44,056 --> 00:05:45,156
Make sure machine learning is


159
00:05:45,156 --> 00:05:46,496
the right thing to do there and


160
00:05:46,496 --> 00:05:47,996
define a machine learning


161
00:05:49,696 --> 00:05:49,926
problem.


162
00:05:50,076 --> 00:05:52,006
Second, collect data.


163
00:05:53,326 --> 00:05:55,446
Make sure this data reflects the


164
00:05:55,446 --> 00:05:57,766
real usage of your app.


165
00:05:58,566 --> 00:05:59,686
So, for example, if you're


166
00:05:59,686 --> 00:06:01,916
making a custom image classifier


167
00:06:02,546 --> 00:06:04,066
that is going to be used by


168
00:06:04,066 --> 00:06:06,486
users on their iPhone, so


169
00:06:06,486 --> 00:06:07,946
collect pictures from your


170
00:06:07,946 --> 00:06:08,236
iPhone.


171
00:06:08,676 --> 00:06:10,246
Do not collect -- collect less


172
00:06:10,366 --> 00:06:12,566
screenshots but have more iPhone


173
00:06:13,106 --> 00:06:13,326
pictures.


174
00:06:14,536 --> 00:06:17,606
Then you train your model.


175
00:06:18,396 --> 00:06:21,276
Finally, an important step here


176
00:06:21,276 --> 00:06:22,756
is to evaluate this model.


177
00:06:23,366 --> 00:06:25,686
The model evaluation is done on


178
00:06:25,686 --> 00:06:27,996
a separate handout set.


179
00:06:29,286 --> 00:06:31,556
If you're happy, you write out


180
00:06:31,606 --> 00:06:32,376
the ML model.


181
00:06:33,726 --> 00:06:35,416
But let's just say the results


182
00:06:35,416 --> 00:06:36,216
are not good.


183
00:06:36,216 --> 00:06:37,246
You should either retrain your


184
00:06:37,246 --> 00:06:39,416
model with different parameters


185
00:06:39,686 --> 00:06:41,676
or you collect more data.


186
00:06:43,456 --> 00:06:45,356
Create ML actually helps you


187
00:06:45,356 --> 00:06:47,736
across all four stages of this


188
00:06:47,736 --> 00:06:48,176
workflow.


189
00:06:48,796 --> 00:06:52,886
We have powerful in-built data


190
00:06:52,886 --> 00:06:53,846
[inaudible] utilities, data


191
00:06:53,946 --> 00:06:55,816
source and data table that we


192
00:06:55,816 --> 00:06:57,196
will talk in the remainder of


193
00:06:57,196 --> 00:06:58,036
the presentation.


194
00:06:58,466 --> 00:07:01,546
You can actually train your


195
00:07:01,546 --> 00:07:02,776
model using only one line of


196
00:07:02,866 --> 00:07:03,196
code.


197
00:07:04,416 --> 00:07:06,196
And the training is done


198
00:07:06,196 --> 00:07:07,386
hardware optimized.


199
00:07:08,096 --> 00:07:11,796
There are built-in evaluation


200
00:07:11,796 --> 00:07:12,976
metrics, so you don't have to


201
00:07:12,976 --> 00:07:14,236
write your own precision and


202
00:07:14,236 --> 00:07:15,576
recall and confusion metrics


203
00:07:15,576 --> 00:07:16,316
calculation.


204
00:07:16,646 --> 00:07:19,926
Use them. And finally, when


205
00:07:19,926 --> 00:07:22,376
you're happy, just write out the


206
00:07:22,376 --> 00:07:22,716
model.


207
00:07:23,366 --> 00:07:25,936
Now we will take a deeper look


208
00:07:25,936 --> 00:07:28,506
in all three use cases: images,


209
00:07:29,006 --> 00:07:32,646
text, and tabular data.


210
00:07:32,986 --> 00:07:34,466
So let's start with images.


211
00:07:34,466 --> 00:07:36,056
And to do that, I will invite


212
00:07:36,056 --> 00:07:38,036
Lizi Ottens, Senior Engineer in


213
00:07:38,036 --> 00:07:38,766
Machine Learning team.


214
00:07:38,926 --> 00:07:39,266
Thank you.


215
00:07:40,516 --> 00:07:44,996
[ Applause ]


216
00:07:45,496 --> 00:07:49,516
>> Thank you, Gaurav.


217
00:07:50,106 --> 00:07:51,716
Since enabling image-based


218
00:07:51,716 --> 00:07:53,866
experiences are some of the most


219
00:07:53,866 --> 00:07:55,906
powerful and interactive ones


220
00:07:55,906 --> 00:07:56,806
that you can add to your apps,


221
00:07:57,526 --> 00:07:59,346
today we'll take a look at how


222
00:07:59,346 --> 00:08:00,886
to train custom image


223
00:08:00,886 --> 00:08:02,156
classification models.


224
00:08:03,316 --> 00:08:04,686
Image classification is the


225
00:08:04,686 --> 00:08:06,626
problem of identifying what


226
00:08:06,626 --> 00:08:08,546
label out of a set of categories


227
00:08:08,546 --> 00:08:10,336
you'd like to apply to an image.


228
00:08:11,646 --> 00:08:12,486
Depending on the type of


229
00:08:12,486 --> 00:08:14,216
training data, you can target


230
00:08:14,216 --> 00:08:16,676
domain specific use cases to


231
00:08:16,676 --> 00:08:18,666
enable in your apps.


232
00:08:19,346 --> 00:08:21,236
The first step is to collect


233
00:08:21,416 --> 00:08:21,876
training data.


234
00:08:23,826 --> 00:08:25,286
In doing so, we'll take a look


235
00:08:25,536 --> 00:08:27,586
at a fruit classifier and see


236
00:08:27,586 --> 00:08:28,286
how you would do so.


237
00:08:29,596 --> 00:08:31,756
First, you'd want to gather many


238
00:08:31,756 --> 00:08:33,306
varied types of images that


239
00:08:33,306 --> 00:08:34,756
reflect the true data that


240
00:08:34,756 --> 00:08:36,296
you'll end up seeing and then


241
00:08:36,296 --> 00:08:37,796
label them.


242
00:08:37,796 --> 00:08:38,726
First, you can do this as a


243
00:08:38,726 --> 00:08:41,775
dictionary with the string label


244
00:08:42,066 --> 00:08:43,256
corresponding to arrays of


245
00:08:43,256 --> 00:08:43,726
images.


246
00:08:44,376 --> 00:08:46,466
Or what we've noticed is many


247
00:08:46,506 --> 00:08:48,226
popular data sets are organized


248
00:08:48,316 --> 00:08:49,636
in hierarchical directory


249
00:08:49,636 --> 00:08:51,706
structures such that the label


250
00:08:52,356 --> 00:08:53,726
is the name of the folder that


251
00:08:53,726 --> 00:08:55,006
contains all images within it.


252
00:08:56,726 --> 00:08:57,556
There are also other data


253
00:08:57,806 --> 00:09:00,116
sources such as single folders


254
00:09:00,286 --> 00:09:01,836
that contain labeled filenames.


255
00:09:02,296 --> 00:09:04,186
And in the Create ML API, we've


256
00:09:04,186 --> 00:09:05,876
provided conveniences to extract


257
00:09:06,156 --> 00:09:06,776
these structures.


258
00:09:09,126 --> 00:09:11,256
Now training is the more complex


259
00:09:11,396 --> 00:09:12,246
part of the equation.


260
00:09:12,686 --> 00:09:14,756
So once you have your data, this


261
00:09:14,806 --> 00:09:15,596
is what you will get next.


262
00:09:17,036 --> 00:09:18,946
And what you can do is you can


263
00:09:19,046 --> 00:09:20,576
start training a very complex


264
00:09:20,646 --> 00:09:22,776
model from scratch on your input


265
00:09:22,776 --> 00:09:23,176
images.


266
00:09:23,936 --> 00:09:25,516
And for this you need lots and


267
00:09:25,516 --> 00:09:26,326
lots of label data.


268
00:09:26,976 --> 00:09:28,546
You need big compute and you


269
00:09:28,546 --> 00:09:29,446
need a lot of patience.


270
00:09:30,396 --> 00:09:31,626
But another well-established


271
00:09:31,696 --> 00:09:33,376
technique in the industry is


272
00:09:33,376 --> 00:09:34,086
transfer learning.


273
00:09:34,966 --> 00:09:36,936
And since Apple has lots of


274
00:09:36,936 --> 00:09:38,796
experience in training complex


275
00:09:38,906 --> 00:09:40,236
machine learning models, we


276
00:09:40,236 --> 00:09:41,386
already have one in the


277
00:09:41,426 --> 00:09:43,036
operating system that you can


278
00:09:43,036 --> 00:09:43,826
take advantage of.


279
00:09:44,336 --> 00:09:46,056
So what we do is we apply


280
00:09:46,056 --> 00:09:47,616
transfer learning on top of this


281
00:09:47,686 --> 00:09:49,346
model that already exists in the


282
00:09:49,346 --> 00:09:50,806
OS, and we augment it,


283
00:09:51,256 --> 00:09:52,836
retraining the last few layers


284
00:09:53,166 --> 00:09:55,046
to your specific data so you no


285
00:09:55,046 --> 00:09:57,126
longer need millions of images.


286
00:09:57,476 --> 00:09:59,736
You can train a good classifier


287
00:09:59,936 --> 00:10:01,116
using the amount of data that


288
00:10:01,166 --> 00:10:01,446
you have.


289
00:10:03,576 --> 00:10:05,426
This results in faster training


290
00:10:05,516 --> 00:10:05,656
times.


291
00:10:06,176 --> 00:10:07,306
And for developers that we've


292
00:10:07,346 --> 00:10:08,936
worked with, we've seen them go


293
00:10:09,596 --> 00:10:12,996
from hours of training down to


294
00:10:12,996 --> 00:10:14,576
minutes for thousands of images


295
00:10:15,056 --> 00:10:16,756
or for small data sets, even


296
00:10:16,826 --> 00:10:17,166
seconds.


297
00:10:19,886 --> 00:10:21,126
This also results in much


298
00:10:21,296 --> 00:10:23,026
smaller models going from


299
00:10:23,026 --> 00:10:25,156
hundreds of megabytes down to


300
00:10:25,606 --> 00:10:26,756
just a few megabytes for


301
00:10:26,756 --> 00:10:28,426
thousands of images or even


302
00:10:28,426 --> 00:10:28,896
kilobytes.


303
00:10:32,076 --> 00:10:34,416
The goal of Create ML is to


304
00:10:34,416 --> 00:10:35,966
abstract much of this and make


305
00:10:35,966 --> 00:10:37,646
it simple and easy to use.


306
00:10:38,286 --> 00:10:39,786
But to prove it, let's take a


307
00:10:39,786 --> 00:10:40,396
look at a demo.


308
00:10:47,396 --> 00:10:49,356
First, to set up the problem, I


309
00:10:49,446 --> 00:10:51,066
started by running an app that's


310
00:10:51,126 --> 00:10:52,546
using a state-of-the-art image


311
00:10:52,626 --> 00:10:54,286
classification model that's


312
00:10:54,286 --> 00:10:55,166
already in the industry.


313
00:10:56,326 --> 00:10:57,486
This one, though, is quite


314
00:10:57,526 --> 00:10:57,766
large.


315
00:10:57,766 --> 00:10:59,446
It's 100 megabytes in our app.


316
00:11:00,676 --> 00:11:03,066
And if we run it, we have some


317
00:11:03,116 --> 00:11:07,016
fruits but it's not quite what I


318
00:11:07,016 --> 00:11:07,756
was looking for.


319
00:11:08,626 --> 00:11:10,256
I'd really like it if, instead,


320
00:11:11,356 --> 00:11:12,626
we could classify these


321
00:11:12,686 --> 00:11:13,316
particular ones.


322
00:11:14,376 --> 00:11:15,796
So what we can do is we can


323
00:11:15,886 --> 00:11:19,346
switch to a new playground and


324
00:11:19,346 --> 00:11:21,536
import CreateMLUI and walk


325
00:11:21,536 --> 00:11:24,166
through how to do this using the


326
00:11:24,166 --> 00:11:25,016
UI for it.


327
00:11:26,166 --> 00:11:27,276
We can define a builder.


328
00:11:28,796 --> 00:11:29,576
Initialize it.


329
00:11:29,576 --> 00:11:31,226
And to enable drag-and-drop


330
00:11:31,276 --> 00:11:32,766
training, we can show the


331
00:11:32,766 --> 00:11:34,186
builder in the live view.


332
00:11:38,426 --> 00:11:40,696
This brings up a prompt in the


333
00:11:40,696 --> 00:11:42,476
live view to drag in images to


334
00:11:42,646 --> 00:11:43,306
begin training.


335
00:11:44,886 --> 00:11:47,176
And here I set aside some photos


336
00:11:47,176 --> 00:11:47,866
of fruits.


337
00:11:48,746 --> 00:11:50,236
Here's some blueberries and


338
00:11:50,236 --> 00:11:50,676
other types.


339
00:11:51,746 --> 00:11:53,396
And you can drag them in and


340
00:11:53,476 --> 00:11:54,626
automatically an image


341
00:11:54,626 --> 00:11:56,366
classifier model begins training


342
00:11:56,576 --> 00:11:57,056
on the Mac.


343
00:11:57,916 --> 00:11:59,616
All of this is accelerated by


344
00:11:59,616 --> 00:12:01,806
the GPU on however many


345
00:12:01,806 --> 00:12:03,336
categories you end up training


346
00:12:03,336 --> 00:12:03,516
on.


347
00:12:04,736 --> 00:12:06,036
It automatically tells you what


348
00:12:06,036 --> 00:12:07,566
the accuracy is on the training


349
00:12:07,566 --> 00:12:09,526
data set, but what's more


350
00:12:09,526 --> 00:12:11,316
helpful is to try this on new


351
00:12:11,316 --> 00:12:13,076
images that the model hasn't


352
00:12:13,076 --> 00:12:15,006
seen before to predict how it


353
00:12:15,006 --> 00:12:17,076
will do on real use cases.


354
00:12:17,806 --> 00:12:18,846
So I can drag in this other


355
00:12:18,906 --> 00:12:20,696
folder containing unseen images.


356
00:12:21,786 --> 00:12:23,376
And now the model is evaluating


357
00:12:23,376 --> 00:12:24,846
all these new types of fruits.


358
00:12:25,246 --> 00:12:26,896
And if you scroll, you can see


359
00:12:26,896 --> 00:12:28,566
what the true label is of each


360
00:12:28,606 --> 00:12:30,296
type as well as with the


361
00:12:30,346 --> 00:12:31,756
predicted one was by the model.


362
00:12:34,376 --> 00:12:36,406
And if you're happy with this


363
00:12:36,406 --> 00:12:38,216
accuracy, what you can do is you


364
00:12:38,216 --> 00:12:39,976
can take the model and drag it


365
00:12:39,976 --> 00:12:40,406
into your app.


366
00:12:44,786 --> 00:12:45,496
I'll add it here.


367
00:12:45,806 --> 00:12:48,036
And if we take a look, this


368
00:12:48,076 --> 00:12:49,836
model is 83 kilobytes.


369
00:12:50,396 --> 00:12:52,656
It's a huge savings down from


370
00:12:52,766 --> 00:12:53,206
hundreds.


371
00:12:54,516 --> 00:12:59,736
[ Applause ]


372
00:13:00,236 --> 00:13:01,696
So we can delete the old model


373
00:13:01,696 --> 00:13:02,686
that we were using before.


374
00:13:02,686 --> 00:13:04,786
And in the view controller, we


375
00:13:04,786 --> 00:13:06,286
can initialize this new one,


376
00:13:06,986 --> 00:13:07,806
ImageClassifier.


377
00:13:10,536 --> 00:13:11,676
We can then re-run the app,


378
00:13:13,146 --> 00:13:17,866
bring up the simulator, and see


379
00:13:17,866 --> 00:13:18,946
how it does on some of those


380
00:13:19,026 --> 00:13:19,356
fruits.


381
00:13:24,026 --> 00:13:25,436
On the raspberry, it can now


382
00:13:25,436 --> 00:13:27,366
correctly predict it since we


383
00:13:27,366 --> 00:13:28,806
trained the model to recognize


384
00:13:29,276 --> 00:13:29,826
raspberries.


385
00:13:30,686 --> 00:13:31,736
We can even see if it can


386
00:13:31,736 --> 00:13:32,986
distinguish from strawberries


387
00:13:33,396 --> 00:13:34,126
and it can now.


388
00:13:37,956 --> 00:13:39,236
But there are other workflows


389
00:13:39,286 --> 00:13:39,826
you can use.


390
00:13:40,636 --> 00:13:41,516
Perhaps you want to do this


391
00:13:41,606 --> 00:13:43,356
programmatically or perhaps you


392
00:13:43,356 --> 00:13:44,056
want to automate it.


393
00:13:45,116 --> 00:13:46,486
We can also walk through how to


394
00:13:46,486 --> 00:13:48,096
use Create ML to do so.


395
00:13:48,866 --> 00:13:54,246
So now we can switch to another


396
00:13:54,296 --> 00:13:57,316
playground and import Create ML.


397
00:13:57,866 --> 00:13:59,566
Since we'll be using URLs, we


398
00:13:59,566 --> 00:14:01,386
also can import foundation.


399
00:14:03,686 --> 00:14:05,406
And since, on our desktop, we


400
00:14:05,406 --> 00:14:06,826
still have these folders of


401
00:14:06,826 --> 00:14:09,776
fruits, we can say where they


402
00:14:09,776 --> 00:14:14,586
are and also say where the


403
00:14:14,586 --> 00:14:15,466
testing fruits are.


404
00:14:15,466 --> 00:14:17,526
And then the next step is to


405
00:14:17,526 --> 00:14:18,636
actually train the model.


406
00:14:19,426 --> 00:14:22,376
So we can define a model, and we


407
00:14:22,376 --> 00:14:23,716
can initialize an image


408
00:14:23,716 --> 00:14:24,386
classifier.


409
00:14:25,206 --> 00:14:26,726
And now if we take a look at


410
00:14:26,726 --> 00:14:28,166
what auto complete shows to us,


411
00:14:28,296 --> 00:14:29,826
we can see we can provide


412
00:14:29,826 --> 00:14:31,006
training data in the form of a


413
00:14:31,006 --> 00:14:33,016
dictionary of labels to arrays


414
00:14:33,086 --> 00:14:36,056
of images or we can use a data


415
00:14:36,166 --> 00:14:38,616
source or even specify model


416
00:14:38,666 --> 00:14:39,846
training parameters if we want


417
00:14:39,906 --> 00:14:40,046
to.


418
00:14:41,456 --> 00:14:42,466
Let's use a data source.


419
00:14:42,466 --> 00:14:44,226
And we'll use label directories


420
00:14:44,296 --> 00:14:45,366
since that's how our data is


421
00:14:45,366 --> 00:14:47,576
organized and specify the


422
00:14:47,576 --> 00:14:48,436
training directory.


423
00:14:50,526 --> 00:14:51,556
And since we're running in the


424
00:14:51,556 --> 00:14:52,946
new [inaudible] mode of Xcode


425
00:14:52,976 --> 00:14:54,226
playground, I just need to hit


426
00:14:54,226 --> 00:14:56,726
shift enter and the model begins


427
00:14:56,726 --> 00:14:57,796
training right away.


428
00:14:59,216 --> 00:15:00,576
You can even pull up the console


429
00:15:01,556 --> 00:15:04,006
and see output of one, its


430
00:15:04,006 --> 00:15:06,036
extracting features and how many


431
00:15:06,036 --> 00:15:07,256
iterations it's running through.


432
00:15:08,566 --> 00:15:10,126
Afterwards, you can also open


433
00:15:10,126 --> 00:15:12,066
quick looks and see the name of


434
00:15:12,066 --> 00:15:13,866
the model and how many instances


435
00:15:13,866 --> 00:15:14,546
it's trained on.


436
00:15:16,216 --> 00:15:18,076
Now we might want to evaluate on


437
00:15:18,076 --> 00:15:19,286
the testing data that we've set


438
00:15:19,376 --> 00:15:19,686
aside.


439
00:15:20,666 --> 00:15:22,926
So what we can do is we can call


440
00:15:22,926 --> 00:15:25,116
evaluation on another data


441
00:15:25,306 --> 00:15:26,626
source since that folder is


442
00:15:26,626 --> 00:15:27,636
organized the same way,


443
00:15:28,036 --> 00:15:29,596
specifying the URL of the


444
00:15:29,646 --> 00:15:30,206
testing data.


445
00:15:30,986 --> 00:15:33,246
You can hit shift enter and now


446
00:15:33,246 --> 00:15:35,196
the model is evaluating testing


447
00:15:35,196 --> 00:15:35,456
images.


448
00:15:36,196 --> 00:15:37,816
Once it's complete, we can also


449
00:15:37,816 --> 00:15:39,326
look at the quick look and see


450
00:15:39,326 --> 00:15:40,956
how many examples it evaluated


451
00:15:40,956 --> 00:15:42,636
on as well as how many classes


452
00:15:42,726 --> 00:15:44,166
were in that folder altogether


453
00:15:44,596 --> 00:15:45,366
and the accuracy.


454
00:15:46,886 --> 00:15:48,326
If we're happy with that, we can


455
00:15:48,376 --> 00:15:48,816
write it out.


456
00:15:58,606 --> 00:15:59,716
And say that I want to write it


457
00:15:59,826 --> 00:16:00,996
to the desktop with the name


458
00:16:01,206 --> 00:16:02,706
fruit classifier ML model.


459
00:16:04,846 --> 00:16:06,296
Once I do, you can see this new


460
00:16:06,296 --> 00:16:07,676
model appears on the desktop.


461
00:16:08,586 --> 00:16:09,876
We can double-click it and take


462
00:16:09,876 --> 00:16:12,046
a look and see it's exactly the


463
00:16:12,126 --> 00:16:12,466
same.


464
00:16:12,696 --> 00:16:14,256
This is also 83 kilobytes.


465
00:16:17,036 --> 00:16:18,316
Furthermore, we can integrate it


466
00:16:18,376 --> 00:16:19,666
back into our app the same way.


467
00:16:21,206 --> 00:16:21,596
Let's recap.


468
00:16:22,516 --> 00:16:31,506
[ Applause ]


469
00:16:32,006 --> 00:16:33,536
We saw two ways of training


470
00:16:33,536 --> 00:16:35,126
image classifier models in


471
00:16:35,126 --> 00:16:35,516
Create ML.


472
00:16:36,276 --> 00:16:38,406
One was with the UI which makes


473
00:16:38,406 --> 00:16:40,446
it super simple to drag-and-drop


474
00:16:40,656 --> 00:16:41,626
your training data and


475
00:16:41,626 --> 00:16:43,956
evaluation data to produce an ML


476
00:16:43,956 --> 00:16:44,276
model.


477
00:16:45,396 --> 00:16:47,126
The other way was with the


478
00:16:47,126 --> 00:16:47,866
Create ML API.


479
00:16:48,676 --> 00:16:49,726
If we walk through some of this


480
00:16:49,726 --> 00:16:51,406
code, we can see the first thing


481
00:16:51,406 --> 00:16:53,396
we had to do was import Create


482
00:16:53,396 --> 00:16:53,486
ML.


483
00:16:54,456 --> 00:16:56,066
The next was to specify where


484
00:16:56,066 --> 00:16:57,486
our training and testing data


485
00:16:57,486 --> 00:16:59,666
was and then actually begin


486
00:16:59,666 --> 00:17:01,396
training the model by specifying


487
00:17:01,496 --> 00:17:02,726
how our training data was laid


488
00:17:02,726 --> 00:17:02,926
out.


489
00:17:04,205 --> 00:17:05,346
We can then evaluate on the


490
00:17:05,415 --> 00:17:07,996
testing data and finally save ML


491
00:17:07,996 --> 00:17:08,306
model.


492
00:17:11,576 --> 00:17:12,596
If you want to automate this,


493
00:17:13,006 --> 00:17:14,215
you can also turn these into


494
00:17:14,326 --> 00:17:16,106
scripts, which is a very popular


495
00:17:16,106 --> 00:17:17,836
way of saving what you've done


496
00:17:17,836 --> 00:17:19,215
and re-running it whenever.


497
00:17:21,746 --> 00:17:22,896
You can then change permissions


498
00:17:22,896 --> 00:17:24,766
on the file and run them like


499
00:17:24,866 --> 00:17:25,086
so.


500
00:17:26,056 --> 00:17:27,806
Or for other workflows, you can


501
00:17:27,806 --> 00:17:29,996
always use Swift command line


502
00:17:29,996 --> 00:17:30,126
[inaudible].


503
00:17:30,126 --> 00:17:33,246
So we've seen today how to train


504
00:17:33,246 --> 00:17:34,496
image classification models


505
00:17:35,016 --> 00:17:36,176
using a few different workflows.


506
00:17:36,176 --> 00:17:38,496
But next, I'd like to pass it


507
00:17:38,496 --> 00:17:40,576
off to Tao to talk about natural


508
00:17:40,576 --> 00:17:40,976
language.


509
00:17:41,476 --> 00:17:41,766
Thank you.


510
00:17:42,516 --> 00:17:49,876
[ Applause ]


511
00:17:50,376 --> 00:17:53,546
>> Thank you, Lizi.


512
00:17:54,636 --> 00:17:55,336
Hello everyone.


513
00:17:55,526 --> 00:17:56,466
My name is Tao.


514
00:17:56,466 --> 00:17:58,416
I'm an engineer here at Apple


515
00:17:58,686 --> 00:18:00,086
working on the Core ML team.


516
00:18:00,996 --> 00:18:03,166
You just saw how easy and


517
00:18:03,166 --> 00:18:04,676
intuitive to train an image


518
00:18:04,676 --> 00:18:07,036
classifier with just a few lines


519
00:18:07,036 --> 00:18:07,616
of code.


520
00:18:08,246 --> 00:18:10,146
Now I'm going to show you the


521
00:18:10,146 --> 00:18:11,876
same can be done for natural


522
00:18:11,876 --> 00:18:12,406
language.


523
00:18:12,956 --> 00:18:15,926
In this year's release, we're


524
00:18:15,926 --> 00:18:17,476
going to support two natural


525
00:18:17,476 --> 00:18:19,826
language tasks: text


526
00:18:19,826 --> 00:18:21,866
classification and word tagging.


527
00:18:23,096 --> 00:18:25,046
Today, I'm going to focus on


528
00:18:25,046 --> 00:18:26,516
text classification.


529
00:18:26,836 --> 00:18:28,216
For details on word tagging,


530
00:18:28,796 --> 00:18:30,136
please join the natural language


531
00:18:30,136 --> 00:18:31,796
session that happens tomorrow.


532
00:18:32,656 --> 00:18:34,446
Text classification can be used


533
00:18:34,696 --> 00:18:35,846
in a few machine learning


534
00:18:35,926 --> 00:18:36,606
applications.


535
00:18:37,816 --> 00:18:39,886
For example, sentiment analysis.


536
00:18:40,756 --> 00:18:42,526
The energy of developers is


537
00:18:42,526 --> 00:18:43,516
amazing.


538
00:18:43,826 --> 00:18:44,906
That's a positive note.


539
00:18:45,336 --> 00:18:46,776
You want your app to know it.


540
00:18:47,516 --> 00:18:50,166
[ Applause ]


541
00:18:50,666 --> 00:18:51,656
Spam analysis.


542
00:18:52,336 --> 00:18:54,006
If you saw this message in your


543
00:18:54,006 --> 00:18:55,846
mailbox, you know it's very


544
00:18:55,846 --> 00:18:57,616
likely it's spam.


545
00:18:57,766 --> 00:19:00,056
So you want your app to know


546
00:19:00,526 --> 00:19:02,086
that as well.


547
00:19:02,086 --> 00:19:03,076
Topic analysis.


548
00:19:03,736 --> 00:19:05,696
The Warriors just had an amazing


549
00:19:05,696 --> 00:19:06,636
comeback win.


550
00:19:07,166 --> 00:19:08,686
That's a sport post.


551
00:19:08,906 --> 00:19:10,406
You want your app to be able to


552
00:19:10,406 --> 00:19:11,186
classify that.


553
00:19:12,406 --> 00:19:14,876
So to train such a classifier,


554
00:19:14,876 --> 00:19:16,226
the first thing you do is to


555
00:19:16,226 --> 00:19:17,436
collect some training data.


556
00:19:18,326 --> 00:19:21,076
With Create ML, we support a few


557
00:19:21,076 --> 00:19:22,256
different ways for you to


558
00:19:22,256 --> 00:19:23,686
organize your training data.


559
00:19:24,326 --> 00:19:26,776
For example, label directories.


560
00:19:27,486 --> 00:19:28,796
Here you have two folders.


561
00:19:29,116 --> 00:19:30,856
One named positive, the other


562
00:19:30,856 --> 00:19:32,196
one named negative.


563
00:19:32,836 --> 00:19:34,526
Within each folder, you have a


564
00:19:34,526 --> 00:19:37,026
number of articles with just raw


565
00:19:37,026 --> 00:19:40,046
text whose truth label is simply


566
00:19:40,046 --> 00:19:41,616
the name of the folder.


567
00:19:43,096 --> 00:19:45,056
Alternatively, you can prepare


568
00:19:45,056 --> 00:19:46,456
your training data using simple


569
00:19:46,456 --> 00:19:48,866
CSV where you prepare your raw


570
00:19:48,866 --> 00:19:50,766
text and the truth label


571
00:19:50,966 --> 00:19:51,916
separated by comma.


572
00:19:52,926 --> 00:19:54,926
We also support JSON formatting


573
00:19:54,926 --> 00:19:56,856
the training data and know that


574
00:19:57,236 --> 00:19:58,426
we just talk about the training


575
00:19:58,426 --> 00:20:00,326
data organization and you can


576
00:20:00,366 --> 00:20:02,056
actually organize your test data


577
00:20:02,056 --> 00:20:03,326
in the exact same way.


578
00:20:06,376 --> 00:20:08,296
Now with your training data and


579
00:20:08,296 --> 00:20:10,196
test data ready, what other


580
00:20:10,196 --> 00:20:12,246
steps involve to train such a


581
00:20:12,246 --> 00:20:13,196
text classifier?


582
00:20:16,046 --> 00:20:17,806
A typical workflow would look


583
00:20:17,806 --> 00:20:18,576
something like this.


584
00:20:20,046 --> 00:20:21,396
You start with your raw text.


585
00:20:22,286 --> 00:20:24,206
You do a language identification


586
00:20:24,206 --> 00:20:25,536
to figure out which language it


587
00:20:25,536 --> 00:20:25,906
is in.


588
00:20:27,286 --> 00:20:28,916
You convert that into tokens.


589
00:20:30,306 --> 00:20:31,756
And then you convert that into


590
00:20:31,756 --> 00:20:34,946
some feature values and then you


591
00:20:34,946 --> 00:20:36,216
can apply a machine learning


592
00:20:36,216 --> 00:20:38,536
model that gives you some


593
00:20:38,536 --> 00:20:40,116
predictive value that you have


594
00:20:40,116 --> 00:20:42,066
to map to some desired label.


595
00:20:42,066 --> 00:20:44,126
And then you can compare that


596
00:20:44,126 --> 00:20:46,256
label to your truth label and


597
00:20:46,346 --> 00:20:49,206
start iterating on it.


598
00:20:49,466 --> 00:20:51,926
With Create ML, though, we took


599
00:20:51,926 --> 00:20:54,666
away all these complexities so


600
00:20:54,666 --> 00:20:56,696
that all you need to do is to


601
00:20:56,696 --> 00:20:58,896
prepare raw text with their


602
00:20:58,896 --> 00:21:01,226
truth label and start training


603
00:21:01,686 --> 00:21:02,566
immediately.


604
00:21:03,516 --> 00:21:09,356
[ Applause ]


605
00:21:09,856 --> 00:21:11,686
Now let me give you a concrete


606
00:21:11,686 --> 00:21:13,256
example like how you can train


607
00:21:13,256 --> 00:21:15,406
such a classifier and use it.


608
00:21:16,186 --> 00:21:18,396
For example, we have this simple


609
00:21:18,536 --> 00:21:21,106
app called Stay Positive whose


610
00:21:21,196 --> 00:21:23,566
purpose is to encourage positive


611
00:21:23,626 --> 00:21:24,016
post.


612
00:21:24,656 --> 00:21:27,246
If a user entered I hate


613
00:21:27,246 --> 00:21:29,326
traffic, the background turns


614
00:21:29,326 --> 00:21:31,506
red and it will disable the post


615
00:21:31,506 --> 00:21:31,856
button.


616
00:21:32,706 --> 00:21:37,206
I love driving my car at five


617
00:21:37,206 --> 00:21:40,006
mile per hour just chilling in


618
00:21:40,736 --> 00:21:41,416
traffic.


619
00:21:41,626 --> 00:21:42,736
That's a positive post.


620
00:21:42,946 --> 00:21:44,646
We encourage you to post it.


621
00:21:46,116 --> 00:21:47,876
Just imagine what our Internet


622
00:21:47,876 --> 00:21:49,486
would look like with this app


623
00:21:49,836 --> 00:21:51,406
running on everybody's phone?


624
00:21:52,516 --> 00:21:56,396
[ Applause ]


625
00:21:56,896 --> 00:21:58,336
Now, in order to do that, let me


626
00:21:58,336 --> 00:21:59,296
give you a live demo.


627
00:22:07,016 --> 00:22:09,966
So to train such a classifier,


628
00:22:09,966 --> 00:22:11,506
the first thing I do is collect


629
00:22:11,506 --> 00:22:12,206
some training data.


630
00:22:12,916 --> 00:22:17,736
On my desktop, I have a train


631
00:22:17,736 --> 00:22:19,436
folder and also a test folder.


632
00:22:20,126 --> 00:22:21,616
In train folder, we have two


633
00:22:21,616 --> 00:22:22,156
folders.


634
00:22:22,316 --> 00:22:23,816
One is named positive, the other


635
00:22:23,816 --> 00:22:26,246
one negative, and there are a


636
00:22:26,246 --> 00:22:28,106
number of articles in each


637
00:22:28,106 --> 00:22:28,446
folder.


638
00:22:29,526 --> 00:22:31,486
And test folder is organized in


639
00:22:31,486 --> 00:22:32,686
a very similar way.


640
00:22:33,436 --> 00:22:38,116
So the first thing I do is to


641
00:22:38,116 --> 00:22:41,196
import Create ML.


642
00:22:41,446 --> 00:22:43,846
Now I need to tell the


643
00:22:43,846 --> 00:22:45,206
[inaudible] where to find my


644
00:22:45,206 --> 00:22:46,666
training data.


645
00:22:47,436 --> 00:22:50,056
For that, I'm simply using a URL


646
00:22:50,056 --> 00:22:53,056
capability and then I can start


647
00:22:53,056 --> 00:22:54,656
training my model using the


648
00:22:54,656 --> 00:22:56,576
label directories that Lizi just


649
00:22:56,576 --> 00:22:57,206
showed you.


650
00:22:57,556 --> 00:23:00,756
Look. The training has started.


651
00:23:02,406 --> 00:23:03,656
As you can see on the bottom


652
00:23:03,656 --> 00:23:05,166
there, there is some progress


653
00:23:05,166 --> 00:23:06,726
report for you to check.


654
00:23:06,926 --> 00:23:08,746
Looks like training has


655
00:23:10,056 --> 00:23:10,276
finished.


656
00:23:10,406 --> 00:23:12,566
Now you can check some basic


657
00:23:12,566 --> 00:23:13,696
performance numbers on this


658
00:23:13,696 --> 00:23:14,256
model.


659
00:23:14,496 --> 00:23:15,096
For example,


660
00:23:15,966 --> 00:23:19,226
model.trainingMetrics that shows


661
00:23:19,226 --> 00:23:20,516
you this model has been trained


662
00:23:20,516 --> 00:23:23,226
on over 2000 examples and


663
00:23:23,226 --> 00:23:24,786
accuracy is 100%.


664
00:23:25,286 --> 00:23:29,796
But how does it perform on some


665
00:23:29,846 --> 00:23:30,556
unseen data?


666
00:23:31,446 --> 00:23:33,336
So I'm going to do the same to


667
00:23:33,366 --> 00:23:37,126
define test data and then


668
00:23:38,376 --> 00:23:42,086
evaluate that model on the test


669
00:23:43,316 --> 00:23:43,456
data.


670
00:23:43,626 --> 00:23:46,336
As you can see, we have 77 test


671
00:23:46,516 --> 00:23:49,036
examples, and we are achieving


672
00:23:49,446 --> 00:23:52,966
over 94% accuracy, which is very


673
00:23:52,966 --> 00:23:53,616
good.


674
00:23:54,556 --> 00:23:56,076
I'm sure you want to iterate on


675
00:23:56,076 --> 00:23:57,296
that if you want to see like


676
00:23:57,296 --> 00:23:59,906
even a higher number, but this


677
00:23:59,906 --> 00:24:01,936
number is pretty good enough for


678
00:24:01,936 --> 00:24:04,276
my app so let me just test it


679
00:24:04,276 --> 00:24:04,456
out.


680
00:24:05,306 --> 00:24:07,686
So to save out the model, what I


681
00:24:07,686 --> 00:24:10,446
need to do is define a URL where


682
00:24:10,446 --> 00:24:14,496
it's saving to and then write


683
00:24:14,496 --> 00:24:16,176
out a model to my desktop.


684
00:24:16,736 --> 00:24:19,086
Looks, that model has been


685
00:24:19,246 --> 00:24:20,306
saved.


686
00:24:22,236 --> 00:24:23,906
So now I need to switch back to


687
00:24:23,906 --> 00:24:24,386
my app.


688
00:24:25,326 --> 00:24:27,266
Just drag and drop it.


689
00:24:27,836 --> 00:24:29,396
There you go.


690
00:24:33,636 --> 00:24:36,756
Now I can start use it.


691
00:24:37,276 --> 00:24:39,686
I will do let model equal to


692
00:24:39,686 --> 00:24:42,176
textClassifier which should auto


693
00:24:42,176 --> 00:24:42,566
complete.


694
00:24:43,426 --> 00:24:45,236
And then I'm going to insert


695
00:24:45,236 --> 00:24:47,236
some basic inference code.


696
00:24:47,776 --> 00:24:50,716
In this inference code, as you


697
00:24:50,716 --> 00:24:52,576
see, the first line I do is


698
00:24:52,696 --> 00:24:54,826
using model.prediction to get


699
00:24:54,826 --> 00:24:55,386
prediction.


700
00:24:55,386 --> 00:24:56,806
And then in order to hook up


701
00:24:56,806 --> 00:24:58,586
with this simple app UI, I just


702
00:24:58,586 --> 00:25:00,026
convert that into some double


703
00:25:00,026 --> 00:25:00,456
value.


704
00:25:01,146 --> 00:25:03,566
Let's give it a try.


705
00:25:16,456 --> 00:25:18,026
Yeah. Let's try some example we


706
00:25:18,026 --> 00:25:18,766
have showed you.


707
00:25:19,676 --> 00:25:23,566
I hate traffic.


708
00:25:24,666 --> 00:25:27,196
Negative. I love driving my car


709
00:25:27,936 --> 00:25:30,856
at five mile per hour just


710
00:25:30,856 --> 00:25:32,666
chilling in traffic.


711
00:25:33,416 --> 00:25:35,866
Positive. Let's try something


712
00:25:35,866 --> 00:25:37,686
different that'll be fun.


713
00:25:38,706 --> 00:25:41,486
Machine learning is hard.


714
00:25:41,686 --> 00:25:45,436
Create ML makes it so easy.


715
00:25:46,536 --> 00:25:47,076
Positive.


716
00:25:48,516 --> 00:25:53,166
[ Applause ]


717
00:25:53,666 --> 00:25:55,046
So that's how you train your


718
00:25:55,046 --> 00:25:57,776
customized text classifier and


719
00:25:57,776 --> 00:25:59,926
drag it into your app to use it.


720
00:26:04,796 --> 00:26:06,406
Here's a recap.


721
00:26:07,836 --> 00:26:09,726
So to train such a classifier,


722
00:26:09,866 --> 00:26:11,266
the first thing you do is to


723
00:26:11,266 --> 00:26:12,246
specify your data.


724
00:26:13,216 --> 00:26:14,686
You specify your training data


725
00:26:14,686 --> 00:26:18,136
as well as your test data and


726
00:26:18,136 --> 00:26:19,586
then you can create your model


727
00:26:19,586 --> 00:26:20,836
on the training data.


728
00:26:22,146 --> 00:26:24,646
To evaluate its performance, you


729
00:26:24,646 --> 00:26:26,246
evaluate a model on the test


730
00:26:26,246 --> 00:26:26,466
data.


731
00:26:27,786 --> 00:26:30,136
Finally, to use your model in


732
00:26:30,136 --> 00:26:32,716
your app, you simply save it out


733
00:26:32,716 --> 00:26:35,336
using this write API.


734
00:26:38,176 --> 00:26:41,586
To summarize, with just a few


735
00:26:41,586 --> 00:26:43,676
lines of code, you can train


736
00:26:43,676 --> 00:26:45,986
your customized text classifier


737
00:26:47,136 --> 00:26:48,526
simple intuitive.


738
00:26:49,046 --> 00:26:52,196
With that, I'd like to hand back


739
00:26:52,196 --> 00:26:53,586
to Gaurav who is going to talk


740
00:26:53,586 --> 00:26:54,696
about tabular data.


741
00:26:55,256 --> 00:26:55,626
Thank you.


742
00:26:56,516 --> 00:27:00,986
[ Applause ]


743
00:27:01,486 --> 00:27:04,576
>> Thank you, Tao.


744
00:27:04,826 --> 00:27:07,136
Besides images and text, another


745
00:27:07,136 --> 00:27:08,776
common source of data that


746
00:27:08,776 --> 00:27:10,106
occurs very frequently when


747
00:27:10,106 --> 00:27:11,136
you're solving a machine


748
00:27:11,136 --> 00:27:12,556
learning problem is tabular


749
00:27:12,556 --> 00:27:12,706
data.


750
00:27:13,986 --> 00:27:15,526
What I mean by tabular data, I


751
00:27:15,526 --> 00:27:17,446
mean the data is in special


752
00:27:17,446 --> 00:27:19,206
format or in a table format.


753
00:27:19,686 --> 00:27:21,126
This kind of data occurs fairly


754
00:27:21,126 --> 00:27:21,716
frequently.


755
00:27:22,766 --> 00:27:24,356
For example, let's just say


756
00:27:24,356 --> 00:27:25,706
you're trying to predict house


757
00:27:25,796 --> 00:27:27,326
prices using number of beds,


758
00:27:27,406 --> 00:27:28,716
number of baths, or square


759
00:27:28,786 --> 00:27:29,196
footage.


760
00:27:29,836 --> 00:27:31,366
Generally the data is arranged


761
00:27:31,446 --> 00:27:32,446
in a tabular format.


762
00:27:32,446 --> 00:27:35,656
You want to predict the quality


763
00:27:35,656 --> 00:27:36,996
of wine using its chemical


764
00:27:36,996 --> 00:27:37,996
compositions.


765
00:27:38,316 --> 00:27:39,336
Chances are data will be


766
00:27:39,336 --> 00:27:40,456
arranged in table format.


767
00:27:41,066 --> 00:27:42,426
Or something even simple like


768
00:27:42,486 --> 00:27:44,116
where to hop, which bar to hop


769
00:27:44,116 --> 00:27:46,396
tonight using happy hour or its


770
00:27:46,516 --> 00:27:48,516
price, the data will be in


771
00:27:48,776 --> 00:27:50,066
tabular format.


772
00:27:51,696 --> 00:27:55,076
To handle the data which is in


773
00:27:55,076 --> 00:27:56,756
tabular format, we actually


774
00:27:56,936 --> 00:27:59,846
introduce a new data structure


775
00:27:59,846 --> 00:28:01,686
which we call as MLDataTable.


776
00:28:02,496 --> 00:28:04,876
MLDataTable is based on


777
00:28:04,876 --> 00:28:06,866
[inaudible] technology that we


778
00:28:06,866 --> 00:28:08,546
will discuss in detail tomorrow.


779
00:28:09,036 --> 00:28:11,136
There's something interesting


780
00:28:11,136 --> 00:28:12,286
about these data tables.


781
00:28:13,876 --> 00:28:15,056
The rows contains the


782
00:28:15,056 --> 00:28:17,266
observations or examples.


783
00:28:17,356 --> 00:28:18,946
So here, house number two has


784
00:28:19,056 --> 00:28:21,236
four bed, three bath, and 500K


785
00:28:21,316 --> 00:28:21,666
price.


786
00:28:22,336 --> 00:28:25,006
The columns contains what we


787
00:28:25,006 --> 00:28:25,876
call as features.


788
00:28:26,306 --> 00:28:27,636
So the beds are features, baths


789
00:28:28,636 --> 00:28:30,426
are features, square feet,


790
00:28:30,966 --> 00:28:31,886
etcetera are features.


791
00:28:33,206 --> 00:28:34,966
There is one special column that


792
00:28:35,016 --> 00:28:37,446
we want to predict, in this case


793
00:28:37,586 --> 00:28:41,246
price, and this column is known


794
00:28:41,246 --> 00:28:43,286
as target or response variable.


795
00:28:44,046 --> 00:28:45,546
The whole idea behind tabular


796
00:28:45,546 --> 00:28:47,136
data is that we want to predict


797
00:28:47,136 --> 00:28:49,456
target variable as a function of


798
00:28:49,646 --> 00:28:51,846
one or many of these features.


799
00:28:51,896 --> 00:28:57,086
So what are the common sources


800
00:28:57,086 --> 00:28:57,756
that we support?


801
00:28:57,756 --> 00:28:59,926
Well, CSV, JSON as well as you


802
00:28:59,926 --> 00:29:02,306
can actually have code.


803
00:29:02,786 --> 00:29:04,666
So let's talk a little bit more


804
00:29:05,436 --> 00:29:07,886
about MLDataTable.


805
00:29:08,396 --> 00:29:11,946
First, you can read data simply


806
00:29:11,946 --> 00:29:14,346
by using CSV.


807
00:29:14,826 --> 00:29:17,536
What is more important that you


808
00:29:17,536 --> 00:29:19,636
can access the column using a


809
00:29:19,636 --> 00:29:20,806
subscript notation.


810
00:29:20,996 --> 00:29:22,426
So all you do is house or the


811
00:29:22,496 --> 00:29:23,926
price and you get an entire


812
00:29:23,926 --> 00:29:27,296
column of price.


813
00:29:27,476 --> 00:29:28,856
You can add two columns,


814
00:29:28,856 --> 00:29:30,356
subtract two column, multiply


815
00:29:30,356 --> 00:29:31,886
two column, divide two columns.


816
00:29:32,686 --> 00:29:35,376
And the way you do it is in very


817
00:29:35,376 --> 00:29:36,696
natural looking syntax.


818
00:29:36,696 --> 00:29:37,956
So you just simply say house or


819
00:29:37,956 --> 00:29:39,296
the price divided by house or


820
00:29:39,296 --> 00:29:41,356
the square foot to get price per


821
00:29:41,356 --> 00:29:41,896
square foot.


822
00:29:43,136 --> 00:29:45,196
Behind the scenes, this


823
00:29:45,226 --> 00:29:46,936
calculation is done using


824
00:29:46,936 --> 00:29:49,106
[inaudible] evaluation and


825
00:29:49,106 --> 00:29:50,196
through vector operations.


826
00:29:50,956 --> 00:29:53,716
It can also do some of the other


827
00:29:53,716 --> 00:29:54,576
interesting things.


828
00:29:54,686 --> 00:29:56,596
For example, you can split data


829
00:29:56,596 --> 00:29:58,616
table in training as well as you


830
00:29:58,696 --> 00:29:59,946
can even do filtering.


831
00:30:00,746 --> 00:30:02,146
So for example, if you're only


832
00:30:02,146 --> 00:30:04,406
interested in large houses, you


833
00:30:04,406 --> 00:30:05,956
can create an indicator variable


834
00:30:05,956 --> 00:30:06,896
and filter it out.


835
00:30:08,116 --> 00:30:09,846
There a lot of operations that


836
00:30:09,846 --> 00:30:11,656
data table support.


837
00:30:11,656 --> 00:30:13,686
I urge you to try it out in


838
00:30:13,686 --> 00:30:14,626
Xcode playground.


839
00:30:14,766 --> 00:30:15,196
They're fun.


840
00:30:15,196 --> 00:30:19,406
Now once you have data in data


841
00:30:19,406 --> 00:30:20,706
table, you would like to do the


842
00:30:20,746 --> 00:30:21,426
training on it.


843
00:30:22,846 --> 00:30:24,416
Create ML supports a large


844
00:30:24,416 --> 00:30:25,766
number of algorithms such as


845
00:30:25,766 --> 00:30:29,006
Boosted Tree Regression, Random


846
00:30:29,006 --> 00:30:30,146
Forest, etcetera.


847
00:30:31,256 --> 00:30:33,526
And all of these algorithms are


848
00:30:33,526 --> 00:30:34,506
represented by their class.


849
00:30:34,506 --> 00:30:37,936
In order to train your model,


850
00:30:37,936 --> 00:30:39,356
you only have to write one line


851
00:30:39,356 --> 00:30:39,816
of code.


852
00:30:40,246 --> 00:30:41,786
Basically, you tell what is the


853
00:30:41,826 --> 00:30:44,036
target and where you're getting


854
00:30:44,036 --> 00:30:45,466
the data and which is the


855
00:30:45,466 --> 00:30:46,886
algorithm you are instantiating.


856
00:30:47,456 --> 00:30:49,006
So in this case, let's just say


857
00:30:49,006 --> 00:30:49,846
you are running Linear


858
00:30:49,846 --> 00:30:52,586
Regression or Regularized Linear


859
00:30:52,586 --> 00:30:53,816
Regression, you just actually


860
00:30:53,816 --> 00:30:56,676
tell it that the data is house


861
00:30:56,676 --> 00:30:57,876
data and the column is price.


862
00:30:58,666 --> 00:31:03,016
If you do Boosted Tree


863
00:31:03,016 --> 00:31:04,746
Regression, just replace Linear


864
00:31:04,746 --> 00:31:06,046
Regression with Boosted Tree and


865
00:31:06,046 --> 00:31:06,676
you're all set.


866
00:31:07,676 --> 00:31:09,946
Now Random Forest like that.


867
00:31:11,316 --> 00:31:14,346
Plus we also provide a high


868
00:31:14,346 --> 00:31:16,186
level abstraction MLRegressor


869
00:31:16,526 --> 00:31:18,066
that automatically runs all


870
00:31:18,066 --> 00:31:19,706
these algorithms and choose the


871
00:31:19,706 --> 00:31:20,666
best one for you.


872
00:31:21,516 --> 00:31:27,196
[ Applause ]


873
00:31:27,696 --> 00:31:28,866
This is in line with our


874
00:31:28,866 --> 00:31:30,606
philosophy that you should focus


875
00:31:30,606 --> 00:31:30,876
on task.


876
00:31:30,876 --> 00:31:32,476
So the task is to predict the


877
00:31:32,536 --> 00:31:32,916
price.


878
00:31:32,916 --> 00:31:34,146
You should not focus about


879
00:31:34,516 --> 00:31:35,656
nitty-gritty details of the


880
00:31:35,656 --> 00:31:36,286
algorithm.


881
00:31:37,056 --> 00:31:38,776
Having said that, in case you're


882
00:31:38,776 --> 00:31:40,876
an expert, you can actually use


883
00:31:40,876 --> 00:31:42,316
Boosted Tree and change its


884
00:31:42,316 --> 00:31:43,506
parameters also.


885
00:31:48,156 --> 00:31:50,446
So a complete end-to-end would


886
00:31:50,446 --> 00:31:51,126
look like this.


887
00:31:52,016 --> 00:31:54,396
It follows exactly the same


888
00:31:54,396 --> 00:31:56,196
pattern as image and text.


889
00:31:56,586 --> 00:31:59,956
First, you specify the data.


890
00:32:00,276 --> 00:32:02,616
Second, you just create your


891
00:32:03,646 --> 00:32:04,096
model.


892
00:32:04,546 --> 00:32:05,966
Third, you evaluate the model.


893
00:32:07,346 --> 00:32:09,126
And once you're happy, you save


894
00:32:09,126 --> 00:32:09,386
it out.


895
00:32:10,536 --> 00:32:13,856
So tabular data, image data, or


896
00:32:14,086 --> 00:32:15,746
text data, they all follow the


897
00:32:15,806 --> 00:32:17,206
same pattern.


898
00:32:19,876 --> 00:32:21,466
So let's just take a quick


899
00:32:21,466 --> 00:32:23,856
summary of what we saw in this


900
00:32:23,946 --> 00:32:24,356
session.


901
00:32:27,676 --> 00:32:30,466
So Create ML is our ML framework


902
00:32:30,466 --> 00:32:30,896
insert.


903
00:32:30,896 --> 00:32:33,156
It's very simple to use and it


904
00:32:33,156 --> 00:32:34,876
is very powerful and it


905
00:32:34,876 --> 00:32:35,836
leverages core Apple


906
00:32:35,836 --> 00:32:36,836
technologies.


907
00:32:36,836 --> 00:32:38,226
You do end-to-end machine


908
00:32:38,226 --> 00:32:40,686
learning in Swift on your Mac.


909
00:32:43,256 --> 00:32:45,116
We also discussed about our


910
00:32:45,176 --> 00:32:46,036
workflow.


911
00:32:46,976 --> 00:32:49,146
Once again, you start from an


912
00:32:49,146 --> 00:32:49,896
experience.


913
00:32:50,576 --> 00:32:51,576
What is the experience you're


914
00:32:51,576 --> 00:32:52,366
trying to enable?


915
00:32:53,716 --> 00:32:55,196
Then define the problem.


916
00:32:55,946 --> 00:32:57,176
Then collect the data.


917
00:32:57,456 --> 00:32:58,846
Make sure this data is


918
00:32:58,896 --> 00:33:00,456
reflective of the real-world


919
00:33:00,456 --> 00:33:02,776
usage of your scenario.


920
00:33:03,606 --> 00:33:05,156
Then you train the model.


921
00:33:05,536 --> 00:33:07,186
And finally evaluate it.


922
00:33:08,016 --> 00:33:10,406
And once you are happy, you just


923
00:33:10,476 --> 00:33:14,366
save it out.


924
00:33:14,636 --> 00:33:17,046
Create ML is in Swift.


925
00:33:17,406 --> 00:33:18,986
And it's available on macOS


926
00:33:18,986 --> 00:33:19,496
Mojave.


927
00:33:22,836 --> 00:33:24,396
You can use it in Xcode


928
00:33:24,396 --> 00:33:28,206
Playground, Swift Scripts and


929
00:33:28,206 --> 00:33:29,076
[inaudible].


930
00:33:29,076 --> 00:33:30,536
So please try it out.


931
00:33:32,326 --> 00:33:33,776
We would love to hear from you.


932
00:33:33,776 --> 00:33:35,546
We are here to receive your


933
00:33:35,546 --> 00:33:37,946
feedback, and we hope that you


934
00:33:37,946 --> 00:33:38,956
will love it as much as we do.


935
00:33:41,456 --> 00:33:43,146
We will be in the machine


936
00:33:43,146 --> 00:33:44,656
learning get together as well as


937
00:33:44,656 --> 00:33:45,146
the labs.


938
00:33:45,296 --> 00:33:46,276
So there is -- tomorrow there is


939
00:33:46,276 --> 00:33:46,946
a get together.


940
00:33:47,376 --> 00:33:49,046
We will be in labs also, so


941
00:33:49,046 --> 00:33:50,236
please give us your feedback.


942
00:33:51,346 --> 00:33:52,866
There are also related sessions


943
00:33:52,866 --> 00:33:53,986
in the WWDC App.


944
00:33:54,146 --> 00:33:56,626
We have Core ML session tomorrow


945
00:33:56,626 --> 00:34:00,346
morning and ML session tomorrow


946
00:34:00,346 --> 00:34:03,516
afternoon, Vision sessions on


947
00:34:05,216 --> 00:34:05,606
Thursday.


948
00:34:05,606 --> 00:34:08,186
And we have labs on Wednesday


949
00:34:08,186 --> 00:34:08,795
and Friday.


950
00:34:09,466 --> 00:34:09,786
Thank you.


951
00:34:10,516 --> 00:34:20,370
[ Applause ]

