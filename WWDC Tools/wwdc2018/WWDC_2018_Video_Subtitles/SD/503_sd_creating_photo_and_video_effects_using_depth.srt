1
00:00:07,516 --> 00:00:15,500
[ Music ]


2
00:00:18,516 --> 00:00:20,546
[ Applause ]


3
00:00:21,046 --> 00:00:23,856
>> Good morning, it's a pleasure


4
00:00:23,856 --> 00:00:24,676
to be here with you.


5
00:00:25,346 --> 00:00:26,386
My name is Emmanuel and I'm an


6
00:00:26,386 --> 00:00:27,476
engineer on the Core Image team.


7
00:00:28,586 --> 00:00:30,106
This morning we'll be looking at


8
00:00:30,206 --> 00:00:31,616
creating photo and video effects


9
00:00:31,866 --> 00:00:32,386
using depth.


10
00:00:32,866 --> 00:00:35,686
Let's get started.


11
00:00:37,036 --> 00:00:38,976
With iOS 11 we started


12
00:00:38,976 --> 00:00:40,726
delivering portrait depth data


13
00:00:40,726 --> 00:00:41,816
alongside your portrait still


14
00:00:41,816 --> 00:00:42,206
images.


15
00:00:43,516 --> 00:00:45,386
During last year's WWDC sessions


16
00:00:45,736 --> 00:00:46,746
we showed how you can leverage


17
00:00:46,746 --> 00:00:47,826
that depth data to achieve


18
00:00:47,826 --> 00:00:49,436
amazing effects, such as force


19
00:00:49,436 --> 00:00:51,446
perspective, simulated depth of


20
00:00:51,446 --> 00:00:52,996
field effects, as well as


21
00:00:52,996 --> 00:00:53,806
various foreground and


22
00:00:53,806 --> 00:00:55,286
background separation effects.


23
00:00:56,716 --> 00:00:57,806
This year we're extremely


24
00:00:57,806 --> 00:00:59,206
excited to announce that we're


25
00:00:59,206 --> 00:01:01,456
coming out with a new feature, a


26
00:01:01,656 --> 00:01:01,976
portrait matte.


27
00:01:06,046 --> 00:01:07,036
So during the first half of this


28
00:01:07,036 --> 00:01:08,616
session we'll be focusing on


29
00:01:08,616 --> 00:01:09,696
portrait still images and how


30
00:01:09,696 --> 00:01:11,166
you can apply really great


31
00:01:11,166 --> 00:01:11,896
effects on them.


32
00:01:12,956 --> 00:01:14,366
During the next half my


33
00:01:14,366 --> 00:01:15,446
colleague Ron over from video


34
00:01:15,446 --> 00:01:17,176
engineering will be focusing on


35
00:01:17,176 --> 00:01:18,426
using a TrueDepth camera to


36
00:01:18,426 --> 00:01:19,906
achieve real-time video effects.


37
00:01:21,936 --> 00:01:24,076
All right, let's take a look at


38
00:01:24,076 --> 00:01:26,636
the portrait segmentation API.


39
00:01:27,236 --> 00:01:28,436
So I mentioned a portrait matte,


40
00:01:28,436 --> 00:01:29,526
so what is a portrait matte?


41
00:01:29,526 --> 00:01:30,636
A portrait matte is a


42
00:01:30,636 --> 00:01:32,476
segmentation from foreground to


43
00:01:32,476 --> 00:01:33,856
background and what this means


44
00:01:33,856 --> 00:01:35,706
precisely is that you have a


45
00:01:35,706 --> 00:01:37,706
mask which is 1.0 in the


46
00:01:37,706 --> 00:01:40,576
foreground and 0.0 in the


47
00:01:40,576 --> 00:01:42,176
background and you get soft and


48
00:01:42,176 --> 00:01:42,976
continuous values in between.


49
00:01:47,046 --> 00:01:47,646
The portrait matte is of


50
00:01:47,646 --> 00:01:49,116
extremely high quality and is


51
00:01:49,116 --> 00:01:50,626
able to preserve fine details,


52
00:01:50,676 --> 00:01:52,666
such as curl and hair on the


53
00:01:52,666 --> 00:01:53,696
outline of your subject.


54
00:01:54,076 --> 00:01:55,446
This is amazing.


55
00:01:56,716 --> 00:01:59,646
The matte can be used to achieve


56
00:01:59,646 --> 00:02:01,666
great many effects, here is just


57
00:02:01,666 --> 00:02:03,556
one of them where we essentially


58
00:02:03,556 --> 00:02:04,916
do a foreground and background


59
00:02:04,916 --> 00:02:06,306
separation by darkening the


60
00:02:06,306 --> 00:02:06,866
background.


61
00:02:06,866 --> 00:02:08,466
But we're really putting this


62
00:02:08,466 --> 00:02:09,806
tool into your hands so that you


63
00:02:09,806 --> 00:02:12,256
can create amazing apps and new


64
00:02:12,256 --> 00:02:13,836
effects and delight your users.


65
00:02:15,836 --> 00:02:18,466
All right, so the portrait


66
00:02:18,466 --> 00:02:20,116
effects matte is coming to you


67
00:02:20,116 --> 00:02:21,326
with iOS 12.


68
00:02:22,056 --> 00:02:25,536
It is available for both the


69
00:02:25,536 --> 00:02:27,046
front and the rear facing


70
00:02:27,046 --> 00:02:27,476
camera.


71
00:02:28,056 --> 00:02:31,516
It is available to you with


72
00:02:31,516 --> 00:02:33,726
portrait still images and at the


73
00:02:33,726 --> 00:02:34,766
moment only when there are


74
00:02:34,766 --> 00:02:35,616
people in the scene.


75
00:02:37,426 --> 00:02:39,426
Note that the portrait matte is


76
00:02:39,426 --> 00:02:41,086
linearly encoded, so it's not


77
00:02:41,086 --> 00:02:42,306
gamma encoded and what you get


78
00:02:42,306 --> 00:02:43,346
is a grayscale buffer.


79
00:02:44,756 --> 00:02:46,966
And also there's no guarantee


80
00:02:46,966 --> 00:02:47,826
that you will be getting a


81
00:02:47,826 --> 00:02:49,036
portrait matte alongside your


82
00:02:49,036 --> 00:02:50,076
portrait still images, you


83
00:02:50,116 --> 00:02:51,516
always do get the depth data but


84
00:02:51,866 --> 00:02:53,316
you need to make sure to test


85
00:02:53,316 --> 00:02:54,196
for its existence.


86
00:02:54,516 --> 00:02:57,176
All right, let's take a look at


87
00:02:57,176 --> 00:02:58,666
the API and how we can actually


88
00:02:58,666 --> 00:03:00,126
load that data in.


89
00:03:00,586 --> 00:03:02,876
So ImageIO provides a low-level


90
00:03:02,876 --> 00:03:04,286
API that allows you to load


91
00:03:04,516 --> 00:03:05,466
portrait effects matte.


92
00:03:05,766 --> 00:03:08,456
So by calling CGImageSourceCopy


93
00:03:09,156 --> 00:03:10,426
there's a new key it can pass


94
00:03:10,706 --> 00:03:12,576
kCGImageAuxiliaryData


95
00:03:12,576 --> 00:03:13,806
TypePortraitEffectsMatte.


96
00:03:15,186 --> 00:03:16,046
And this call returns a


97
00:03:16,046 --> 00:03:17,206
dictionary containing three main


98
00:03:17,206 --> 00:03:18,216
pieces of information.


99
00:03:18,846 --> 00:03:20,426
The image data itself as a


100
00:03:20,426 --> 00:03:24,176
CFDataRef, metadata pertaining


101
00:03:24,176 --> 00:03:25,496
to the buffer itself as a


102
00:03:25,496 --> 00:03:28,096
CFDictionary, as well as


103
00:03:28,266 --> 00:03:30,236
metadata pertaining to the


104
00:03:30,236 --> 00:03:31,146
capture itself.


105
00:03:33,356 --> 00:03:35,056
AVFoundation also provides a


106
00:03:35,056 --> 00:03:36,386
higher-level API that sits on


107
00:03:36,386 --> 00:03:38,186
top of ImageIO that you can use.


108
00:03:38,986 --> 00:03:40,176
So taking the output from


109
00:03:40,176 --> 00:03:42,286
CGImageSourceCopy you can feed


110
00:03:42,286 --> 00:03:43,766
it to the AVPortrait effects


111
00:03:43,766 --> 00:03:43,976
matte class.


112
00:03:48,046 --> 00:03:49,656
And what you get out of it is


113
00:03:49,656 --> 00:03:51,326
very simple it's a CV pixel


114
00:03:51,326 --> 00:03:53,596
buffer along with pixel format


115
00:03:53,816 --> 00:03:54,946
type so you can use that CV


116
00:03:54,946 --> 00:03:56,626
pixel buffer for your further


117
00:03:56,626 --> 00:03:58,586
processing needs, it's really


118
00:03:59,006 --> 00:04:00,296
that simple.


119
00:04:01,106 --> 00:04:02,676
AVFoundation also supports


120
00:04:02,676 --> 00:04:04,236
portrait matte delivery at


121
00:04:04,236 --> 00:04:04,966
capture time.


122
00:04:05,516 --> 00:04:07,176
So starting with your typical


123
00:04:07,176 --> 00:04:08,956
AVFoundation setup with your


124
00:04:08,956 --> 00:04:11,296
AVCaptureInput, device, as well


125
00:04:11,296 --> 00:04:12,126
as capture session.


126
00:04:12,706 --> 00:04:14,386
The first thing you want to do


127
00:04:14,386 --> 00:04:15,436
is make sure that your


128
00:04:15,436 --> 00:04:16,495
environment supports the


129
00:04:16,495 --> 00:04:17,736
delivery of the portrait effects


130
00:04:17,736 --> 00:04:17,986
matte.


131
00:04:18,206 --> 00:04:20,286
To do this you'll be checking


132
00:04:20,286 --> 00:04:21,636
for is that data delivery


133
00:04:21,636 --> 00:04:23,036
supported, as well as is


134
00:04:23,036 --> 00:04:24,176
portrait effects matte delivery


135
00:04:24,176 --> 00:04:24,596
supported.


136
00:04:25,136 --> 00:04:26,406
The reason we have the two there


137
00:04:26,506 --> 00:04:27,636
both depth and portrait effects


138
00:04:27,636 --> 00:04:28,496
matte is that they come


139
00:04:28,496 --> 00:04:29,046
together.


140
00:04:29,636 --> 00:04:31,286
You can either opt in to get


141
00:04:31,286 --> 00:04:32,976
only the depth data, but


142
00:04:32,976 --> 00:04:34,026
whenever you want the portrait


143
00:04:34,026 --> 00:04:35,516
effects matte you also need to


144
00:04:35,516 --> 00:04:36,716
activate the depth data


145
00:04:36,716 --> 00:04:37,216
delivery.


146
00:04:38,126 --> 00:04:39,786
And to activate or to opt in for


147
00:04:39,786 --> 00:04:41,606
that delivery make sure to


148
00:04:41,606 --> 00:04:42,336
modify your


149
00:04:42,336 --> 00:04:44,146
AVCapturePhotoSettings and set


150
00:04:44,146 --> 00:04:45,336
the isPortraitEffects


151
00:04:45,336 --> 00:04:46,906
MatteDelivery enabled, as well


152
00:04:46,906 --> 00:04:48,806
as isDepthDataDeliveryEnabled to


153
00:04:49,756 --> 00:04:49,846
true.


154
00:04:50,806 --> 00:04:52,266
Then the capture time your


155
00:04:52,706 --> 00:04:53,776
ddiFinishProcessingPhoto


156
00:04:53,776 --> 00:04:55,086
callback will give you the


157
00:04:55,086 --> 00:04:57,346
portrait effects matte.


158
00:04:57,346 --> 00:04:59,316
It's really that simple.


159
00:05:00,256 --> 00:05:01,366
All right Core Image also


160
00:05:01,366 --> 00:05:02,986
provides you with a way to load


161
00:05:02,986 --> 00:05:04,406
and save your portrait effects


162
00:05:04,406 --> 00:05:04,626
matte.


163
00:05:05,546 --> 00:05:06,806
A new queue was introduced


164
00:05:06,926 --> 00:05:07,726
auxiliaryPortrait


165
00:05:07,726 --> 00:05:09,106
EffectsMatte which you just pass


166
00:05:09,106 --> 00:05:10,976
your image with contents of URL


167
00:05:11,536 --> 00:05:13,386
and you get a CI image back


168
00:05:13,386 --> 00:05:14,456
which contains the portrait


169
00:05:14,456 --> 00:05:14,776
effect.


170
00:05:19,046 --> 00:05:19,866
Core Image also allows you to


171
00:05:19,866 --> 00:05:21,636
save your portrait effects


172
00:05:21,636 --> 00:05:23,946
mattes directly into your files.


173
00:05:24,426 --> 00:05:26,526
To do this there's a new context


174
00:05:26,526 --> 00:05:27,326
option called


175
00:05:27,576 --> 00:05:29,506
portraitEffectsMatteImage, you


176
00:05:29,506 --> 00:05:30,876
pass in your CI image containing


177
00:05:30,876 --> 00:05:32,696
the portrait effects matte, and


178
00:05:32,696 --> 00:05:34,086
then you can write your file to


179
00:05:34,086 --> 00:05:35,246
disk using for example


180
00:05:35,246 --> 00:05:36,576
writeHEIFRepresntationOfImage.


181
00:05:37,196 --> 00:05:39,246
All right so one thing that's


182
00:05:39,246 --> 00:05:41,136
important to note here is that


183
00:05:41,416 --> 00:05:42,826
the three images, so your RGB,


184
00:05:42,826 --> 00:05:44,796
the depth buffer, and the


185
00:05:44,796 --> 00:05:47,116
portrait matte buffer live at a


186
00:05:47,116 --> 00:05:47,996
different resolution.


187
00:05:49,266 --> 00:05:50,426
So for example, the portrait


188
00:05:50,426 --> 00:05:51,876
matte for the rear facing camera


189
00:05:51,876 --> 00:05:53,866
is half-size and the depth data


190
00:05:53,866 --> 00:05:54,696
is even smaller.


191
00:05:55,526 --> 00:05:56,386
So let's look at the images


192
00:05:56,386 --> 00:05:57,616
side-by-side in the case of the


193
00:05:57,616 --> 00:05:58,516
rear facing camera.


194
00:05:59,786 --> 00:06:00,816
What this means that in your


195
00:06:00,816 --> 00:06:02,076
applications you need to make


196
00:06:02,076 --> 00:06:04,236
sure to either down-sample your


197
00:06:04,236 --> 00:06:06,076
RGB image to the size of your


198
00:06:06,076 --> 00:06:08,636
portrait depth or portrait matte


199
00:06:09,336 --> 00:06:11,086
or [inaudible] and sample them


200
00:06:11,086 --> 00:06:12,496
to the size of your RGB image.


201
00:06:13,256 --> 00:06:15,316
So that's all I wanted to talk


202
00:06:15,316 --> 00:06:16,286
about today for the portrait


203
00:06:16,286 --> 00:06:18,686
segmentation API and we have a


204
00:06:18,686 --> 00:06:20,626
great demo for you to see this


205
00:06:20,626 --> 00:06:21,226
live in action.


206
00:06:22,056 --> 00:06:24,986
So during this demo I'll be


207
00:06:24,986 --> 00:06:26,376
making use of a Jupiter Notebook


208
00:06:26,896 --> 00:06:28,276
which is a browser-based,


209
00:06:28,426 --> 00:06:30,816
real-time interpreter for


210
00:06:32,056 --> 00:06:32,436
Python.


211
00:06:33,306 --> 00:06:34,826
And we'll be making use of


212
00:06:34,886 --> 00:06:36,456
Python bindings for Core Image


213
00:06:36,546 --> 00:06:37,646
which we'll be introducing later


214
00:06:37,646 --> 00:06:38,976
today in a separate session.


215
00:06:45,056 --> 00:06:46,626
So let's start and load an image


216
00:06:46,626 --> 00:06:48,686
that contains portrait depth and


217
00:06:48,686 --> 00:06:49,706
portrait matte in.


218
00:06:50,016 --> 00:06:50,906
So this is the image we're going


219
00:06:50,906 --> 00:06:51,516
to be working with.


220
00:06:52,296 --> 00:06:54,956
The first thing I want to show


221
00:06:54,956 --> 00:06:56,796
you is what the depth data looks


222
00:06:56,796 --> 00:06:57,906
like for that image, so let's


223
00:06:57,906 --> 00:06:59,196
look at the two side-by-side.


224
00:06:59,296 --> 00:07:00,436
So we have the portrait depth on


225
00:07:00,436 --> 00:07:02,206
the left and the portrait matte


226
00:07:02,206 --> 00:07:03,046
on the right-hand side and you


227
00:07:03,046 --> 00:07:04,116
can just see how fine the


228
00:07:04,116 --> 00:07:04,796
details are.


229
00:07:05,366 --> 00:07:07,496
And we'll do a zoom crop in just


230
00:07:07,496 --> 00:07:09,896
a minute so that you can better


231
00:07:09,896 --> 00:07:12,126
appreciate just how high quality


232
00:07:12,126 --> 00:07:13,066
it is.


233
00:07:13,836 --> 00:07:15,686
Then next thing we do is we


234
00:07:15,686 --> 00:07:16,586
resize the images.


235
00:07:17,426 --> 00:07:18,966
As you see the RGB and the depth


236
00:07:18,966 --> 00:07:20,596
data vary greatly in size.


237
00:07:22,006 --> 00:07:23,516
So we resize our images and


238
00:07:23,516 --> 00:07:24,426
let's have a look at them


239
00:07:24,426 --> 00:07:25,126
side-by-side.


240
00:07:25,436 --> 00:07:26,686
So we have our RGB and our depth


241
00:07:26,686 --> 00:07:27,536
data on the right-hand side.


242
00:07:27,946 --> 00:07:29,076
During the first part of this


243
00:07:29,076 --> 00:07:30,876
demo I'll focus on depth data,


244
00:07:31,326 --> 00:07:32,806
then we'll see how things get


245
00:07:32,806 --> 00:07:33,946
much, much simpler when you use


246
00:07:33,946 --> 00:07:34,846
a portrait effects matte.


247
00:07:35,596 --> 00:07:37,806
So the effect I'm going to be


248
00:07:37,806 --> 00:07:39,296
working on today is depth


249
00:07:39,296 --> 00:07:41,346
thresholding and essentially


250
00:07:41,346 --> 00:07:42,426
what I'll be doing is computing


251
00:07:42,426 --> 00:07:43,576
a histogram of the gray level


252
00:07:43,576 --> 00:07:45,316
values in my portrait depth.


253
00:07:45,316 --> 00:07:47,596
And I'll be applying a threshold


254
00:07:47,596 --> 00:07:48,536
or a clipping point in that


255
00:07:48,536 --> 00:07:49,636
histogram so that everything


256
00:07:49,636 --> 00:07:51,516
becomes zero or one depending if


257
00:07:51,516 --> 00:07:52,986
it's sitting below or above that


258
00:07:52,986 --> 00:07:53,426
threshold.


259
00:07:54,346 --> 00:07:55,886
Then we'll be closing holes in


260
00:07:55,886 --> 00:07:57,336
the image by using morphological


261
00:07:57,336 --> 00:07:59,116
closing operations and then


262
00:07:59,116 --> 00:08:01,386
blurring the mask so that we get


263
00:08:01,386 --> 00:08:03,006
a nice feathered look.


264
00:08:03,766 --> 00:08:05,126
Let's have a look at this in


265
00:08:05,126 --> 00:08:05,456
action.


266
00:08:06,486 --> 00:08:07,456
So remember all of this is


267
00:08:07,456 --> 00:08:09,966
executed live in the browser


268
00:08:09,966 --> 00:08:11,396
using Core Image as a back end.


269
00:08:11,866 --> 00:08:13,836
All right so the first thing I


270
00:08:13,836 --> 00:08:15,356
want to show you is how changing


271
00:08:15,356 --> 00:08:16,836
percentile point changes my mask


272
00:08:16,836 --> 00:08:17,036
here.


273
00:08:17,286 --> 00:08:19,216
So the higher it is the less


274
00:08:19,216 --> 00:08:20,496
aggressive I am on clipping the


275
00:08:20,496 --> 00:08:21,026
foreground.


276
00:08:21,276 --> 00:08:22,316
So let's pick a value that's


277
00:08:22,316 --> 00:08:24,016
reasonable, maybe something like


278
00:08:24,016 --> 00:08:24,466
this here.


279
00:08:25,226 --> 00:08:26,556
And what you can see here is


280
00:08:26,556 --> 00:08:28,246
that there are regions or


281
00:08:28,246 --> 00:08:29,376
islands we call them that are


282
00:08:29,716 --> 00:08:31,226
connected to my foreground and


283
00:08:31,226 --> 00:08:32,176
there's a bit of the subject


284
00:08:32,176 --> 00:08:33,086
here I'd like to take out.


285
00:08:33,296 --> 00:08:35,086
So what I'll do is I'll add a


286
00:08:35,086 --> 00:08:36,446
bit of morphological closing.


287
00:08:36,926 --> 00:08:38,385
Look at how this appears


288
00:08:38,385 --> 00:08:38,936
magically.


289
00:08:38,976 --> 00:08:40,885
If I go too far obviously I lose


290
00:08:40,885 --> 00:08:41,956
my entire subjects, I don't want


291
00:08:41,956 --> 00:08:42,265
to do that.


292
00:08:43,066 --> 00:08:43,866
So let's pick something like


293
00:08:43,866 --> 00:08:44,226
this.


294
00:08:44,916 --> 00:08:46,576
What I can do then is change the


295
00:08:46,576 --> 00:08:47,876
feathering by applying the mask


296
00:08:47,876 --> 00:08:48,556
on top of it all.


297
00:08:49,196 --> 00:08:50,306
Let's take a look at how the RGB


298
00:08:50,306 --> 00:08:51,266
is threshold in back.


299
00:08:51,686 --> 00:08:52,906
This is not the effect we're


300
00:08:52,906 --> 00:08:54,176
coming up it's just to give a


301
00:08:54,176 --> 00:08:55,166
sense of how the mask is


302
00:08:55,166 --> 00:08:56,306
applied, so let's keep going.


303
00:08:57,186 --> 00:08:59,206
So I've chosen a few parameters


304
00:08:59,206 --> 00:09:01,746
for this thresholding here and


305
00:09:01,906 --> 00:09:02,676
this is what I'll be using for


306
00:09:02,676 --> 00:09:02,976
my foreground.


307
00:09:07,256 --> 00:09:09,416
Next, I'm applying an effect


308
00:09:09,416 --> 00:09:10,536
only on my foreground, so in


309
00:09:10,536 --> 00:09:11,546
this particular case I'm using


310
00:09:11,546 --> 00:09:12,936
the Core Image photo effect Noir


311
00:09:13,056 --> 00:09:14,396
which turns everything grayscale


312
00:09:14,396 --> 00:09:15,556
and has a has a bit of contrast.


313
00:09:16,186 --> 00:09:17,206
I'm doing an exposure


314
00:09:17,206 --> 00:09:19,816
adjustment, as well as


315
00:09:19,846 --> 00:09:21,156
desaturating my image slightly


316
00:09:21,156 --> 00:09:22,766
and augmenting the contrast even


317
00:09:22,766 --> 00:09:23,196
further.


318
00:09:23,936 --> 00:09:24,896
Let's take a look at the output.


319
00:09:24,896 --> 00:09:25,716
This is going to be the


320
00:09:25,716 --> 00:09:26,826
foreground that I'll be using


321
00:09:27,336 --> 00:09:28,936
and what I want to do here is


322
00:09:29,016 --> 00:09:32,016
leverage the depth data mask


323
00:09:32,016 --> 00:09:33,756
that I have to composite this


324
00:09:33,756 --> 00:09:35,446
foreground onto a background.


325
00:09:36,496 --> 00:09:37,866
Let's just generate a background


326
00:09:37,866 --> 00:09:39,276
which is just a darker version


327
00:09:39,396 --> 00:09:40,236
of the original image.


328
00:09:40,766 --> 00:09:43,816
We can then composite the two


329
00:09:43,816 --> 00:09:45,146
together using the Core Image


330
00:09:45,146 --> 00:09:48,956
filter blendWithMask and we have


331
00:09:48,956 --> 00:09:50,186
the result right there, it's


332
00:09:50,186 --> 00:09:50,726
that simple.


333
00:09:51,386 --> 00:09:52,866
All right.


334
00:09:52,866 --> 00:09:54,936
Thank you.


335
00:09:55,516 --> 00:09:58,716
[ Applause ]


336
00:09:59,216 --> 00:10:02,076
Okay so as you saw that required


337
00:10:02,076 --> 00:10:02,926
a bit of fiddling with the


338
00:10:02,926 --> 00:10:04,096
parameters for clipping, for


339
00:10:04,096 --> 00:10:05,666
smoothing, and then so on and so


340
00:10:05,666 --> 00:10:06,096
forth.


341
00:10:06,356 --> 00:10:07,366
The portrait effects matte


342
00:10:07,526 --> 00:10:10,406
enables you to do this without


343
00:10:10,406 --> 00:10:11,666
actually doing much process,


344
00:10:11,666 --> 00:10:12,816
this is really exciting so let's


345
00:10:12,816 --> 00:10:13,386
have a look at this.


346
00:10:13,666 --> 00:10:15,506
So here we're starting with


347
00:10:15,506 --> 00:10:19,086
another image that also has


348
00:10:19,086 --> 00:10:20,646
portrait depth and portrait


349
00:10:20,646 --> 00:10:22,386
matte information embedded into


350
00:10:22,386 --> 00:10:23,486
it, so let's look at these.


351
00:10:25,066 --> 00:10:27,056
As I mentioned earlier, this is


352
00:10:27,056 --> 00:10:28,846
an extremely high-quality


353
00:10:28,956 --> 00:10:29,666
foreground mask.


354
00:10:29,666 --> 00:10:31,056
So let's have a look at a crop


355
00:10:31,056 --> 00:10:33,376
on this hair.


356
00:10:33,976 --> 00:10:36,846
Look at how fine the detail is,


357
00:10:36,846 --> 00:10:37,456
this is beautiful.


358
00:10:37,626 --> 00:10:38,526
On the right-hand side here is


359
00:10:38,526 --> 00:10:39,676
the depth that it shows you just


360
00:10:39,676 --> 00:10:42,436
how coarse the depth data is


361
00:10:42,436 --> 00:10:43,586
compared to effect matte.


362
00:10:44,376 --> 00:10:46,036
So we'll do another foreground


363
00:10:46,036 --> 00:10:47,886
separation effect here similarly


364
00:10:47,886 --> 00:10:49,016
to what we just did but we used


365
00:10:49,016 --> 00:10:49,956
a portrait matte instead of


366
00:10:49,956 --> 00:10:50,816
using the portrait depth.


367
00:10:51,386 --> 00:10:53,736
So let's look at our foreground


368
00:10:53,736 --> 00:10:55,606
similar as before but in this


369
00:10:55,606 --> 00:10:56,656
case, we'll desaturate the


370
00:10:56,656 --> 00:10:57,856
foreground slightly, add a bit


371
00:10:57,856 --> 00:10:59,746
of contrast, as well as some


372
00:10:59,746 --> 00:11:02,666
vibrance to the image.


373
00:11:03,406 --> 00:11:04,706
Now let's generate a background,


374
00:11:04,706 --> 00:11:06,006
in this case we'll do a disk


375
00:11:06,006 --> 00:11:07,236
blur which is another Core Image


376
00:11:07,236 --> 00:11:08,836
filter, as well as bring down


377
00:11:08,836 --> 00:11:09,996
the exposure so things get


378
00:11:09,996 --> 00:11:10,746
pretty dark.


379
00:11:10,746 --> 00:11:12,356
But we still get a bit of


380
00:11:12,356 --> 00:11:13,386
background remaining, it's quite


381
00:11:13,386 --> 00:11:14,386
faint but it's still there.


382
00:11:15,446 --> 00:11:17,826
And again, I use a CI blend with


383
00:11:17,826 --> 00:11:19,216
mask which is going to do the


384
00:11:19,216 --> 00:11:20,716
compositing for us with the mask


385
00:11:21,316 --> 00:11:22,216
and we have left and right.


386
00:11:22,526 --> 00:11:23,776
Isn't this beautiful?


387
00:11:24,516 --> 00:11:27,556
[ Applause ]


388
00:11:28,056 --> 00:11:29,276
Thank you.


389
00:11:29,436 --> 00:11:30,476
All right let's look at another


390
00:11:30,476 --> 00:11:32,106
great demo which we call Big


391
00:11:32,106 --> 00:11:32,386
Head.


392
00:11:32,946 --> 00:11:36,326
So because the portrait matte is


393
00:11:36,326 --> 00:11:37,806
so fine we can actually do


394
00:11:37,806 --> 00:11:39,306
things like change the


395
00:11:39,306 --> 00:11:40,496
[inaudible] size of our subject


396
00:11:40,496 --> 00:11:41,606
with respect to the background


397
00:11:41,606 --> 00:11:41,966
using it.


398
00:11:42,216 --> 00:11:44,506
So let's do just that and we'll


399
00:11:44,506 --> 00:11:45,006
do it live.


400
00:11:46,096 --> 00:11:48,536
So here's our input image on the


401
00:11:48,536 --> 00:11:50,416
left here and the portrait matte


402
00:11:50,416 --> 00:11:52,786
on the right-hand side.


403
00:11:52,966 --> 00:11:55,056
And what I'll be doing here as


404
00:11:55,056 --> 00:11:57,146
I'll be playing with the size of


405
00:11:57,146 --> 00:11:59,616
the subject in my frame notice


406
00:11:59,616 --> 00:12:01,296
how the subject is getting


407
00:12:01,626 --> 00:12:02,416
smaller and bigger.


408
00:12:03,176 --> 00:12:04,946
And you can actually you know


409
00:12:05,956 --> 00:12:07,096
give more weight to the subject


410
00:12:07,096 --> 00:12:09,046
in your frame, but you can also


411
00:12:09,046 --> 00:12:11,106
do pretty cool things like now


412
00:12:11,106 --> 00:12:12,456
that I have this let's say that


413
00:12:12,456 --> 00:12:14,966
I pick my favorite size here.


414
00:12:14,966 --> 00:12:17,436
You can do things like pseudo


415
00:12:17,436 --> 00:12:19,346
simulated depth of field here by


416
00:12:19,346 --> 00:12:20,276
giving more contrast to the


417
00:12:20,276 --> 00:12:22,076
foreground and using a


418
00:12:22,076 --> 00:12:22,916
[inaudible] in the background to


419
00:12:22,916 --> 00:12:24,136
give more pop to your subject.


420
00:12:26,296 --> 00:12:28,006
All right let's take a look at


421
00:12:28,006 --> 00:12:29,346
just another image to see just


422
00:12:29,346 --> 00:12:30,506
how easy that is because they're


423
00:12:30,506 --> 00:12:32,226
using the exact same pipeline


424
00:12:32,226 --> 00:12:33,176
under the hood which is very


425
00:12:33,176 --> 00:12:34,486
simple just using the portrait


426
00:12:34,536 --> 00:12:36,376
matte and using it to blur the


427
00:12:36,376 --> 00:12:38,856
foreground and background.


428
00:12:38,856 --> 00:12:40,096
Again our input image here, we


429
00:12:40,096 --> 00:12:42,586
can change the size of it, make


430
00:12:42,586 --> 00:12:44,966
it bigger, then apply a bit of


431
00:12:45,006 --> 00:12:47,156
contrast to give more focus to


432
00:12:47,156 --> 00:12:47,736
our subject.


433
00:12:48,706 --> 00:12:49,976
It's that easy, really exciting.


434
00:12:50,516 --> 00:12:55,216
[ Applause ]


435
00:12:55,716 --> 00:12:57,186
All right let's take a look at


436
00:12:57,186 --> 00:12:58,296
another demo which we call


437
00:12:58,296 --> 00:12:58,956
Marching.


438
00:12:59,226 --> 00:13:01,226
I'm not even going to try to


439
00:13:01,226 --> 00:13:02,976
explain what it does, let's just


440
00:13:02,976 --> 00:13:04,476
take a look at the filter in


441
00:13:04,476 --> 00:13:04,816
action.


442
00:13:10,046 --> 00:13:12,516
There you go, fun stuff and just


443
00:13:12,516 --> 00:13:14,236
because we can do it I can


444
00:13:14,236 --> 00:13:15,696
expose how many of these I want


445
00:13:15,696 --> 00:13:16,406
to stitch together.


446
00:13:16,406 --> 00:13:18,726
So going from just a few to you


447
00:13:18,726 --> 00:13:19,926
really, really pushing that way,


448
00:13:19,926 --> 00:13:20,526
way too far.


449
00:13:21,966 --> 00:13:23,046
Really exciting stuff.


450
00:13:23,456 --> 00:13:23,926
All right.


451
00:13:29,046 --> 00:13:31,506
So that's it for this demo, I


452
00:13:31,506 --> 00:13:32,356
hope you enjoyed this.


453
00:13:33,966 --> 00:13:35,606
So if you'd like to know more


454
00:13:35,606 --> 00:13:36,956
about using Python bindings for


455
00:13:36,956 --> 00:13:38,126
Core Image I encourage you to


456
00:13:38,126 --> 00:13:39,426
come to this afternoon's session


457
00:13:39,796 --> 00:13:40,906
on Core Image Performance


458
00:13:40,906 --> 00:13:42,066
Prototyping in Python.


459
00:13:42,686 --> 00:13:45,616
That's all for me today, let me


460
00:13:45,616 --> 00:13:46,736
introduce you to my colleague


461
00:13:46,736 --> 00:13:48,266
Ron from video engineering who


462
00:13:48,266 --> 00:13:49,676
will be talking about real-time


463
00:13:49,676 --> 00:13:51,046
video effects with TrueDepth.


464
00:13:51,346 --> 00:13:51,976
Thank you everybody.


465
00:13:52,516 --> 00:13:56,500
[ Applause ]


466
00:13:59,286 --> 00:14:00,046
>> Thank you Emmanuel.


467
00:14:01,186 --> 00:14:02,826
Great photo effects but what


468
00:14:02,826 --> 00:14:03,456
about video.


469
00:14:04,866 --> 00:14:06,926
My name is Ron Sokolovsky and I


470
00:14:06,926 --> 00:14:07,916
am from video engineering.


471
00:14:08,476 --> 00:14:11,946
In this part we are going to


472
00:14:11,946 --> 00:14:13,236
leverage the TrueDepth's camera


473
00:14:13,446 --> 00:14:15,576
to create similar effects with


474
00:14:15,576 --> 00:14:17,636
real-time video, like for


475
00:14:17,636 --> 00:14:19,226
example this background


476
00:14:19,226 --> 00:14:20,426
replacement app.


477
00:14:21,856 --> 00:14:24,556
In order to create such effects


478
00:14:24,836 --> 00:14:26,486
we are going to deep dive into


479
00:14:26,486 --> 00:14:27,776
the stream coming from the


480
00:14:27,776 --> 00:14:29,306
TrueDepth camera, the


481
00:14:29,306 --> 00:14:31,336
characteristics, best practices,


482
00:14:31,336 --> 00:14:32,066
and challenges.


483
00:14:32,636 --> 00:14:35,316
We are also going to show you


484
00:14:35,316 --> 00:14:36,706
how to work with point clouds, a


485
00:14:36,706 --> 00:14:38,286
completely different way to


486
00:14:38,286 --> 00:14:40,006
process and render rich depth


487
00:14:40,006 --> 00:14:40,546
information.


488
00:14:41,056 --> 00:14:42,626
And that background replacement


489
00:14:42,846 --> 00:14:44,116
app we're calling it Backdrop


490
00:14:44,476 --> 00:14:45,516
and we'll show you how to make


491
00:14:45,516 --> 00:14:46,756
it step-by-step.


492
00:14:48,336 --> 00:14:50,116
But first things first, the


493
00:14:50,386 --> 00:14:51,446
stream for the TrueDepth's


494
00:14:51,446 --> 00:14:53,396
camera is made of frames, each


495
00:14:53,396 --> 00:14:55,326
frame is a depth map, a 2-D


496
00:14:55,326 --> 00:14:57,186
image in which each pixel


497
00:14:57,426 --> 00:14:58,926
contains the depth information


498
00:14:59,236 --> 00:15:00,526
or the distance to the scene in


499
00:15:00,526 --> 00:15:00,976
that direction.


500
00:15:05,046 --> 00:15:06,296
We've chosen a specific coloring


501
00:15:06,296 --> 00:15:08,466
scheme, closed pixels are


502
00:15:08,466 --> 00:15:11,056
colored in red while fire red


503
00:15:11,056 --> 00:15:12,306
pixels are colored in blue.


504
00:15:12,886 --> 00:15:14,216
In between them there is a


505
00:15:14,216 --> 00:15:16,426
colorful spectrum so you can see


506
00:15:16,776 --> 00:15:18,566
the texture of the depth map.


507
00:15:20,156 --> 00:15:21,686
There are also black pixels,


508
00:15:22,156 --> 00:15:23,636
those are holes in a depth map.


509
00:15:24,286 --> 00:15:25,946
For those pixels we have no


510
00:15:25,946 --> 00:15:27,596
information what is the depth.


511
00:15:28,456 --> 00:15:30,796
We are releasing today a new


512
00:15:30,796 --> 00:15:32,936
tool, a sample app for you to


513
00:15:32,936 --> 00:15:34,676
explore this stream and we call


514
00:15:34,676 --> 00:15:36,526
it TrueDepth Streamer.


515
00:15:37,076 --> 00:15:40,716
You can slide between the video


516
00:15:40,716 --> 00:15:42,976
stream and the TrueDepth stream.


517
00:15:47,046 --> 00:15:48,716
Now because the TrueDepth camera


518
00:15:49,456 --> 00:15:51,936
has active illumination even in


519
00:15:51,936 --> 00:15:53,676
complete darkness while the


520
00:15:53,676 --> 00:15:56,966
video is pitch black it is


521
00:15:56,966 --> 00:15:58,186
business as usual for the


522
00:15:58,186 --> 00:15:59,026
TrueDepth camera.


523
00:16:01,716 --> 00:16:04,636
So now you see me and now you


524
00:16:04,636 --> 00:16:04,906
don't.


525
00:16:05,516 --> 00:16:09,266
[ Applause ]


526
00:16:09,766 --> 00:16:11,666
So how do you add the stream


527
00:16:11,666 --> 00:16:12,896
from the TrueDepth camera into


528
00:16:12,896 --> 00:16:13,986
your application?


529
00:16:14,946 --> 00:16:15,906
Well I'm glad you asked.


530
00:16:16,276 --> 00:16:17,526
The first thing you need to do


531
00:16:17,986 --> 00:16:19,346
is to discover the built-in


532
00:16:19,346 --> 00:16:22,146
TrueDepth camera and then you


533
00:16:22,146 --> 00:16:23,866
initialize the device capture


534
00:16:23,866 --> 00:16:24,186
input.


535
00:16:24,186 --> 00:16:27,416
And you add the depth data


536
00:16:27,416 --> 00:16:28,766
output into your session.


537
00:16:29,606 --> 00:16:31,426
At this point you're good to go,


538
00:16:31,496 --> 00:16:32,826
you can start the session and


539
00:16:32,826 --> 00:16:33,706
you will have the TrueDepth


540
00:16:33,706 --> 00:16:35,266
stream with your session.


541
00:16:37,376 --> 00:16:39,286
This stream can come in two


542
00:16:39,286 --> 00:16:41,836
forms of data, disparity or


543
00:16:41,836 --> 00:16:42,166
depth.


544
00:16:42,846 --> 00:16:44,306
Now disparity is the inverse of


545
00:16:44,306 --> 00:16:46,586
depth and vice versa, so which


546
00:16:46,586 --> 00:16:47,396
one should you choose?


547
00:16:48,666 --> 00:16:51,366
Well disparity usually yields


548
00:16:51,366 --> 00:16:53,456
better results, especially for


549
00:16:53,456 --> 00:16:54,596
machine learning applications


550
00:16:55,216 --> 00:16:56,646
but the depth data has more


551
00:16:56,646 --> 00:16:58,346
meaning in terms of real-world


552
00:16:58,346 --> 00:16:58,926
measurements.


553
00:17:00,036 --> 00:17:01,666
Know that if you work with depth


554
00:17:01,746 --> 00:17:05,246
that the depth error goes with


555
00:17:05,246 --> 00:17:05,935
the depth squared.


556
00:17:06,036 --> 00:17:08,096
That means that an object at 1


557
00:17:08,096 --> 00:17:09,685
meter would have four times the


558
00:17:09,685 --> 00:17:11,826
depth accuracy as an object at 2


559
00:17:11,826 --> 00:17:11,976
meters.


560
00:17:16,286 --> 00:17:18,496
We have two streams, video and


561
00:17:18,496 --> 00:17:19,425
depth, and they don't


562
00:17:19,425 --> 00:17:20,596
necessarily share the same


563
00:17:20,596 --> 00:17:21,136
resolution.


564
00:17:21,646 --> 00:17:23,006
The native resolution of the


565
00:17:23,006 --> 00:17:24,596
TrueDepth's camera is VGA or


566
00:17:24,596 --> 00:17:27,736
640x480 and that's what you'll


567
00:17:27,736 --> 00:17:30,176
get if you choose a video preset


568
00:17:30,656 --> 00:17:32,236
of an aspect racial of 4:3.


569
00:17:33,226 --> 00:17:35,516
If however you choose an aspect


570
00:17:35,516 --> 00:17:37,816
ratio of 16x9 you'll get a depth


571
00:17:37,816 --> 00:17:40,246
map of 640x360.


572
00:17:40,966 --> 00:17:42,916
In both cases the depth map will


573
00:17:42,916 --> 00:17:44,856
cover the entire field of view


574
00:17:45,146 --> 00:17:46,146
of the RGB image.


575
00:17:46,666 --> 00:17:49,466
Now we are talking about video


576
00:17:49,466 --> 00:17:51,116
applications, so we are


577
00:17:51,116 --> 00:17:52,946
crunching a lot of numbers very,


578
00:17:52,946 --> 00:17:54,956
very fast and that could create


579
00:17:55,306 --> 00:17:57,266
system pressure over time.


580
00:17:57,936 --> 00:17:59,696
So you can test your application


581
00:17:59,696 --> 00:18:01,306
and gauge the system pressure


582
00:18:01,306 --> 00:18:04,006
level which goes from nominal to


583
00:18:04,006 --> 00:18:06,216
fair, serious, critical, and


584
00:18:06,216 --> 00:18:07,056
then shutdown.


585
00:18:07,476 --> 00:18:08,956
And the responsibility is in


586
00:18:08,956 --> 00:18:10,886
your hands because the system


587
00:18:11,166 --> 00:18:12,326
will let you go all the way to


588
00:18:12,326 --> 00:18:15,206
shutdown but when it does it's


589
00:18:15,206 --> 00:18:17,326
bye-bye every capture device.


590
00:18:17,726 --> 00:18:22,026
Another thing you can do is to


591
00:18:22,026 --> 00:18:24,006
adopt a degradation scheme, if


592
00:18:24,006 --> 00:18:25,496
the pressure level gets serious


593
00:18:25,496 --> 00:18:27,206
you can reduce the frame rate to


594
00:18:27,206 --> 00:18:29,736
15 frames per second or you can


595
00:18:29,736 --> 00:18:31,516
choose a more elaborate scheme


596
00:18:31,896 --> 00:18:33,966
with gentle degradation going


597
00:18:33,966 --> 00:18:37,356
from 30, 24, 20 and 15 frames


598
00:18:37,356 --> 00:18:39,536
per second anytime the pressure


599
00:18:39,536 --> 00:18:39,976
level increases.


600
00:18:43,836 --> 00:18:45,026
So we have holes in the depth


601
00:18:45,026 --> 00:18:46,406
map what can we do about it?


602
00:18:47,686 --> 00:18:49,456
Well, in fact you could get the


603
00:18:49,456 --> 00:18:51,496
stream already filtered for you.


604
00:18:52,176 --> 00:18:53,936
There is a parameter called


605
00:18:53,936 --> 00:18:55,546
isFilteringEnabled and it's'


606
00:18:55,546 --> 00:18:57,676
defaulted to true, which means


607
00:18:57,676 --> 00:18:59,236
you get a filtered depth map


608
00:18:59,606 --> 00:19:01,576
smooth, spatially and temporally


609
00:19:01,776 --> 00:19:03,536
and the holes are filled from


610
00:19:03,536 --> 00:19:04,356
the RGB image.


611
00:19:05,466 --> 00:19:07,256
This is especially useful for


612
00:19:07,256 --> 00:19:08,616
photography and segmentation


613
00:19:08,616 --> 00:19:10,206
applications because you know


614
00:19:10,446 --> 00:19:12,386
every time you query a pixel you


615
00:19:12,386 --> 00:19:13,216
get the depth's value.


616
00:19:13,776 --> 00:19:17,376
In TrueDepth Streamer you can


617
00:19:17,376 --> 00:19:19,566
switch to the filter stream and


618
00:19:19,566 --> 00:19:21,876
see that it is smoother and the


619
00:19:21,876 --> 00:19:22,586
holes are filled.


620
00:19:23,126 --> 00:19:27,526
So this is great, but it is not


621
00:19:27,526 --> 00:19:29,246
applicable to 100% of the use


622
00:19:29,246 --> 00:19:29,636
cases.


623
00:19:30,226 --> 00:19:31,676
If you're working with point


624
00:19:31,676 --> 00:19:34,606
clouds or any type of real-world


625
00:19:34,836 --> 00:19:36,256
measurements you're better off


626
00:19:36,256 --> 00:19:38,366
staying with the raw data which


627
00:19:38,366 --> 00:19:39,806
holds the highest fidelity.


628
00:19:40,846 --> 00:19:42,726
If you do you will have holes,


629
00:19:42,906 --> 00:19:44,496
you will have pixels marked as


630
00:19:44,496 --> 00:19:46,866
zero, it does not mean that they


631
00:19:46,866 --> 00:19:48,396
are the distance of zero meters


632
00:19:48,396 --> 00:19:50,356
from the camera it just means we


633
00:19:50,356 --> 00:19:52,296
have no information about them.


634
00:19:53,336 --> 00:19:54,946
Therefore, you should watch out


635
00:19:55,116 --> 00:19:56,506
for operations like averaging


636
00:19:56,506 --> 00:19:57,606
and downsampling because you


637
00:19:57,606 --> 00:19:59,386
don't want to mix those real


638
00:19:59,386 --> 00:20:00,976
values with those zeros.


639
00:20:03,756 --> 00:20:04,996
But why do we even get holes?


640
00:20:05,536 --> 00:20:08,876
Well the TrueDepth camera


641
00:20:09,296 --> 00:20:11,456
detects objects up to a distance


642
00:20:11,456 --> 00:20:14,056
of about 5 meters, but not all


643
00:20:14,056 --> 00:20:15,296
materials are made the same.


644
00:20:15,636 --> 00:20:16,796
Some materials have low


645
00:20:16,796 --> 00:20:17,496
reflectivity.


646
00:20:17,716 --> 00:20:20,126
they absorb most of the lights.


647
00:20:21,476 --> 00:20:23,656
For example this extreme


648
00:20:23,706 --> 00:20:26,046
scenario is a very low


649
00:20:26,046 --> 00:20:27,896
reflective fabric watch what


650
00:20:27,896 --> 00:20:29,686
happens when we switch to the


651
00:20:29,686 --> 00:20:31,766
depth map and I walk away from


652
00:20:33,346 --> 00:20:33,436
it.


653
00:20:33,696 --> 00:20:35,066
Even though there are objects in


654
00:20:35,066 --> 00:20:37,466
the scene with larger distance


655
00:20:37,796 --> 00:20:39,866
we see holes forming on this


656
00:20:39,866 --> 00:20:41,436
fabric because it's absorbing


657
00:20:42,026 --> 00:20:42,766
most of the light.


658
00:20:44,126 --> 00:20:45,446
If we switch to the filtered


659
00:20:45,446 --> 00:20:47,616
stream and repeat the same


660
00:20:47,616 --> 00:20:49,246
motion those holes are filled.


661
00:20:49,786 --> 00:20:53,336
But it's not only about the


662
00:20:53,336 --> 00:20:54,766
amount of light reflected back


663
00:20:55,326 --> 00:20:56,916
it's also about the direction in


664
00:20:56,916 --> 00:20:58,056
which it is reflected to.


665
00:20:59,116 --> 00:21:01,036
Some materials are specular or


666
00:21:01,036 --> 00:21:02,826
shiny and they are very picky


667
00:21:02,826 --> 00:21:04,166
and choosy in which direction


668
00:21:04,166 --> 00:21:05,046
they send back the light.


669
00:21:05,656 --> 00:21:08,406
An extreme scenario would be


670
00:21:08,406 --> 00:21:11,816
this display, you can watch the


671
00:21:11,816 --> 00:21:12,846
video stream to see the


672
00:21:12,846 --> 00:21:13,436
reflection.


673
00:21:14,616 --> 00:21:15,746
And when we switch to the depth


674
00:21:15,746 --> 00:21:18,366
map holes are forming depending


675
00:21:18,366 --> 00:21:19,746
on the angle between the device


676
00:21:19,746 --> 00:21:20,246
and the screen.


677
00:21:21,556 --> 00:21:23,376
And if we switch to the filtered


678
00:21:23,376 --> 00:21:25,216
stream those holes are filled


679
00:21:25,666 --> 00:21:26,976
but with less fidelity.


680
00:21:31,046 --> 00:21:32,916
Another challenging scenario is


681
00:21:32,916 --> 00:21:35,306
outdoor, typically in an outdoor


682
00:21:35,306 --> 00:21:36,996
scene the background is very far


683
00:21:36,996 --> 00:21:38,736
away so we don't expect to get


684
00:21:38,736 --> 00:21:39,806
any depth on the background.


685
00:21:40,456 --> 00:21:42,956
Also, the sun acts as an


686
00:21:42,956 --> 00:21:44,396
aggressor to the active


687
00:21:44,396 --> 00:21:44,906
illumination.


688
00:21:45,496 --> 00:21:48,696
To demonstrate that I went


689
00:21:48,696 --> 00:21:50,006
outside on a very sunny


690
00:21:50,006 --> 00:21:51,556
afternoon, positioned myself


691
00:21:51,556 --> 00:21:52,326
against the sun.


692
00:21:53,216 --> 00:21:54,286
And when we switch to the depth


693
00:21:54,286 --> 00:21:55,926
map you can see there's no


694
00:21:55,926 --> 00:21:58,056
depths on the background and we


695
00:21:58,056 --> 00:21:59,786
get some holes around the


696
00:21:59,786 --> 00:22:01,726
frames, specifically in this


697
00:22:01,726 --> 00:22:02,506
case the hair.


698
00:22:03,476 --> 00:22:05,556
But still most of the depth on


699
00:22:05,556 --> 00:22:07,126
the foreground is intact and


700
00:22:07,126 --> 00:22:07,696
very useful.


701
00:22:08,256 --> 00:22:12,436
One final point I want to cover


702
00:22:12,596 --> 00:22:14,616
for getting holes is the fact


703
00:22:14,616 --> 00:22:15,736
that from the perspective of the


704
00:22:15,736 --> 00:22:17,516
TrueDepth camera some of the


705
00:22:17,516 --> 00:22:19,396
light projected hits an object


706
00:22:19,396 --> 00:22:21,306
on the way back so we get


707
00:22:21,306 --> 00:22:23,006
shadows from the parallax


708
00:22:23,006 --> 00:22:24,886
between the projector and the


709
00:22:25,776 --> 00:22:26,096
camera.


710
00:22:26,096 --> 00:22:27,316
You can see an example on the


711
00:22:27,316 --> 00:22:29,266
right side of this mug, but


712
00:22:30,176 --> 00:22:31,576
something is different here.


713
00:22:32,676 --> 00:22:34,426
This is not a depth map so why


714
00:22:34,426 --> 00:22:36,916
do we even get holes?


715
00:22:37,096 --> 00:22:38,586
Well in TrueDepth Streamer you


716
00:22:38,586 --> 00:22:41,076
can switch from 2-D mode into


717
00:22:41,076 --> 00:22:43,136
3-D mode, which gives us a point


718
00:22:43,136 --> 00:22:43,616
cloud view.


719
00:22:44,326 --> 00:22:45,956
With point clouds we can


720
00:22:45,956 --> 00:22:47,426
dynamically change the


721
00:22:47,426 --> 00:22:48,936
perspective of the scene


722
00:22:50,796 --> 00:22:53,506
creating even more holes when we


723
00:22:54,106 --> 00:22:56,256
do so.


724
00:22:56,396 --> 00:22:58,226
And now I can ask you is this


725
00:22:58,226 --> 00:23:01,706
mug half empty or half full and


726
00:23:01,706 --> 00:23:03,826
the answer is we have no idea.


727
00:23:05,256 --> 00:23:07,176
By virtually changing the point


728
00:23:07,176 --> 00:23:08,606
of view of the camera we don't


729
00:23:08,606 --> 00:23:10,696
add new information and that is


730
00:23:10,696 --> 00:23:11,966
because the TrueDepth camera can


731
00:23:11,966 --> 00:23:13,656
do many things, but bending


732
00:23:13,656 --> 00:23:16,466
light into the mug not one of


733
00:23:17,556 --> 00:23:17,726
them.


734
00:23:18,076 --> 00:23:18,786
Let's see this live.


735
00:23:21,516 --> 00:23:24,500
[ Applause ]


736
00:23:32,046 --> 00:23:32,946
So I'm starting with a video


737
00:23:32,946 --> 00:23:34,156
view and I want you to look in


738
00:23:34,156 --> 00:23:34,736
this corner.


739
00:23:35,636 --> 00:23:37,356
Watch what happens when I touch


740
00:23:37,356 --> 00:23:38,456
the screen, I will touch my


741
00:23:38,456 --> 00:23:39,636
forehead, you can see an


742
00:23:39,636 --> 00:23:41,456
indication of the depth.


743
00:23:41,806 --> 00:23:44,466
And if I move the phone you can


744
00:23:44,466 --> 00:23:46,036
see the [inaudible] changing and


745
00:23:46,036 --> 00:23:47,606
the reason I can do so is


746
00:23:47,606 --> 00:23:50,206
because we have the stream from


747
00:23:50,206 --> 00:23:51,346
the TrueDepth camera running as


748
00:23:51,346 --> 00:23:53,836
well and you can see that it is


749
00:23:53,836 --> 00:23:55,316
overlaid on the video.


750
00:23:55,316 --> 00:23:58,976
So we have this livestream 30


751
00:23:58,976 --> 00:24:00,766
frames per second and we can


752
00:24:00,766 --> 00:24:01,996
switch to the filtered stream


753
00:24:02,456 --> 00:24:04,866
and then all the holes are


754
00:24:05,886 --> 00:24:06,026
filled.


755
00:24:06,206 --> 00:24:07,446
If I switch to the point cloud


756
00:24:07,446 --> 00:24:10,076
view I can dynamically change


757
00:24:11,636 --> 00:24:13,296
the point of view to the scene.


758
00:24:14,276 --> 00:24:15,516
So even though I'm looking


759
00:24:15,516 --> 00:24:17,786
directly to the device it looks


760
00:24:17,786 --> 00:24:19,136
as if somebody's watching me


761
00:24:19,136 --> 00:24:19,846
from up above.


762
00:24:21,336 --> 00:24:22,516
Now the reason we call this a


763
00:24:22,516 --> 00:24:25,076
point cloud is if I zoom in you


764
00:24:25,076 --> 00:24:27,366
can actually see the points in


765
00:24:27,366 --> 00:24:28,156
3-D space.


766
00:24:28,686 --> 00:24:32,016
But being here with you in WWDC


767
00:24:32,466 --> 00:24:33,576
I feel like I have to pinch


768
00:24:33,576 --> 00:24:35,666
myself just to get things back


769
00:24:35,666 --> 00:24:36,306
in perspective.


770
00:24:39,516 --> 00:24:42,500
[ Applause ]


771
00:24:45,076 --> 00:24:47,396
Thank you so that brings us to


772
00:24:47,936 --> 00:24:48,446
point clouds.


773
00:24:48,446 --> 00:24:49,306
How do we create them?


774
00:24:50,126 --> 00:24:51,426
We're starting from a depth map,


775
00:24:51,826 --> 00:24:54,236
a 2-D image in which the depth Z


776
00:24:54,716 --> 00:24:55,886
is a function of the pixel


777
00:24:55,886 --> 00:24:57,056
coordinates U and V.


778
00:24:58,486 --> 00:25:00,076
And we want to transform it to a


779
00:25:00,076 --> 00:25:01,586
new coordinate system in 3-D


780
00:25:01,586 --> 00:25:03,486
space, X, Y, Z.


781
00:25:04,336 --> 00:25:06,256
Now we already have Z right,


782
00:25:06,256 --> 00:25:07,616
that's the depth from the depth


783
00:25:07,616 --> 00:25:09,766
map but we want to get X and Y.


784
00:25:10,416 --> 00:25:13,606
For that we need to get the help


785
00:25:13,606 --> 00:25:15,806
from the Intrinsics Matrix which


786
00:25:15,806 --> 00:25:17,196
holds information for the focal


787
00:25:17,196 --> 00:25:18,346
lengths and principle point.


788
00:25:19,376 --> 00:25:21,686
If for example I want to get X I


789
00:25:21,686 --> 00:25:22,936
need to start with the pixel


790
00:25:22,936 --> 00:25:24,506
coordinate U, subtract the


791
00:25:24,506 --> 00:25:26,576
principle point, multiply by the


792
00:25:26,576 --> 00:25:28,576
depth, and divide by the focal


793
00:25:28,576 --> 00:25:28,916
lengths.


794
00:25:29,136 --> 00:25:30,416
And naturally I have to do the


795
00:25:30,416 --> 00:25:31,256
same thing for the other


796
00:25:31,256 --> 00:25:32,026
dimension as well.


797
00:25:33,196 --> 00:25:36,976
Now this Intrinsics Matrix is


798
00:25:36,976 --> 00:25:38,436
accessible through the camera


799
00:25:38,436 --> 00:25:39,126
calibration data.


800
00:25:39,716 --> 00:25:43,656
In fact, this operation is done


801
00:25:44,786 --> 00:25:46,676
in every frame of the TrueDepth


802
00:25:46,676 --> 00:25:47,056
stream.


803
00:25:47,506 --> 00:25:49,836
The reason for that is that the


804
00:25:49,836 --> 00:25:51,656
video stream and the depth


805
00:25:51,656 --> 00:25:53,076
stream are coming from two


806
00:25:53,286 --> 00:25:54,506
separate cameras.


807
00:25:55,136 --> 00:25:57,246
But because the TrueDepth camera


808
00:25:57,246 --> 00:25:58,936
gives us a depth map we can


809
00:25:58,936 --> 00:26:00,446
transform it into a point cloud


810
00:26:00,876 --> 00:26:03,046
and re-project it to the


811
00:26:03,046 --> 00:26:06,306
perspective of the RGB image so


812
00:26:06,306 --> 00:26:07,756
the depth stream is already


813
00:26:07,756 --> 00:26:10,076
registered on the video stream


814
00:26:10,076 --> 00:26:13,556
for you and you get RGBD data.


815
00:26:14,146 --> 00:26:15,916
Now, thank you.


816
00:26:16,496 --> 00:26:18,346
Yeah, it's pretty cool.


817
00:26:20,066 --> 00:26:21,526
Now these types of operations


818
00:26:21,626 --> 00:26:23,456
are best done in metal graphic


819
00:26:23,456 --> 00:26:23,906
shaders.


820
00:26:24,226 --> 00:26:25,476
And you can download the code


821
00:26:25,476 --> 00:26:27,066
for TrueDepth Streamer and you


822
00:26:27,066 --> 00:26:28,666
want to focus on two areas.


823
00:26:29,196 --> 00:26:32,286
In the vertex shader we control


824
00:26:32,286 --> 00:26:33,296
the location of the points,


825
00:26:33,486 --> 00:26:34,976
we'll start with the depth map


826
00:26:35,126 --> 00:26:36,696
and transform it to real-world


827
00:26:36,696 --> 00:26:37,986
coordinates or X, Y, Z.


828
00:26:39,186 --> 00:26:40,796
Then we can multiply it with a


829
00:26:40,796 --> 00:26:43,006
view matrix to change the point


830
00:26:43,006 --> 00:26:43,706
of view to the scene.


831
00:26:44,336 --> 00:26:49,066
In the fragment shader we get


832
00:26:49,066 --> 00:26:51,766
the output of the vertex, but we


833
00:26:51,766 --> 00:26:53,866
have to see if it's a real value


834
00:26:54,096 --> 00:26:55,186
or a hole in the depth map.


835
00:26:56,026 --> 00:26:57,476
If it's a hole and it's marked


836
00:26:57,476 --> 00:26:59,766
as zero we don't know its depth


837
00:26:59,766 --> 00:27:01,516
so we cannot transform it to X,


838
00:27:01,516 --> 00:27:02,856
Y, Z and we would need to


839
00:27:02,856 --> 00:27:03,816
discard this point.


840
00:27:05,196 --> 00:27:06,786
If it is a real value we can


841
00:27:06,786 --> 00:27:09,286
sample the RGB texture and add


842
00:27:09,286 --> 00:27:11,366
color to the fragment or point


843
00:27:11,366 --> 00:27:14,746
in this case.


844
00:27:14,956 --> 00:27:17,356
So I understand this part was a


845
00:27:17,356 --> 00:27:19,066
bit technical and a lot of you


846
00:27:19,066 --> 00:27:20,276
come from different backgrounds.


847
00:27:21,016 --> 00:27:22,876
Have no fear we have just the


848
00:27:22,876 --> 00:27:25,056
app for you, an app to replace


849
00:27:25,056 --> 00:27:26,756
your background, let's see it


850
00:27:26,756 --> 00:27:26,906
live.


851
00:27:38,046 --> 00:27:40,926
Let's see it live.


852
00:27:41,136 --> 00:27:43,516
So I can put myself in Yosemite,


853
00:27:43,936 --> 00:27:46,466
I can swipe down put myself in


854
00:27:46,466 --> 00:27:47,466
something more abstract.


855
00:27:48,166 --> 00:27:51,466
I can even go all the way to


856
00:27:51,466 --> 00:27:53,006
Antelope Canyon, Arizona, it


857
00:27:53,006 --> 00:27:54,356
took me 15 hours to get there


858
00:27:54,356 --> 00:27:55,846
last time, I could have just


859
00:27:55,846 --> 00:27:57,426
swiped down, saved a lot of


860
00:27:57,426 --> 00:27:58,126
money on gas.


861
00:27:59,546 --> 00:28:02,016
In fact, this application can


862
00:28:02,016 --> 00:28:04,116
even put you in space where


863
00:28:04,116 --> 00:28:05,876
nobody can hear you stream.


864
00:28:11,516 --> 00:28:15,616
[ Applause ]


865
00:28:16,116 --> 00:28:19,036
So how do we create that?


866
00:28:19,256 --> 00:28:21,586
Anytime we're dealing with a


867
00:28:21,586 --> 00:28:23,706
video application there's other


868
00:28:23,706 --> 00:28:25,476
things that are going on a per


869
00:28:25,476 --> 00:28:28,456
frame basis, in this case we


870
00:28:28,456 --> 00:28:31,696
have to detect a face, create a


871
00:28:31,696 --> 00:28:33,316
brand-new mask from the depth


872
00:28:33,316 --> 00:28:36,056
map, smooth and upscale it to


873
00:28:36,056 --> 00:28:37,286
the RGB resolution.


874
00:28:37,736 --> 00:28:39,246
And then we take this foreground


875
00:28:39,246 --> 00:28:41,536
mask and upscale it again to the


876
00:28:41,536 --> 00:28:42,636
low-light background image.


877
00:28:43,446 --> 00:28:44,616
And then we can blend or


878
00:28:44,646 --> 00:28:46,876
[inaudible] them, but there's


879
00:28:46,876 --> 00:28:49,336
something we can do to reduce


880
00:28:49,416 --> 00:28:50,416
some of the complexity.


881
00:28:51,976 --> 00:28:54,466
If anytime we load a background


882
00:28:54,466 --> 00:28:56,306
image we resize it to the RGB


883
00:28:56,306 --> 00:28:57,756
resolution just once not


884
00:28:57,756 --> 00:28:59,556
per-frame, then we don't need


885
00:28:59,556 --> 00:29:01,446
that second upscale and the


886
00:29:01,446 --> 00:29:02,926
blending is done at low


887
00:29:02,926 --> 00:29:04,376
resolution which makes a big


888
00:29:04,376 --> 00:29:04,886
difference.


889
00:29:06,276 --> 00:29:07,716
So let's deep dive into those


890
00:29:07,716 --> 00:29:08,086
depths.


891
00:29:08,626 --> 00:29:10,606
The first thing we need is to


892
00:29:10,606 --> 00:29:11,856
find the center of the face.


893
00:29:12,366 --> 00:29:14,406
And in iOS there are actually


894
00:29:14,646 --> 00:29:16,386
quite a few ways you can get


895
00:29:16,386 --> 00:29:17,316
face metadata.


896
00:29:18,296 --> 00:29:19,246
You can use a Core Image


897
00:29:19,246 --> 00:29:20,706
detector or the Vision


898
00:29:20,706 --> 00:29:22,796
Framework, but in this case


899
00:29:22,976 --> 00:29:25,226
since we just need the pixel at


900
00:29:25,226 --> 00:29:26,366
the center of the face we can


901
00:29:26,366 --> 00:29:28,586
use AV meta data object type


902
00:29:28,586 --> 00:29:29,056
face.


903
00:29:30,426 --> 00:29:32,896
But it gives us the center in


904
00:29:32,896 --> 00:29:34,236
the coding system of the RGB


905
00:29:34,236 --> 00:29:36,086
image and we need to map it to


906
00:29:36,086 --> 00:29:38,196
the depth map which might not be


907
00:29:38,196 --> 00:29:39,106
in the same resolution.


908
00:29:41,356 --> 00:29:43,316
Once we have the value of the


909
00:29:43,316 --> 00:29:45,886
depth of the face we can use it


910
00:29:45,886 --> 00:29:47,566
plus a margin of characteristic


911
00:29:47,566 --> 00:29:50,656
25 centimeters to threshold the


912
00:29:50,656 --> 00:29:52,306
depth map and create a binary


913
00:29:52,306 --> 00:29:54,076
mask, foreground is one,


914
00:29:54,476 --> 00:29:55,296
background is zero.


915
00:29:56,556 --> 00:29:58,456
In fact, we can stop here, we


916
00:29:58,456 --> 00:30:00,236
can use this binary mask and


917
00:30:00,236 --> 00:30:00,956
create the effect.


918
00:30:01,596 --> 00:30:02,816
The transition from background


919
00:30:02,816 --> 00:30:04,166
to foreground will be very


920
00:30:04,166 --> 00:30:06,636
sharp, but we'll get some


921
00:30:06,636 --> 00:30:07,826
fidgeting around the edges.


922
00:30:09,486 --> 00:30:10,856
So we want to filter it a bit.


923
00:30:11,826 --> 00:30:14,156
The first stage will be to apply


924
00:30:14,156 --> 00:30:15,216
some smoothing from the


925
00:30:15,216 --> 00:30:16,346
background to the foreground, in


926
00:30:16,346 --> 00:30:17,896
this case Gaussian Blurring.


927
00:30:18,626 --> 00:30:20,446
The radius of Gaussian Blurring


928
00:30:20,446 --> 00:30:22,716
will determine the slope of the


929
00:30:22,716 --> 00:30:25,096
transition and you can play with


930
00:30:25,096 --> 00:30:26,696
the value to get different


931
00:30:27,996 --> 00:30:28,526
effects.


932
00:30:29,426 --> 00:30:31,126
Another processing stage we add


933
00:30:31,346 --> 00:30:33,966
is gamma adjustments, it allows


934
00:30:33,966 --> 00:30:35,286
us to further fine-tune this


935
00:30:35,286 --> 00:30:36,456
transition from background to


936
00:30:36,456 --> 00:30:36,976
foreground.


937
00:30:37,426 --> 00:30:39,386
If we use a gamma value which is


938
00:30:39,386 --> 00:30:41,576
higher than one we'll get a


939
00:30:41,576 --> 00:30:43,156
narrower foreground mask.


940
00:30:44,176 --> 00:30:45,966
On the other hand, if we use a


941
00:30:45,966 --> 00:30:47,526
gamma value that is smaller than


942
00:30:47,526 --> 00:30:49,886
one we'll get a wider foreground


943
00:30:49,886 --> 00:30:51,026
mask and maybe some aura.


944
00:30:52,386 --> 00:30:53,646
So you can create different


945
00:30:53,646 --> 00:30:56,286
effects by combining those two


946
00:30:56,446 --> 00:30:57,136
parameters.


947
00:30:57,556 --> 00:31:01,156
If you use a large blur radius


948
00:31:01,366 --> 00:31:02,866
and a large gamma value you


949
00:31:02,866 --> 00:31:04,656
create this transparent


950
00:31:04,656 --> 00:31:06,726
transition that makes you seem


951
00:31:06,726 --> 00:31:08,486
as if you're a hologram in space


952
00:31:09,546 --> 00:31:10,706
or similarly it could be


953
00:31:10,706 --> 00:31:13,336
underwater and you can play with


954
00:31:13,336 --> 00:31:15,146
the values to create different


955
00:31:15,146 --> 00:31:15,576
effects.


956
00:31:15,576 --> 00:31:17,936
If I keep the radius high and


957
00:31:18,116 --> 00:31:19,766
reduce the gamma value to a very


958
00:31:19,766 --> 00:31:22,186
low number I create this halo


959
00:31:22,186 --> 00:31:22,756
around my head.


960
00:31:23,406 --> 00:31:24,376
So you can play with this to


961
00:31:24,376 --> 00:31:27,586
create your own effects.


962
00:31:27,586 --> 00:31:31,266
How do we implement this?


963
00:31:31,466 --> 00:31:33,026
In Core Image it is very


964
00:31:33,026 --> 00:31:34,106
straightforward, we can


965
00:31:34,106 --> 00:31:35,896
concatenate three filters in a


966
00:31:35,896 --> 00:31:36,166
row.


967
00:31:36,886 --> 00:31:38,516
We start with a Gaussian Blur,


968
00:31:39,866 --> 00:31:42,656
we add the gamma adjustment, and


969
00:31:42,656 --> 00:31:44,446
we upscale to the RGB


970
00:31:44,446 --> 00:31:45,016
resolution.


971
00:31:46,616 --> 00:31:48,306
But there are a couple of small


972
00:31:48,306 --> 00:31:49,756
points I want to emphasize as


973
00:31:49,756 --> 00:31:50,686
best practices.


974
00:31:52,076 --> 00:31:54,176
Anytime you work with a


975
00:31:54,176 --> 00:31:55,696
convolutional based operation


976
00:31:55,696 --> 00:31:57,436
such as Gaussian Blurring the


977
00:31:57,436 --> 00:31:59,466
best practice will be to start


978
00:31:59,466 --> 00:32:00,696
by clamping to extent.


979
00:32:01,856 --> 00:32:03,576
By repeating the border pixels


980
00:32:03,576 --> 00:32:06,446
outwards we can make sure all


981
00:32:06,446 --> 00:32:07,566
the borders of the image are


982
00:32:07,566 --> 00:32:10,996
handled correctly by the filter.


983
00:32:11,126 --> 00:32:13,236
Moreover, after the filtering


984
00:32:13,236 --> 00:32:14,616
and just before the upscaling


985
00:32:15,116 --> 00:32:16,286
the best practice will be to


986
00:32:16,286 --> 00:32:18,386
crop back to the original extent


987
00:32:18,886 --> 00:32:20,006
because that's the part of the


988
00:32:20,006 --> 00:32:21,496
image we really care about.


989
00:32:21,766 --> 00:32:25,816
At this point we have an alpha


990
00:32:25,816 --> 00:32:27,766
matte of the foreground and you


991
00:32:27,766 --> 00:32:29,096
can use it to create different


992
00:32:29,096 --> 00:32:30,246
kinds of effects for the


993
00:32:30,246 --> 00:32:31,336
background and the foreground


994
00:32:31,796 --> 00:32:33,006
just like Emmanuel showed in the


995
00:32:33,006 --> 00:32:33,646
first half.


996
00:32:34,076 --> 00:32:39,266
In Backdrop, we blend the RGB


997
00:32:39,266 --> 00:32:41,136
stream with a loaded background


998
00:32:41,136 --> 00:32:43,186
image in a single line of Core


999
00:32:43,186 --> 00:32:45,016
Image code using the alpha matte


1000
00:32:45,016 --> 00:32:46,296
we created from the TrueDepth


1001
00:32:46,296 --> 00:32:48,706
camera to create this background


1002
00:32:49,216 --> 00:32:50,236
replacement effect.


1003
00:32:53,996 --> 00:32:57,056
So the TrueDepth camera gives us


1004
00:32:58,046 --> 00:32:59,416
a resolution of depth map of


1005
00:32:59,416 --> 00:33:02,576
640x480 coming at you 30 frames


1006
00:33:02,576 --> 00:33:05,116
a second, already registered to


1007
00:33:05,116 --> 00:33:05,936
the video stream.


1008
00:33:06,476 --> 00:33:09,496
You can use it to create point


1009
00:33:09,496 --> 00:33:10,776
clouds and dynamically change


1010
00:33:10,776 --> 00:33:12,426
the perspective of the scene or


1011
00:33:12,486 --> 00:33:16,066
use the filter depth to create


1012
00:33:16,336 --> 00:33:17,916
different kinds of video


1013
00:33:17,916 --> 00:33:18,486
effects.


1014
00:33:21,476 --> 00:33:22,986
You can go to the webpage and


1015
00:33:22,986 --> 00:33:25,176
download the Jupiter Notebook


1016
00:33:25,466 --> 00:33:28,576
TrueDepth Streamer and Backdrop


1017
00:33:29,246 --> 00:33:31,986
and we hope it inspires you as a


1018
00:33:31,986 --> 00:33:34,876
starting point to many new cool


1019
00:33:34,876 --> 00:33:37,056
video effects to create in your


1020
00:33:37,056 --> 00:33:37,776
applications.


1021
00:33:39,316 --> 00:33:41,156
Come say hi at the AVCapture


1022
00:33:41,156 --> 00:33:42,456
lab, thank you so much for your


1023
00:33:42,456 --> 00:33:42,666
time.


1024
00:33:42,666 --> 00:33:42,976
Have a great day.


1025
00:33:43,516 --> 00:33:46,500
[ Applause ]

