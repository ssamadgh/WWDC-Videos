1
00:00:07,016 --> 00:00:14,500
[ Music ]


2
00:00:20,516 --> 00:00:27,186
[ Applause ]


3
00:00:27,686 --> 00:00:28,656
>> Good afternoon, everybody,


4
00:00:28,656 --> 00:00:30,936
and welcome to Object Tracking


5
00:00:30,936 --> 00:00:31,636
in Vision session.


6
00:00:32,375 --> 00:00:34,186
Do you ever need to face and


7
00:00:34,186 --> 00:00:35,316
solve various computer vision


8
00:00:35,316 --> 00:00:35,796
problems?


9
00:00:36,716 --> 00:00:38,726
If you do, and whether your Mac


10
00:00:39,406 --> 00:00:40,956
and iOS, or each of you as


11
00:00:40,996 --> 00:00:42,416
developer, you're in the right


12
00:00:42,416 --> 00:00:42,816
place.


13
00:00:43,426 --> 00:00:44,586
My name is Sergey Kamensky.


14
00:00:44,866 --> 00:00:46,186
I'm excited to share with you


15
00:00:46,496 --> 00:00:47,646
how Vision Framework can help.


16
00:00:51,356 --> 00:00:52,836
Our agenda today consists of


17
00:00:52,836 --> 00:00:53,456
four items.


18
00:00:53,836 --> 00:00:54,946
First, we're going to talk about


19
00:00:54,946 --> 00:00:55,396
Why Vision?


20
00:00:56,326 --> 00:00:57,596
Second, we're going to look


21
00:00:57,596 --> 00:00:58,966
about what's new that we're


22
00:00:58,966 --> 00:00:59,796
introducing this year.


23
00:01:00,866 --> 00:01:02,016
Third, we're going to have a


24
00:01:02,016 --> 00:01:03,506
deeper dive into helping


25
00:01:03,506 --> 00:01:04,456
throughout this Vision API.


26
00:01:04,906 --> 00:01:06,696
And then, finally, we're going


27
00:01:06,696 --> 00:01:07,816
to get to the main topic of our


28
00:01:07,816 --> 00:01:09,766
presentation, which is Tracking


29
00:01:09,886 --> 00:01:11,006
in Vision.


30
00:01:13,676 --> 00:01:15,626
So, why Vision?


31
00:01:17,616 --> 00:01:19,166
When we designed our framework,


32
00:01:19,416 --> 00:01:20,806
we wanted it to be one central


33
00:01:20,806 --> 00:01:22,186
stop to solve all of your


34
00:01:22,186 --> 00:01:24,366
computer vision problems while


35
00:01:24,366 --> 00:01:26,026
first in simple and consistent


36
00:01:26,026 --> 00:01:28,466
interface, one multi-platform;


37
00:01:28,776 --> 00:01:31,336
our framework runs on iOS,


38
00:01:31,676 --> 00:01:33,036
macOS, and tvOS.


39
00:01:34,226 --> 00:01:35,296
We're privacy oriented.


40
00:01:35,976 --> 00:01:37,376
What that means is that your


41
00:01:37,376 --> 00:01:39,056
data never leaves the device.


42
00:01:39,596 --> 00:01:40,496
All the [inaudible] sync is


43
00:01:40,496 --> 00:01:43,206
local, and we're continuously


44
00:01:43,206 --> 00:01:43,576
working.


45
00:01:44,586 --> 00:01:46,006
We're enhancing our existing


46
00:01:46,006 --> 00:01:48,246
algorithms, and we're developing


47
00:01:48,326 --> 00:01:49,746
new ones.


48
00:01:51,236 --> 00:01:52,786
Let's look at the Vision basics.


49
00:01:53,526 --> 00:01:55,736
When you think about how to


50
00:01:55,736 --> 00:01:57,526
interact with Vision API, I want


51
00:01:57,526 --> 00:01:59,086
you to think about in these


52
00:01:59,086 --> 00:02:01,686
terms, what to process, how to


53
00:02:01,686 --> 00:02:03,016
process, and where to look for


54
00:02:03,016 --> 00:02:03,326
results.


55
00:02:04,776 --> 00:02:06,076
What to process is about a


56
00:02:06,076 --> 00:02:07,056
family of requests.


57
00:02:07,826 --> 00:02:09,006
That is how you tell us what you


58
00:02:09,006 --> 00:02:09,395
want to do.


59
00:02:10,476 --> 00:02:12,986
How is about our request


60
00:02:12,986 --> 00:02:14,506
handlers or engines-- our


61
00:02:14,506 --> 00:02:16,246
request handlers, they're used


62
00:02:16,246 --> 00:02:18,156
to process our requests.


63
00:02:19,146 --> 00:02:20,906
And finally, the results; the


64
00:02:20,906 --> 00:02:22,546
results in Vision come in forms


65
00:02:22,546 --> 00:02:23,406
of observations.


66
00:02:24,556 --> 00:02:25,316
Please take a look at this


67
00:02:25,316 --> 00:02:25,576
slide.


68
00:02:26,296 --> 00:02:27,546
If you were to remember anything


69
00:02:27,546 --> 00:02:28,986
from this presentation, this


70
00:02:28,986 --> 00:02:29,956
slide is probably one of the


71
00:02:29,956 --> 00:02:30,876
more important ones.


72
00:02:31,326 --> 00:02:32,536
This slide presents a


73
00:02:32,536 --> 00:02:33,866
philosophy, how to interact with


74
00:02:33,866 --> 00:02:36,076
Vision, requests, request


75
00:02:36,706 --> 00:02:37,346
handlers,


76
00:02:38,236 --> 00:02:41,096
and observations.


77
00:02:42,356 --> 00:02:43,186
Let's look at the requests


78
00:02:43,186 --> 00:02:43,566
first.


79
00:02:44,276 --> 00:02:46,126
This is a collection of requests


80
00:02:46,126 --> 00:02:46,866
that we offer today.


81
00:02:46,866 --> 00:02:49,386
As you can see, we have various


82
00:02:49,386 --> 00:02:49,936
detectors.


83
00:02:50,536 --> 00:02:51,696
We have Image Registration


84
00:02:51,696 --> 00:02:52,096
Request.


85
00:02:52,806 --> 00:02:54,626
We have two trackers, and we


86
00:02:54,626 --> 00:02:55,826
have a CoreML request.


87
00:02:56,366 --> 00:02:57,426
If you're interested to learn


88
00:02:57,426 --> 00:02:59,116
more about integration of Vision


89
00:02:59,116 --> 00:03:00,956
and CoreML, I invite you to come


90
00:03:00,956 --> 00:03:02,246
to the next session in this room


91
00:03:02,516 --> 00:03:03,756
where Fran, my colleague, will


92
00:03:03,756 --> 00:03:05,246
cover details of that


93
00:03:05,246 --> 00:03:05,786
integration.


94
00:03:07,426 --> 00:03:09,546
Let's take a look at the request


95
00:03:09,546 --> 00:03:09,956
handlers.


96
00:03:10,936 --> 00:03:12,226
In Vision, we have two.


97
00:03:12,506 --> 00:03:13,896
We have Image Request Handler,


98
00:03:13,896 --> 00:03:15,766
and we have Sequence Request


99
00:03:15,766 --> 00:03:16,046
Handler.


100
00:03:16,646 --> 00:03:18,446
Let's compare the two using this


101
00:03:18,446 --> 00:03:18,826
criteria.


102
00:03:20,066 --> 00:03:21,196
First, we'll look at the Image


103
00:03:21,196 --> 00:03:21,736
Request Handler.


104
00:03:23,796 --> 00:03:25,326
Image request handler is used to


105
00:03:25,326 --> 00:03:27,996
process one or more requests on


106
00:03:27,996 --> 00:03:28,666
the same image.


107
00:03:30,126 --> 00:03:31,676
What it doesn't say, it caches


108
00:03:31,676 --> 00:03:33,066
certain information like image


109
00:03:33,066 --> 00:03:34,796
derivatives and results of


110
00:03:34,796 --> 00:03:35,636
posting requests.


111
00:03:35,956 --> 00:03:37,216
So, other requests in the


112
00:03:37,216 --> 00:03:38,416
pipeline can use that


113
00:03:38,416 --> 00:03:39,006
information.


114
00:03:39,666 --> 00:03:40,526
I'm going to give you an


115
00:03:40,526 --> 00:03:41,036
example.


116
00:03:41,396 --> 00:03:43,116
If a request depends on running


117
00:03:43,116 --> 00:03:44,606
neural network, as you know,


118
00:03:44,606 --> 00:03:46,436
neural network expects images in


119
00:03:46,436 --> 00:03:47,876
certain sizes and certain colors


120
00:03:47,876 --> 00:03:48,276
schemes.


121
00:03:48,606 --> 00:03:49,926
Let's say your neural network


122
00:03:50,076 --> 00:03:52,706
expects 500 by 500 black and


123
00:03:52,706 --> 00:03:52,906
white.


124
00:03:53,926 --> 00:03:55,446
It's very rare that you'll get


125
00:03:55,446 --> 00:03:57,006
user input just in that format.


126
00:03:57,236 --> 00:03:58,786
So, what we'll do inside, we'll


127
00:03:58,786 --> 00:03:59,626
convert the image.


128
00:03:59,856 --> 00:04:01,066
We'll feed it into that neural


129
00:04:01,066 --> 00:04:02,186
network to get results for the


130
00:04:02,186 --> 00:04:03,606
current request, but we will


131
00:04:03,606 --> 00:04:05,286
also cache that information on


132
00:04:05,286 --> 00:04:06,266
the request handler object.


133
00:04:06,706 --> 00:04:07,916
So, the next request, when it


134
00:04:07,916 --> 00:04:09,366
comes, if it needs to use the


135
00:04:09,366 --> 00:04:10,946
same format, it's already there,


136
00:04:11,016 --> 00:04:11,816
and it doesn't need to be


137
00:04:11,816 --> 00:04:12,356
recomputed.


138
00:04:13,246 --> 00:04:14,866
We'll also cache results that we


139
00:04:14,866 --> 00:04:16,386
get from the requests so other


140
00:04:16,386 --> 00:04:17,296
requests can use it in


141
00:04:17,296 --> 00:04:18,416
pipelines, and we're going to


142
00:04:18,416 --> 00:04:20,176
look at pipelines going forward


143
00:04:20,176 --> 00:04:21,036
in this presentation.


144
00:04:21,766 --> 00:04:23,636
Let's take a look at the


145
00:04:23,636 --> 00:04:24,536
Sequence Request Handler.


146
00:04:25,626 --> 00:04:26,906
Sequence request handler is used


147
00:04:27,196 --> 00:04:28,366
to process a particular


148
00:04:28,366 --> 00:04:30,626
operation like tracking in a


149
00:04:30,626 --> 00:04:31,566
sequence of frames.


150
00:04:32,506 --> 00:04:34,256
What it does inside, it caches


151
00:04:34,256 --> 00:04:35,886
the state of that operation from


152
00:04:35,886 --> 00:04:37,506
frame to frame to frame for the


153
00:04:37,506 --> 00:04:38,256
entire sequence.


154
00:04:39,656 --> 00:04:41,106
In Vision, it's used to process


155
00:04:41,506 --> 00:04:43,016
tracking and image registration


156
00:04:43,016 --> 00:04:43,476
requests.


157
00:04:43,866 --> 00:04:45,516
All other requests are processed


158
00:04:45,516 --> 00:04:46,576
with our Image Request Handler.


159
00:04:50,856 --> 00:04:52,196
Let's look at the results.


160
00:04:52,776 --> 00:04:53,996
Results in Vision coming from


161
00:04:54,146 --> 00:04:54,876
observations.


162
00:04:55,406 --> 00:04:57,186
Observations is a collection of


163
00:04:57,236 --> 00:04:59,336
classes derived from


164
00:04:59,946 --> 00:05:01,026
VNObservation class.


165
00:05:01,616 --> 00:05:02,746
How do we get an observation?


166
00:05:03,616 --> 00:05:04,886
Well, first, the most natural


167
00:05:04,886 --> 00:05:06,566
way is when the request is


168
00:05:06,566 --> 00:05:07,746
processed, you're going to look


169
00:05:07,746 --> 00:05:08,886
at the results property of that


170
00:05:08,886 --> 00:05:10,256
request, and that results


171
00:05:10,256 --> 00:05:11,356
property is a collection of


172
00:05:11,356 --> 00:05:11,966
observations.


173
00:05:11,966 --> 00:05:13,516
That's how we tell you results


174
00:05:13,726 --> 00:05:14,306
of processing.


175
00:05:14,976 --> 00:05:18,606
The second way is you create it


176
00:05:18,606 --> 00:05:18,996
manually.


177
00:05:19,696 --> 00:05:20,866
We're going to look at examples


178
00:05:20,866 --> 00:05:22,006
for other presentations how to


179
00:05:22,006 --> 00:05:22,336
do both.


180
00:05:26,636 --> 00:05:28,886
Let's now look at what's new


181
00:05:28,886 --> 00:05:29,636
coming this year.


182
00:05:30,476 --> 00:05:32,286
First, we have our new face


183
00:05:32,286 --> 00:05:32,706
detector.


184
00:05:33,206 --> 00:05:36,336
Now, we can detect more faces,


185
00:05:37,196 --> 00:05:37,986
and we're now


186
00:05:38,096 --> 00:05:39,096
orientation-agnostic.


187
00:05:39,886 --> 00:05:40,726
Let's look at example.


188
00:05:41,186 --> 00:05:42,256
On the left-hand side, you can


189
00:05:42,256 --> 00:05:43,776
see an image with seven faces in


190
00:05:43,776 --> 00:05:45,806
it, and we could process that


191
00:05:45,806 --> 00:05:46,906
image with the detector from


192
00:05:46,906 --> 00:05:48,236
last year, we can detect only


193
00:05:48,236 --> 00:05:50,206
three faces, and those faces are


194
00:05:50,406 --> 00:05:51,746
the ones that are close to the


195
00:05:51,746 --> 00:05:52,596
upright position.


196
00:05:53,966 --> 00:05:55,216
If you process the same image


197
00:05:55,216 --> 00:05:56,596
with the face detector that's


198
00:05:57,016 --> 00:05:58,426
coming this year, as you can


199
00:05:58,426 --> 00:05:59,866
see, all faces can be detected,


200
00:05:59,996 --> 00:06:01,256
and orientation is not a problem


201
00:06:01,256 --> 00:06:01,556
anymore.


202
00:06:01,556 --> 00:06:04,516
Let's look a little bit more


203
00:06:04,516 --> 00:06:04,966
into details.


204
00:06:05,136 --> 00:06:06,096
Thank you.


205
00:06:07,176 --> 00:06:09,500
[ Applause ]


206
00:06:15,186 --> 00:06:17,976
So, first, our new face detector


207
00:06:18,356 --> 00:06:20,226
uses the same API as from last


208
00:06:20,226 --> 00:06:20,456
year.


209
00:06:20,836 --> 00:06:22,196
The only difference is if you


210
00:06:22,196 --> 00:06:23,426
want to specify revision, you


211
00:06:23,426 --> 00:06:24,636
need to overwrite a revision


212
00:06:24,636 --> 00:06:26,236
property of that request and set


213
00:06:26,236 --> 00:06:28,056
it explicitly to User Vision #2.


214
00:06:28,496 --> 00:06:29,196
Again, I'll talk about the


215
00:06:29,196 --> 00:06:30,336
reasons right on the next slide.


216
00:06:31,556 --> 00:06:33,466
We're also introducing two new


217
00:06:33,466 --> 00:06:34,116
properties.


218
00:06:34,566 --> 00:06:36,516
One is roll, which is when the


219
00:06:36,516 --> 00:06:38,126
head rotates like this, and the


220
00:06:38,126 --> 00:06:39,856
other one is yaw, which when the


221
00:06:39,856 --> 00:06:41,500
head rotates around the neck.


222
00:06:45,116 --> 00:06:45,676
Revisions.


223
00:06:46,616 --> 00:06:47,676
What happens with Vision where


224
00:06:47,676 --> 00:06:48,696
when we need to introducing a


225
00:06:48,696 --> 00:06:50,156
new algorithm, we don't


226
00:06:50,156 --> 00:06:51,246
deprecate the old one right


227
00:06:51,246 --> 00:06:51,516
away.


228
00:06:52,146 --> 00:06:53,486
Instead, we're going to keep for


229
00:06:53,486 --> 00:06:55,026
some time both revisions or,


230
00:06:55,026 --> 00:06:56,396
maybe going forward, even more,


231
00:06:56,956 --> 00:06:57,696
simultaneously.


232
00:06:58,496 --> 00:06:59,896
You tell us which one you want


233
00:06:59,896 --> 00:07:01,186
to work with by specifying


234
00:07:01,186 --> 00:07:02,256
revision property of the


235
00:07:02,256 --> 00:07:02,696
request.


236
00:07:04,066 --> 00:07:04,966
So, that's the explicit


237
00:07:04,966 --> 00:07:05,376
behavior.


238
00:07:05,866 --> 00:07:06,936
But we also have a default


239
00:07:06,936 --> 00:07:07,376
behavior.


240
00:07:07,876 --> 00:07:09,156
If you create a request object,


241
00:07:09,336 --> 00:07:10,566
and you don't tell us anything


242
00:07:10,566 --> 00:07:12,326
at all, and you start processing


243
00:07:12,326 --> 00:07:13,556
that request, here's what's


244
00:07:13,556 --> 00:07:14,916
going to happen.


245
00:07:14,916 --> 00:07:17,076
By default, you're getting the


246
00:07:17,076 --> 00:07:18,956
latest revision of the request


247
00:07:19,376 --> 00:07:20,436
that your app is linked


248
00:07:20,436 --> 00:07:22,516
against-- of the SDK that your


249
00:07:22,516 --> 00:07:23,596
app is linked against.


250
00:07:23,986 --> 00:07:25,376
This is important to understand,


251
00:07:25,376 --> 00:07:26,276
and I'll give you an example.


252
00:07:27,116 --> 00:07:28,386
Let's say your app is linked


253
00:07:28,386 --> 00:07:29,546
against there's the SDK from the


254
00:07:29,546 --> 00:07:30,056
last year.


255
00:07:30,696 --> 00:07:32,306
Last year, we had only single


256
00:07:32,306 --> 00:07:32,746
detector.


257
00:07:33,316 --> 00:07:34,406
So, this is the detector you're


258
00:07:34,406 --> 00:07:36,436
going to get, even if you take


259
00:07:36,436 --> 00:07:37,506
that app and without a


260
00:07:37,506 --> 00:07:38,676
compilation, run it on the


261
00:07:38,676 --> 00:07:39,366
current OS.


262
00:07:40,586 --> 00:07:42,456
If, on the other hand, you


263
00:07:42,456 --> 00:07:44,026
recompile your app with the


264
00:07:44,026 --> 00:07:45,756
current SDK without changing a


265
00:07:45,756 --> 00:07:47,466
single line or coordinate, and


266
00:07:47,466 --> 00:07:48,806
you run it on the current OS,


267
00:07:48,926 --> 00:07:49,986
you're going to get by default


268
00:07:49,986 --> 00:07:51,436
revision #2 because this is the


269
00:07:51,436 --> 00:07:54,716
way this from the current SDK.


270
00:07:54,946 --> 00:07:56,016
We highly recommend you to


271
00:07:56,016 --> 00:07:57,646
future-proof your apps, but


272
00:07:57,646 --> 00:07:58,906
again it's exclusive to Vision.


273
00:07:59,436 --> 00:08:01,246
What you get is, first, you get


274
00:08:01,246 --> 00:08:02,416
the deterministic behavior.


275
00:08:03,026 --> 00:08:04,846
You know performance of the


276
00:08:04,846 --> 00:08:06,636
algorithm that you're quoting


277
00:08:06,636 --> 00:08:06,976
against.


278
00:08:07,356 --> 00:08:08,356
You know what to expect.


279
00:08:08,846 --> 00:08:10,526
We also can be-- you can get


280
00:08:10,526 --> 00:08:12,596
your app to be future-proof from


281
00:08:12,596 --> 00:08:14,106
the errors like, for example, if


282
00:08:14,106 --> 00:08:15,606
we deprecate certain revision


283
00:08:15,796 --> 00:08:16,956
going forward, like a couple of


284
00:08:16,956 --> 00:08:18,766
years from now, then you can


285
00:08:18,836 --> 00:08:21,186
[inaudible]against that


286
00:08:22,156 --> 00:08:22,306
[inaudible] today.


287
00:08:25,176 --> 00:08:26,996
Let's have a deeper dive into


288
00:08:27,106 --> 00:08:31,916
how to interact with Vision API.


289
00:08:32,066 --> 00:08:32,866
First, we're going to look at


290
00:08:32,866 --> 00:08:33,986
the example with Image Request


291
00:08:33,986 --> 00:08:34,226
Handler.


292
00:08:35,676 --> 00:08:36,716
So, as you remember, image


293
00:08:36,716 --> 00:08:37,706
request handler is used to


294
00:08:37,706 --> 00:08:39,996
process one or more requests on


295
00:08:39,996 --> 00:08:40,676
the same image.


296
00:08:41,316 --> 00:08:44,516
It's optimized by caching some


297
00:08:44,516 --> 00:08:45,446
information like image


298
00:08:45,446 --> 00:08:46,956
derivatives and request results.


299
00:08:47,316 --> 00:08:49,206
So, the consecutive requests


300
00:08:49,286 --> 00:08:50,636
that are coming to be processed


301
00:08:51,136 --> 00:08:52,236
can use this information.


302
00:08:53,446 --> 00:08:57,026
Let's look at code sample.


303
00:08:57,026 --> 00:08:58,216
Before we dive into the code


304
00:08:58,216 --> 00:08:59,286
sample, I just want to emphasize


305
00:08:59,286 --> 00:09:00,546
a couple of points about the


306
00:09:01,126 --> 00:09:01,866
code samples in this


307
00:09:01,866 --> 00:09:02,506
presentation.


308
00:09:03,376 --> 00:09:04,956
The error handling is not a good


309
00:09:04,956 --> 00:09:06,136
example how errors should be


310
00:09:06,136 --> 00:09:06,526
handled.


311
00:09:06,526 --> 00:09:07,796
I use a short version of try,


312
00:09:07,876 --> 00:09:09,026
and I use [inaudible].


313
00:09:09,746 --> 00:09:11,136
This is just to simplify the


314
00:09:11,136 --> 00:09:11,686
examples.


315
00:09:11,996 --> 00:09:12,906
When you code your apps, you


316
00:09:12,906 --> 00:09:14,356
probably should use guards to


317
00:09:14,356 --> 00:09:15,526
protect against unwanted


318
00:09:15,526 --> 00:09:15,946
behavior.


319
00:09:17,186 --> 00:09:20,086
I also use Image URL when I


320
00:09:20,256 --> 00:09:22,346
create my image request handler


321
00:09:22,346 --> 00:09:24,416
objects, and that is just a


322
00:09:24,416 --> 00:09:26,716
place on the SSD where the file


323
00:09:26,716 --> 00:09:27,236
is located.


324
00:09:28,516 --> 00:09:29,416
Now, let's look at example.


325
00:09:30,746 --> 00:09:32,046
First, I'm going to create my


326
00:09:32,206 --> 00:09:34,346
detect faces request object.


327
00:09:35,136 --> 00:09:36,476
Then, I'm going to create my


328
00:09:36,476 --> 00:09:38,036
image request handler passing


329
00:09:38,036 --> 00:09:40,036
the image URL with the file of


330
00:09:40,036 --> 00:09:41,866
the image where the faces should


331
00:09:41,866 --> 00:09:42,336
be located.


332
00:09:43,246 --> 00:09:44,526
Then, I'm going to ask my


333
00:09:44,526 --> 00:09:45,716
request handler to process my


334
00:09:45,716 --> 00:09:46,186
request.


335
00:09:46,706 --> 00:09:47,796
And finally, I'm going to look


336
00:09:47,796 --> 00:09:48,500
at the results.


337
00:09:50,046 --> 00:09:50,506
Very simple.


338
00:09:51,016 --> 00:09:52,276
If I had an image with a single


339
00:09:52,276 --> 00:09:54,036
face in it, my results would


340
00:09:54,036 --> 00:09:55,330
look something like this.


341
00:10:00,136 --> 00:10:01,076
So, what I get back?


342
00:10:01,076 --> 00:10:02,626
I get back a face observation


343
00:10:02,626 --> 00:10:04,116
object, and the one of the more


344
00:10:04,116 --> 00:10:05,496
important fields in that object


345
00:10:05,496 --> 00:10:06,576
is the bounding box where the


346
00:10:06,576 --> 00:10:07,336
face is located.


347
00:10:09,116 --> 00:10:10,836
Let's take a look at this slide


348
00:10:10,836 --> 00:10:11,156
again.


349
00:10:11,156 --> 00:10:12,976
The first three lines is pretty


350
00:10:12,976 --> 00:10:14,446
much all you need to find all


351
00:10:14,446 --> 00:10:15,426
the faces in the image.


352
00:10:15,636 --> 00:10:16,296
Isn't that cool?


353
00:10:18,516 --> 00:10:22,306
[ Applause ]


354
00:10:22,806 --> 00:10:23,656
Let's now take a look at the


355
00:10:23,656 --> 00:10:25,246
Sequence Request Handler.


356
00:10:27,636 --> 00:10:28,956
Well, sequence request handler,


357
00:10:28,956 --> 00:10:29,846
as you remember, is used to


358
00:10:29,846 --> 00:10:31,726
process a particular operation


359
00:10:31,726 --> 00:10:33,566
like tracking on a sequence of


360
00:10:33,566 --> 00:10:34,006
frames.


361
00:10:35,486 --> 00:10:36,646
Let's look at code sample, and


362
00:10:36,646 --> 00:10:38,406
this code sample is pretty much


363
00:10:38,406 --> 00:10:40,646
the simplest tracking sequence


364
00:10:40,646 --> 00:10:42,246
we can imagine with Vision API.


365
00:10:43,556 --> 00:10:45,056
First, I'm going to create my


366
00:10:45,226 --> 00:10:46,096
Sequence Request Handler.


367
00:10:47,416 --> 00:10:49,116
Then, I need to specify which


368
00:10:49,116 --> 00:10:50,436
object I want to track, and I'm


369
00:10:50,436 --> 00:10:52,126
going to do that by creating a


370
00:10:52,126 --> 00:10:53,926
detected object observation,


371
00:10:53,926 --> 00:10:55,536
which gets us a parameter


372
00:10:55,876 --> 00:10:57,496
location, a bounding box.


373
00:10:58,806 --> 00:11:00,256
Then, I'm going to start my


374
00:11:00,256 --> 00:11:01,056
tracking signals.


375
00:11:01,786 --> 00:11:03,486
In this example, I'm going to


376
00:11:03,486 --> 00:11:04,676
track my object for five


377
00:11:04,676 --> 00:11:05,626
consecutive frames.


378
00:11:06,896 --> 00:11:07,876
Let's look how the sequence


379
00:11:07,876 --> 00:11:08,236
works.


380
00:11:08,826 --> 00:11:10,636
First, I have a frame feeder


381
00:11:10,636 --> 00:11:11,946
object, which in your case could


382
00:11:11,946 --> 00:11:13,206
be like camera feed, for


383
00:11:13,206 --> 00:11:13,566
example.


384
00:11:14,326 --> 00:11:15,546
This is where I get my frames.


385
00:11:15,546 --> 00:11:18,416
I get my frame, I create my


386
00:11:18,416 --> 00:11:19,666
request object, passing the


387
00:11:19,666 --> 00:11:21,456
detected object observation as a


388
00:11:21,456 --> 00:11:23,886
parameter with its initializer.


389
00:11:24,326 --> 00:11:25,706
And that's something that I just


390
00:11:25,706 --> 00:11:26,876
created before the loop started.


391
00:11:27,496 --> 00:11:29,596
Then, I'm going to ask my


392
00:11:29,596 --> 00:11:31,296
request handler to process


393
00:11:31,296 --> 00:11:31,666
request.


394
00:11:32,296 --> 00:11:34,396
I'm going to look at the


395
00:11:34,396 --> 00:11:35,646
results, and this is the place


396
00:11:35,646 --> 00:11:37,166
where I should be analyzing


397
00:11:37,166 --> 00:11:38,376
results and doing something with


398
00:11:38,376 --> 00:11:38,626
them.


399
00:11:39,246 --> 00:11:41,766
And the last step, which is very


400
00:11:41,766 --> 00:11:43,426
important, what I'm doing here,


401
00:11:43,776 --> 00:11:44,956
I'm taking the results from the


402
00:11:44,956 --> 00:11:46,196
current iteration, and I'm


403
00:11:46,236 --> 00:11:47,376
passing it to the next


404
00:11:47,376 --> 00:11:48,026
iteration.


405
00:11:48,356 --> 00:11:49,426
So, when the next iteration


406
00:11:49,426 --> 00:11:50,846
request is created, I want to


407
00:11:50,846 --> 00:11:51,846
see those results inside.


408
00:11:51,846 --> 00:11:53,456
If I were to want it in a


409
00:11:53,606 --> 00:11:54,786
sequence of five frames, my


410
00:11:54,786 --> 00:11:55,756
results would look something


411
00:11:55,756 --> 00:11:55,976
like this.


412
00:12:06,196 --> 00:12:07,726
How to create a request object.


413
00:12:07,726 --> 00:12:10,616
Well, first, it's important to


414
00:12:10,616 --> 00:12:11,846
understand that our requests


415
00:12:11,846 --> 00:12:13,066
have two types of properties.


416
00:12:13,416 --> 00:12:14,706
There are mandatory properties


417
00:12:14,816 --> 00:12:15,766
and there are optional


418
00:12:15,766 --> 00:12:16,346
properties.


419
00:12:16,696 --> 00:12:18,406
And mandatory properties, as the


420
00:12:18,406 --> 00:12:20,066
name suggests, they need to be


421
00:12:20,066 --> 00:12:21,826
provided via initializer in


422
00:12:21,826 --> 00:12:23,696
order to be able to create a


423
00:12:23,696 --> 00:12:24,436
request object.


424
00:12:24,436 --> 00:12:26,826
Let's look at the example.


425
00:12:28,216 --> 00:12:29,766
There is something that would


426
00:12:29,766 --> 00:12:30,926
just go in the previous slide.


427
00:12:31,636 --> 00:12:33,046
I detected object observation


428
00:12:33,046 --> 00:12:34,366
that is passed into the


429
00:12:34,536 --> 00:12:35,686
initializer of the [inaudible]


430
00:12:35,686 --> 00:12:37,676
object request is an example of


431
00:12:37,676 --> 00:12:39,396
a mandatory property.


432
00:12:40,356 --> 00:12:41,486
We also have optional


433
00:12:41,486 --> 00:12:42,066
properties.


434
00:12:43,466 --> 00:12:44,276
By the way, both types of


435
00:12:44,276 --> 00:12:45,396
properties are declared.


436
00:12:45,866 --> 00:12:47,026
You can find them in the place


437
00:12:47,026 --> 00:12:49,906
where the request object is


438
00:12:50,696 --> 00:12:50,946
declared.


439
00:12:51,016 --> 00:12:53,076
Optional properties is separate


440
00:12:53,076 --> 00:12:54,306
properties where we have


441
00:12:54,336 --> 00:12:55,506
meaningful defaults for them.


442
00:12:55,976 --> 00:12:57,306
So, we'll initialize them for


443
00:12:57,306 --> 00:12:58,776
you, but you can override them


444
00:12:58,776 --> 00:12:59,656
later if you need to.


445
00:13:00,546 --> 00:13:05,906
Let's look at the example.


446
00:13:05,906 --> 00:13:06,776
What I'm doing here, I'm


447
00:13:06,776 --> 00:13:08,106
breaking my detect barcodes


448
00:13:08,106 --> 00:13:08,756
request object.


449
00:13:09,616 --> 00:13:11,256
If I were to do nothing else and


450
00:13:11,256 --> 00:13:12,856
just took my request object and


451
00:13:12,856 --> 00:13:15,256
fed it into request handler, I


452
00:13:15,256 --> 00:13:16,586
would be working on the entire


453
00:13:16,586 --> 00:13:18,416
image, looking for my barcodes.


454
00:13:19,176 --> 00:13:20,066
What I'm going to do here


455
00:13:20,066 --> 00:13:22,316
instead, I'm going to specify a


456
00:13:22,316 --> 00:13:23,746
small portion like a central


457
00:13:23,746 --> 00:13:24,516
property image.


458
00:13:24,966 --> 00:13:25,716
There's this where I want to


459
00:13:25,716 --> 00:13:27,506
focus to look for my barcodes,


460
00:13:27,556 --> 00:13:29,186
and I'm going to overwrite my


461
00:13:29,186 --> 00:13:30,466
region of interest property with


462
00:13:30,466 --> 00:13:30,696
that.


463
00:13:31,476 --> 00:13:32,886
If I take my request object now


464
00:13:32,886 --> 00:13:33,976
and feed it into request


465
00:13:33,976 --> 00:13:35,046
handler, I'm going to be


466
00:13:35,046 --> 00:13:36,406
focusing on the smaller portion


467
00:13:36,406 --> 00:13:37,116
of the image only.


468
00:13:38,166 --> 00:13:39,586
A region of interest property


469
00:13:39,776 --> 00:13:41,496
here is an example of the


470
00:13:41,496 --> 00:13:42,646
optional property that we have.


471
00:13:43,776 --> 00:13:45,026
What's important to understand


472
00:13:45,026 --> 00:13:47,896
here also that once you get a


473
00:13:47,896 --> 00:13:49,186
request object in your hands,


474
00:13:49,436 --> 00:13:50,956
it's a fully constructed object.


475
00:13:51,656 --> 00:13:52,546
It's the object that you can


476
00:13:52,546 --> 00:13:54,226
start working with whenever you


477
00:13:54,226 --> 00:13:55,366
have constructed objects.


478
00:13:55,716 --> 00:13:56,736
If you decide to overwrite


479
00:13:56,736 --> 00:13:58,396
certain properties later on,


480
00:13:58,716 --> 00:13:59,766
you're welcome to do so.


481
00:14:00,036 --> 00:14:01,076
But whenever you have the


482
00:14:01,076 --> 00:14:02,816
object, it's the object that you


483
00:14:02,816 --> 00:14:04,500
can work with.


484
00:14:07,536 --> 00:14:08,526
One thing that's not maybe on


485
00:14:08,526 --> 00:14:09,776
this slide is, which will be


486
00:14:09,776 --> 00:14:10,866
covered in more details in the


487
00:14:10,866 --> 00:14:14,556
next session, is to look at the


488
00:14:14,556 --> 00:14:15,406
bounding boxes.


489
00:14:16,046 --> 00:14:18,456
As you can see, the coordinates


490
00:14:18,456 --> 00:14:20,306
that we receive are normalized.


491
00:14:20,856 --> 00:14:22,576
They are from 0 to 1 and they're


492
00:14:22,576 --> 00:14:23,976
always relative to the lower


493
00:14:23,976 --> 00:14:24,446
left corner.


494
00:14:25,146 --> 00:14:26,166
The next session, which is


495
00:14:26,166 --> 00:14:27,506
CoreML integration with Vision,


496
00:14:27,716 --> 00:14:29,196
will cover this aspect in more


497
00:14:29,196 --> 00:14:29,686
details.


498
00:14:33,336 --> 00:14:34,806
Let's look at how to understand


499
00:14:34,806 --> 00:14:35,256
results.


500
00:14:35,906 --> 00:14:38,616
As we said, results in Vision


501
00:14:38,616 --> 00:14:40,266
come in forms of observations.


502
00:14:41,766 --> 00:14:43,726
Observations are populated


503
00:14:43,726 --> 00:14:45,046
through results property of the


504
00:14:45,046 --> 00:14:45,696
request object.


505
00:14:46,466 --> 00:14:47,526
How many observations can you


506
00:14:47,526 --> 00:14:47,806
get?


507
00:14:48,396 --> 00:14:51,726
All the collection be 0 to N.


508
00:14:52,596 --> 00:14:53,726
There's one more aspect here.


509
00:14:54,046 --> 00:14:55,796
If you get results set to nil,


510
00:14:55,796 --> 00:14:57,096
that means that the [inaudible]


511
00:14:57,096 --> 00:14:58,286
single request failed.


512
00:14:58,806 --> 00:15:00,516
This is different than getting 0


513
00:15:00,516 --> 00:15:01,256
observations met.


514
00:15:01,956 --> 00:15:03,666
Getting 0 observations met means


515
00:15:03,666 --> 00:15:04,736
that whatever you were looking


516
00:15:04,736 --> 00:15:05,946
for is just not there.


517
00:15:05,946 --> 00:15:08,796
As an example, let's say you run


518
00:15:08,796 --> 00:15:09,526
a face detector.


519
00:15:10,816 --> 00:15:11,846
If you feed an image with no


520
00:15:11,846 --> 00:15:13,306
faces in it, naturally, you will


521
00:15:13,306 --> 00:15:14,476
get 0 observations met.


522
00:15:15,416 --> 00:15:16,596
On the other hand, if you feed


523
00:15:16,596 --> 00:15:18,336
the image with one or more faces


524
00:15:18,726 --> 00:15:20,896
in it, you'll get appropriate


525
00:15:20,896 --> 00:15:22,606
number of observations met.


526
00:15:24,036 --> 00:15:25,506
Another important property of


527
00:15:25,506 --> 00:15:27,196
observations is that


528
00:15:27,326 --> 00:15:28,446
observations are immutable.


529
00:15:28,446 --> 00:15:30,016
We will look at the example


530
00:15:30,576 --> 00:15:31,696
where it's used.


531
00:15:32,196 --> 00:15:34,286
There are two more properties


532
00:15:34,286 --> 00:15:34,996
that I want to pay your


533
00:15:34,996 --> 00:15:36,406
attention to, and they are both


534
00:15:36,406 --> 00:15:37,566
declared in the base [inaudible]


535
00:15:37,566 --> 00:15:38,846
for all observations.


536
00:15:39,286 --> 00:15:40,416
One is the unique ID.


537
00:15:41,056 --> 00:15:42,586
This unique ID identifies the


538
00:15:42,586 --> 00:15:44,326
processing step for this


539
00:15:44,326 --> 00:15:45,226
particular-- where this


540
00:15:45,226 --> 00:15:46,666
particular result was created.


541
00:15:47,576 --> 00:15:48,836
Another one is the confidence


542
00:15:48,836 --> 00:15:49,136
level.


543
00:15:50,376 --> 00:15:51,756
Confidence level tells you how


544
00:15:51,756 --> 00:15:53,126
confident the algorithm was


545
00:15:53,376 --> 00:15:54,316
producing the results.


546
00:15:55,596 --> 00:15:57,756
The confidence is in the range


547
00:15:57,756 --> 00:15:58,526
from 0 to 1.


548
00:15:59,176 --> 00:16:00,646
Again, this topic also will be


549
00:16:00,646 --> 00:16:02,166
covered in the next session in


550
00:16:02,166 --> 00:16:03,366
more details.


551
00:16:06,876 --> 00:16:08,086
Let's look at the request


552
00:16:08,086 --> 00:16:08,706
pipelines.


553
00:16:09,786 --> 00:16:10,666
So, what is a pipeline?


554
00:16:11,736 --> 00:16:13,286
Let's say I have three requests,


555
00:16:13,286 --> 00:16:14,266
and it happens to be that


556
00:16:14,266 --> 00:16:16,476
request #1 depends on execution


557
00:16:16,476 --> 00:16:18,136
of request #2, which in turn


558
00:16:18,396 --> 00:16:20,226
depends on execution of request


559
00:16:20,826 --> 00:16:21,936
#3.


560
00:16:22,126 --> 00:16:23,456
How do we process the sequence


561
00:16:23,966 --> 00:16:25,456
while the processing is done in


562
00:16:25,456 --> 00:16:26,246
the opposite order?


563
00:16:26,806 --> 00:16:27,676
What I'm going to do here,


564
00:16:27,846 --> 00:16:29,246
first, I'm going to process my


565
00:16:29,246 --> 00:16:30,106
request #3.


566
00:16:30,476 --> 00:16:31,456
I'm going to get the results


567
00:16:31,456 --> 00:16:32,876
from that request and feed it


568
00:16:32,876 --> 00:16:33,876
into request #2.


569
00:16:34,086 --> 00:16:35,556
I'm going to do exactly the same


570
00:16:35,556 --> 00:16:36,516
with request #2.


571
00:16:36,786 --> 00:16:38,316
And finally, I will process my


572
00:16:38,316 --> 00:16:39,116
request #1.


573
00:16:41,296 --> 00:16:43,036
Let's look at the examples of


574
00:16:43,036 --> 00:16:45,976
how to run request pipeline in


575
00:16:45,976 --> 00:16:47,636
implicit and explicit order.


576
00:16:48,326 --> 00:16:49,196
We're going to look at the next


577
00:16:49,196 --> 00:16:50,426
two slides in these two use


578
00:16:50,426 --> 00:16:52,126
cases, and we're going to run


579
00:16:52,126 --> 00:16:53,746
our face landmarks detector.


580
00:16:54,386 --> 00:16:55,936
As you probably know, landmarks,


581
00:16:55,996 --> 00:16:58,026
face landmarks are the features


582
00:16:58,026 --> 00:16:58,526
on the face.


583
00:16:58,526 --> 00:17:00,236
It's both your eyes, eyebrows,


584
00:17:00,236 --> 00:17:01,726
nose, and mouth location on your


585
00:17:01,726 --> 00:17:02,016
face.


586
00:17:02,996 --> 00:17:05,425
Let's first look at how to do it


587
00:17:05,425 --> 00:17:05,955
implicitly.


588
00:17:13,675 --> 00:17:14,955
I have a simple [inaudible] a


589
00:17:14,955 --> 00:17:16,266
bit similar to what we have seen


590
00:17:16,266 --> 00:17:16,646
already.


591
00:17:17,195 --> 00:17:18,205
First, I'm going to create my


592
00:17:18,205 --> 00:17:19,316
face landmarks request.


593
00:17:20,566 --> 00:17:22,036
Then, I'm going to create my


594
00:17:22,036 --> 00:17:22,846
image request handler.


595
00:17:23,836 --> 00:17:25,006
Then, I'm going to process my


596
00:17:25,006 --> 00:17:25,415
request.


597
00:17:26,246 --> 00:17:27,256
And finally, I'm going to look


598
00:17:27,256 --> 00:17:27,836
at the results.


599
00:17:28,936 --> 00:17:30,136
If I had an image with a single


600
00:17:30,136 --> 00:17:31,976
face in it, my results would


601
00:17:31,976 --> 00:17:35,276
look something like this.


602
00:17:35,406 --> 00:17:35,716
Sorry.


603
00:17:36,066 --> 00:17:39,076
N is for the sequence, and the


604
00:17:39,306 --> 00:17:39,836
results.


605
00:17:40,846 --> 00:17:42,046
So, I get the bounding box of


606
00:17:42,046 --> 00:17:42,536
the face.


607
00:17:43,036 --> 00:17:43,866
That's the location for the


608
00:17:43,866 --> 00:17:46,436
face, and I get the landmarks


609
00:17:46,686 --> 00:17:47,166
for the face.


610
00:17:48,576 --> 00:17:49,786
What's important to understand


611
00:17:49,786 --> 00:17:51,376
here is that when the processing


612
00:17:51,376 --> 00:17:52,726
of the face landmark request


613
00:17:52,726 --> 00:17:54,776
starts, face landmarks request


614
00:17:55,136 --> 00:17:56,906
figures out that faces have not


615
00:17:56,906 --> 00:17:59,316
been detected yet, and it runs


616
00:17:59,316 --> 00:18:01,136
on our behalf inside face


617
00:18:01,136 --> 00:18:01,546
detector.


618
00:18:02,106 --> 00:18:03,686
It gets results from that face


619
00:18:03,686 --> 00:18:05,306
detector, and that's where


620
00:18:05,306 --> 00:18:06,536
landmarks are being searched


621
00:18:06,536 --> 00:18:06,716
for.


622
00:18:08,716 --> 00:18:10,896
On the right-hand side, you can


623
00:18:11,306 --> 00:18:14,186
see a snippet of what face


624
00:18:14,186 --> 00:18:15,386
observation object would look


625
00:18:15,386 --> 00:18:15,566
like.


626
00:18:15,816 --> 00:18:16,576
These are just a couple of


627
00:18:16,576 --> 00:18:17,446
fields from that object.


628
00:18:17,806 --> 00:18:19,296
One is a unique ID that we


629
00:18:19,296 --> 00:18:20,376
discussed that is set to some


630
00:18:20,376 --> 00:18:20,956
unique number.


631
00:18:21,656 --> 00:18:23,316
Then, the bounding box, that's


632
00:18:23,316 --> 00:18:25,216
where the face is located, and


633
00:18:25,216 --> 00:18:26,436
then, finally, the landmarks


634
00:18:26,436 --> 00:18:27,936
field, which points to some


635
00:18:27,936 --> 00:18:29,216
object where the landmarks are


636
00:18:29,216 --> 00:18:29,656
described.


637
00:18:33,526 --> 00:18:35,236
Now, let's take a look at the


638
00:18:35,236 --> 00:18:37,716
same use case but now done


639
00:18:37,716 --> 00:18:38,336
explicitly.


640
00:18:40,416 --> 00:18:41,556
What I'm going to do here


641
00:18:41,556 --> 00:18:42,876
first-- first, I'm going to


642
00:18:42,876 --> 00:18:44,486
explicitly run my face detector.


643
00:18:45,116 --> 00:18:47,516
You've seen these four lines of


644
00:18:47,516 --> 00:18:49,076
code already several times in


645
00:18:49,076 --> 00:18:49,796
the presentation.


646
00:18:49,856 --> 00:18:51,346
When I run it, I get my bounding


647
00:18:51,346 --> 00:18:51,786
box back.


648
00:18:52,606 --> 00:18:54,376
As you can see, the results are


649
00:18:54,376 --> 00:18:56,016
returned in the same type, face


650
00:18:56,016 --> 00:18:56,616
observation.


651
00:18:57,276 --> 00:18:58,796
The fields that we saw on the


652
00:18:58,796 --> 00:18:59,946
previous slide may look like


653
00:18:59,946 --> 00:19:01,176
this, so you get some unique


654
00:19:01,176 --> 00:19:02,226
number to identify this


655
00:19:02,226 --> 00:19:03,386
particular processing step.


656
00:19:04,146 --> 00:19:05,326
Then, you get the bounding box


657
00:19:05,326 --> 00:19:06,476
location, which is the main


658
00:19:06,476 --> 00:19:08,326
outcome of processing this


659
00:19:08,326 --> 00:19:08,716
request.


660
00:19:08,946 --> 00:19:10,616
And the landmarks field is set


661
00:19:10,616 --> 00:19:11,916
to nil because face detector


662
00:19:11,916 --> 00:19:12,986
doesn't know anything about


663
00:19:12,986 --> 00:19:13,496
landmarks.


664
00:19:14,856 --> 00:19:16,246
What I'm going to do next is I'm


665
00:19:16,336 --> 00:19:17,526
going to create my landmarks


666
00:19:17,526 --> 00:19:19,266
request, and then I'm going to


667
00:19:19,266 --> 00:19:20,096
take the results from the


668
00:19:20,096 --> 00:19:22,166
previous step and feed it into


669
00:19:22,166 --> 00:19:23,446
the input object observation


670
00:19:23,496 --> 00:19:24,556
property of that request.


671
00:19:25,996 --> 00:19:26,866
Then, I'm going to ask my


672
00:19:27,066 --> 00:19:28,336
request handler to process it.


673
00:19:29,306 --> 00:19:30,206
And finally, I'm going to look


674
00:19:30,206 --> 00:19:30,836
at the results.


675
00:19:31,726 --> 00:19:33,396
If I run it in the same image, I


676
00:19:33,396 --> 00:19:35,146
get exactly the same results as


677
00:19:35,146 --> 00:19:37,786
I would on the previous slide.


678
00:19:38,726 --> 00:19:39,836
But let's see what happens with


679
00:19:39,836 --> 00:19:40,486
observations.


680
00:19:40,996 --> 00:19:41,826
Remember, we said that


681
00:19:41,826 --> 00:19:43,906
observations are immutable even


682
00:19:43,906 --> 00:19:45,876
though both face detector and


683
00:19:45,876 --> 00:19:48,136
face landmarks detector return


684
00:19:48,136 --> 00:19:50,006
the same type, but we don't


685
00:19:50,036 --> 00:19:51,766
override the observation that


686
00:19:51,976 --> 00:19:52,656
was fed in.


687
00:19:53,296 --> 00:19:54,716
What we do instead, we take the


688
00:19:54,716 --> 00:19:56,696
first two fields and copy it


689
00:19:56,696 --> 00:19:58,776
into a new object, and then we


690
00:19:58,776 --> 00:20:00,326
calculate landmarks and populate


691
00:20:00,326 --> 00:20:01,036
the landmarks field.


692
00:20:02,246 --> 00:20:03,726
Now, if you look now, you will


693
00:20:03,726 --> 00:20:05,246
notice that the UID in most


694
00:20:05,246 --> 00:20:06,356
cases is the same.


695
00:20:07,286 --> 00:20:07,796
Why is that?


696
00:20:08,266 --> 00:20:09,366
Because we're talking about the


697
00:20:09,366 --> 00:20:10,026
same face.


698
00:20:10,026 --> 00:20:11,916
It's the same processing step,


699
00:20:11,956 --> 00:20:14,046
if you will.


700
00:20:14,266 --> 00:20:15,526
Where would you use implicit


701
00:20:15,526 --> 00:20:16,326
versus explicit?


702
00:20:17,406 --> 00:20:18,516
Well, if your application is


703
00:20:18,516 --> 00:20:20,566
very simple, you would probably


704
00:20:20,726 --> 00:20:22,006
want to opt for implicit way.


705
00:20:22,406 --> 00:20:23,046
It's very simple.


706
00:20:23,046 --> 00:20:24,106
You create a single request;


707
00:20:24,106 --> 00:20:25,466
everything else is done on your


708
00:20:25,466 --> 00:20:26,606
behalf.


709
00:20:28,706 --> 00:20:30,236
If, on the other hand, your


710
00:20:30,236 --> 00:20:31,686
application is more complex, for


711
00:20:31,686 --> 00:20:33,106
example, you want to process


712
00:20:33,106 --> 00:20:35,076
faces first, detect them, then


713
00:20:35,076 --> 00:20:35,916
do some filtering.


714
00:20:36,006 --> 00:20:37,186
Let's say you don't care about


715
00:20:37,186 --> 00:20:38,366
faces on the periphery, or you


716
00:20:38,366 --> 00:20:39,986
want to just focus on the ones


717
00:20:39,986 --> 00:20:42,046
that are in the center, you can


718
00:20:42,046 --> 00:20:44,026
do that step, and then you can


719
00:20:44,026 --> 00:20:45,576
do landmarks on the remaining


720
00:20:45,576 --> 00:20:46,436
set of faces.


721
00:20:47,276 --> 00:20:48,476
In this case, you probably want


722
00:20:48,476 --> 00:20:49,566
to use the explicit version


723
00:20:50,626 --> 00:20:52,566
because, in this case, landmarks


724
00:20:52,656 --> 00:20:54,236
detector is not going to rerun


725
00:20:54,306 --> 00:20:54,936
face detector inside.


726
00:21:02,566 --> 00:21:03,616
We want your apps to have


727
00:21:03,866 --> 00:21:05,136
optimal performance both in


728
00:21:05,136 --> 00:21:06,576
terms of memory usage and


729
00:21:06,576 --> 00:21:07,356
execution speed.


730
00:21:07,466 --> 00:21:08,486
That's why it's important to


731
00:21:08,486 --> 00:21:09,586
look at the next two slides.


732
00:21:11,696 --> 00:21:12,956
How long should you keep your


733
00:21:12,956 --> 00:21:14,346
objects in memory?


734
00:21:16,756 --> 00:21:17,956
Well, for the image request


735
00:21:17,956 --> 00:21:19,356
handler, you should keep it as


736
00:21:19,416 --> 00:21:21,066
long as the image needs


737
00:21:21,066 --> 00:21:21,486
processing.


738
00:21:22,356 --> 00:21:23,716
This may sound like a very


739
00:21:23,716 --> 00:21:24,936
innocent and simple statement,


740
00:21:25,296 --> 00:21:26,496
but it is very important that


741
00:21:26,496 --> 00:21:28,296
you do just that.


742
00:21:28,296 --> 00:21:29,736
If you release the object early,


743
00:21:29,736 --> 00:21:31,066
and you still have outstanding


744
00:21:31,066 --> 00:21:32,446
requests to be processed, you


745
00:21:32,446 --> 00:21:33,716
will have to recreate your image


746
00:21:33,716 --> 00:21:34,386
to request handler.


747
00:21:34,716 --> 00:21:36,346
But now you have lost all the


748
00:21:36,346 --> 00:21:37,676
cache that was associated with


749
00:21:37,676 --> 00:21:39,066
the previous object, and you'll


750
00:21:39,066 --> 00:21:40,636
have to pay this performance to


751
00:21:40,636 --> 00:21:42,036
recalculate these derivatives.


752
00:21:42,666 --> 00:21:45,386
If you release it too late, on


753
00:21:45,386 --> 00:21:47,546
the other hand, then, first


754
00:21:47,546 --> 00:21:48,486
you're going to start causing


755
00:21:48,486 --> 00:21:50,196
memory fragmentation, and then


756
00:21:50,196 --> 00:21:51,416
the memory is not going to be


757
00:21:51,416 --> 00:21:53,006
reclaimed by your app for other


758
00:21:53,006 --> 00:21:54,606
meaningful things that you want


759
00:21:54,606 --> 00:21:55,500
to do.


760
00:21:56,156 --> 00:21:57,696
So, it's important to release


761
00:21:57,696 --> 00:21:59,236
it, use it as long as you need


762
00:21:59,236 --> 00:22:00,176
and release it right after.


763
00:22:00,826 --> 00:22:02,316
Remember, it caches the image


764
00:22:02,386 --> 00:22:03,896
and multiple image derivatives


765
00:22:03,896 --> 00:22:04,226
inside.


766
00:22:06,156 --> 00:22:08,116
The situation with sequence


767
00:22:08,116 --> 00:22:09,396
request handler is very similar


768
00:22:09,736 --> 00:22:11,196
with the only difference is if


769
00:22:11,196 --> 00:22:12,526
you release it too early, you


770
00:22:12,526 --> 00:22:13,536
pretty much kill the entire


771
00:22:13,536 --> 00:22:14,846
sequence because the entire


772
00:22:14,846 --> 00:22:18,176
cache is gone by now.


773
00:22:18,406 --> 00:22:20,076
What about requests and


774
00:22:20,076 --> 00:22:20,806
observations?


775
00:22:21,686 --> 00:22:23,516
Well, requests and observations


776
00:22:23,996 --> 00:22:25,206
are very lightweight objects.


777
00:22:25,576 --> 00:22:26,656
You can create them and release


778
00:22:26,656 --> 00:22:27,256
them as needed.


779
00:22:27,556 --> 00:22:28,426
There's no need to cache them.


780
00:22:35,596 --> 00:22:36,876
Where should we process your


781
00:22:37,976 --> 00:22:38,236
requests?


782
00:22:39,636 --> 00:22:41,366
Well many requests in Vision


783
00:22:41,366 --> 00:22:42,856
rely on running neural networks


784
00:22:42,856 --> 00:22:43,436
on the device.


785
00:22:44,266 --> 00:22:45,996
And, as we know, running neural


786
00:22:45,996 --> 00:22:47,616
networks is usually faster on


787
00:22:47,616 --> 00:22:49,216
GPU versus the CPU.


788
00:22:49,926 --> 00:22:53,066
So, the natural question is


789
00:22:53,176 --> 00:22:54,706
where should we run it?


790
00:22:55,476 --> 00:22:56,756
Here's what we do in Vision.


791
00:22:57,716 --> 00:22:59,636
If request is runnable in GPU,


792
00:22:59,636 --> 00:23:01,236
we will try to do that first.


793
00:23:01,996 --> 00:23:03,346
If GPU is not available for


794
00:23:03,346 --> 00:23:04,616
whatever reason at that point in


795
00:23:04,616 --> 00:23:06,176
time, we will switch to CPU


796
00:23:06,766 --> 00:23:08,896
because that's our default


797
00:23:08,896 --> 00:23:09,306
behavior.


798
00:23:09,946 --> 00:23:12,846
But let's say your application


799
00:23:13,326 --> 00:23:14,876
is dependent on displaying a lot


800
00:23:14,876 --> 00:23:16,306
of graphics on the screen, so


801
00:23:16,306 --> 00:23:18,276
you may want to save the GPU for


802
00:23:18,276 --> 00:23:19,446
that particular job.


803
00:23:20,176 --> 00:23:21,386
In this case, you can override


804
00:23:21,766 --> 00:23:23,526
user CPU on the property and set


805
00:23:23,526 --> 00:23:24,736
it to true on the request


806
00:23:24,736 --> 00:23:25,036
object.


807
00:23:25,576 --> 00:23:26,886
This will tell us to process


808
00:23:26,886 --> 00:23:28,856
your request directly on the


809
00:23:28,856 --> 00:23:29,000
CPU.


810
00:23:35,316 --> 00:23:37,176
Now that we've covered basic how


811
00:23:37,176 --> 00:23:39,236
to interact with Vision, Vision


812
00:23:39,236 --> 00:23:41,276
API, in particular, we've seen a


813
00:23:41,276 --> 00:23:43,136
couple of examples, let's switch


814
00:23:43,136 --> 00:23:44,016
to the main topic of our


815
00:23:44,016 --> 00:23:45,916
presentation, which is tracking


816
00:23:46,046 --> 00:23:47,166
in Vision.


817
00:23:48,616 --> 00:23:49,636
So, what is tracking?


818
00:23:50,986 --> 00:23:52,746
Tracking is defined as a problem


819
00:23:52,746 --> 00:23:54,406
of finding an object of interest


820
00:23:54,756 --> 00:23:55,716
in a sequence of frames.


821
00:23:56,166 --> 00:23:57,466
Usually, you find that object in


822
00:23:57,466 --> 00:23:59,256
the first frame, and you try to


823
00:23:59,426 --> 00:24:00,846
look for it in the sequence of


824
00:24:00,846 --> 00:24:01,206
frames.


825
00:24:02,256 --> 00:24:03,356
What are the examples of such


826
00:24:03,356 --> 00:24:03,956
application?


827
00:24:04,606 --> 00:24:06,036
You will probably see many of


828
00:24:06,036 --> 00:24:06,206
them.


829
00:24:06,946 --> 00:24:10,056
It's live annotational sports


830
00:24:10,056 --> 00:24:11,136
events, focus tracking with


831
00:24:11,136 --> 00:24:15,266
camera, many, many others.


832
00:24:15,466 --> 00:24:16,976
You may say why should they use


833
00:24:16,976 --> 00:24:18,496
tracking if I can do detection


834
00:24:18,816 --> 00:24:20,006
on every frame in the sequence?


835
00:24:20,826 --> 00:24:22,116
Well, there are multiple reasons


836
00:24:22,116 --> 00:24:22,426
for that.


837
00:24:23,196 --> 00:24:25,156
First, you probably don't have a


838
00:24:25,156 --> 00:24:26,396
specific tracker for every


839
00:24:26,396 --> 00:24:27,576
single type of object that you


840
00:24:27,576 --> 00:24:29,056
want to track.


841
00:24:29,056 --> 00:24:29,846
Let's say if you're tracking


842
00:24:29,846 --> 00:24:31,296
faces, you're lucky.


843
00:24:31,866 --> 00:24:32,866
You have a face detector for


844
00:24:32,866 --> 00:24:33,436
that purpose.


845
00:24:34,076 --> 00:24:35,306
But if you need, for example, to


846
00:24:35,306 --> 00:24:37,126
track a specific type of bird,


847
00:24:37,916 --> 00:24:39,236
you probably don't have that


848
00:24:39,236 --> 00:24:40,306
detector, and now you're in the


849
00:24:40,306 --> 00:24:41,516
business to create that


850
00:24:41,516 --> 00:24:43,306
particular detector, which you


851
00:24:43,306 --> 00:24:44,706
may not want to do because of


852
00:24:44,706 --> 00:24:46,886
the other things that you want


853
00:24:47,036 --> 00:24:48,036
to have done with your


854
00:24:48,036 --> 00:24:48,456
application.


855
00:24:49,106 --> 00:24:51,696
But let's say you are lucky, and


856
00:24:51,696 --> 00:24:53,366
you're tracking faces, should


857
00:24:53,366 --> 00:24:54,396
you use detector then?


858
00:24:55,136 --> 00:24:56,966
Well, probably not in this case


859
00:24:57,076 --> 00:24:57,196
either.


860
00:24:58,176 --> 00:24:59,106
So, let's look an example.


861
00:25:00,616 --> 00:25:01,406
You start your tracking


862
00:25:01,406 --> 00:25:02,546
sequence, and you run your face


863
00:25:02,546 --> 00:25:03,576
detector on the first frame.


864
00:25:04,266 --> 00:25:05,236
You get five faces back.


865
00:25:06,136 --> 00:25:07,146
Then, you run it in the second


866
00:25:07,146 --> 00:25:08,516
frame; you get another five


867
00:25:08,516 --> 00:25:08,976
faces back.


868
00:25:09,676 --> 00:25:11,506
How do you know that the faces


869
00:25:11,506 --> 00:25:12,546
from the second frame are


870
00:25:12,546 --> 00:25:14,096
exactly the same faces as from


871
00:25:14,096 --> 00:25:14,596
the first frame?


872
00:25:15,306 --> 00:25:16,276
One person could have stepped


873
00:25:16,276 --> 00:25:18,166
out; another one showed up.


874
00:25:18,956 --> 00:25:20,446
So, now, you're in the business


875
00:25:20,446 --> 00:25:22,316
of matching objects that you


876
00:25:22,316 --> 00:25:23,736
found, which is a completely


877
00:25:23,736 --> 00:25:25,326
different task that you may not


878
00:25:25,326 --> 00:25:25,876
want to deal with.


879
00:25:27,166 --> 00:25:30,716
Trackers, on the other hand, use


880
00:25:30,716 --> 00:25:31,956
[inaudible] information to match


881
00:25:31,956 --> 00:25:32,346
objects.


882
00:25:32,516 --> 00:25:33,866
They know the trajectory how the


883
00:25:33,866 --> 00:25:35,136
objects move, and they can


884
00:25:35,136 --> 00:25:36,336
slightly predict where they


885
00:25:36,336 --> 00:25:38,286
would be moving in the next


886
00:25:38,546 --> 00:25:38,660
frame.


887
00:25:39,336 --> 00:25:40,656
But let's say you're lucky


888
00:25:40,656 --> 00:25:40,856
again.


889
00:25:41,536 --> 00:25:43,296
You're tracking faces, and your


890
00:25:43,296 --> 00:25:45,076
use case is limited to a single


891
00:25:45,076 --> 00:25:45,806
face in the frame.


892
00:25:46,196 --> 00:25:47,416
Should you use detectors then?


893
00:25:48,376 --> 00:25:50,036
Well, maybe not even in this


894
00:25:50,696 --> 00:25:51,000
case.


895
00:25:56,556 --> 00:25:57,666
Now, speed is a problem.


896
00:25:58,126 --> 00:26:00,116
Trackers are usually lightweight


897
00:26:00,116 --> 00:26:01,706
algorithms, while detectors


898
00:26:01,946 --> 00:26:03,586
usually run your [inaudible],


899
00:26:03,676 --> 00:26:04,416
which is much longer.


900
00:26:05,136 --> 00:26:07,146
In addition, if you need to


901
00:26:07,146 --> 00:26:08,976
display your tracking


902
00:26:08,976 --> 00:26:10,306
information on a graphical user


903
00:26:10,306 --> 00:26:11,716
interface, you may find that


904
00:26:11,976 --> 00:26:13,356
trackers are smoother and not as


905
00:26:13,386 --> 00:26:14,000
jittery.


906
00:26:17,366 --> 00:26:18,416
Remember, in one of the first


907
00:26:18,416 --> 00:26:19,746
slides, I asked you to remember


908
00:26:21,386 --> 00:26:24,476
these three terms, what, how,


909
00:26:24,476 --> 00:26:25,016
and results.


910
00:26:25,976 --> 00:26:28,206
Let's see how this maps into the


911
00:26:28,206 --> 00:26:30,000
track and use case.


912
00:26:31,046 --> 00:26:33,646
First, request.


913
00:26:34,456 --> 00:26:36,156
So, in Vision, we have two types


914
00:26:36,156 --> 00:26:37,736
of requests for tracking.


915
00:26:38,226 --> 00:26:39,236
There is a general purpose


916
00:26:39,236 --> 00:26:40,786
object tracker, and there is a


917
00:26:40,786 --> 00:26:41,936
rectangular object tracker.


918
00:26:43,046 --> 00:26:43,576
How?


919
00:26:44,686 --> 00:26:45,556
As you should have guessed by


920
00:26:45,556 --> 00:26:46,696
now, we're going to use our


921
00:26:47,046 --> 00:26:49,836
sequence request handler.


922
00:26:49,866 --> 00:26:50,386
Results.


923
00:26:51,716 --> 00:26:52,556
There are two types that are


924
00:26:52,556 --> 00:26:53,196
important here.


925
00:26:53,306 --> 00:26:54,366
There is a detected object


926
00:26:54,366 --> 00:26:55,766
observation, which has an


927
00:26:55,766 --> 00:26:56,826
important property in it,


928
00:26:57,096 --> 00:26:58,346
bounding box, which tells you


929
00:26:58,346 --> 00:27:00,396
where the object is located, and


930
00:27:00,396 --> 00:27:01,806
there is a rectangular


931
00:27:01,806 --> 00:27:03,726
observation, which has four


932
00:27:03,726 --> 00:27:04,926
additional properties telling


933
00:27:04,926 --> 00:27:06,066
you where the vertices of the


934
00:27:06,066 --> 00:27:07,136
rectangle are.


935
00:27:07,956 --> 00:27:08,886
Now, you say if I had my


936
00:27:08,886 --> 00:27:10,136
bounding box, why do I need the


937
00:27:10,136 --> 00:27:11,166
vertices of the rectangle?


938
00:27:12,406 --> 00:27:13,536
Well, when you draw up


939
00:27:13,536 --> 00:27:15,626
rectangles, they are rectangular


940
00:27:15,626 --> 00:27:16,716
objects in the real life.


941
00:27:16,996 --> 00:27:18,106
The way they are projected in


942
00:27:18,106 --> 00:27:19,116
the frame, they may look


943
00:27:19,116 --> 00:27:19,586
differently.


944
00:27:20,136 --> 00:27:21,556
They may look like trapezoid,


945
00:27:21,556 --> 00:27:22,086
for example.


946
00:27:22,666 --> 00:27:24,966
So, the bounding box in this


947
00:27:24,966 --> 00:27:26,456
case is not the rectangle


948
00:27:26,456 --> 00:27:26,926
itself.


949
00:27:26,926 --> 00:27:28,206
It [inaudible] the minimal box


950
00:27:28,206 --> 00:27:29,546
that includes all the vertices


951
00:27:29,546 --> 00:27:32,026
of the rectangle.


952
00:27:33,526 --> 00:27:36,000
Let's look at the demo now.


953
00:27:47,466 --> 00:27:48,916
So, what I have here, I have a


954
00:27:48,916 --> 00:27:50,116
sample app that you, by the way,


955
00:27:50,116 --> 00:27:52,656
can download from WWDC website


956
00:27:52,856 --> 00:27:54,136
and the link is right next to


957
00:27:54,136 --> 00:27:54,616
this session.


958
00:27:55,506 --> 00:27:57,456
What the app does is it takes


959
00:27:57,456 --> 00:28:00,586
the movie; it parses that movie


960
00:28:00,586 --> 00:28:01,246
into frames.


961
00:28:02,106 --> 00:28:03,186
In the first frame, you select


962
00:28:03,186 --> 00:28:03,576
an object.


963
00:28:03,696 --> 00:28:04,716
You want to track a multiple


964
00:28:04,716 --> 00:28:06,276
objects or you want to track,


965
00:28:06,276 --> 00:28:08,526
and it does the tracking.


966
00:28:08,656 --> 00:28:10,446
So, let's first use this movie.


967
00:28:11,516 --> 00:28:13,006
The user interface is simple.


968
00:28:13,466 --> 00:28:14,436
First, you can choose between


969
00:28:14,436 --> 00:28:15,956
objects or rectangles, and


970
00:28:15,956 --> 00:28:17,526
second, you can choose which


971
00:28:17,526 --> 00:28:19,016
algorithm you want to use, fast


972
00:28:19,016 --> 00:28:19,486
or accurate.


973
00:28:19,926 --> 00:28:21,056
What happens in Vision that we


974
00:28:21,056 --> 00:28:23,586
support two types, fast and


975
00:28:23,586 --> 00:28:24,756
accurate, and this is a


976
00:28:24,756 --> 00:28:26,536
trade-off between the speed and


977
00:28:26,536 --> 00:28:27,016
the accuracy.


978
00:28:27,676 --> 00:28:29,776
I'm going to show objects in


979
00:28:29,776 --> 00:28:30,926
this case, and I'm going to use


980
00:28:30,926 --> 00:28:31,856
my fast algorithm.


981
00:28:32,946 --> 00:28:33,766
Let's select objects.


982
00:28:33,766 --> 00:28:36,026
So, I'm going to track this


983
00:28:36,026 --> 00:28:38,436
person under the red umbrella,


984
00:28:38,736 --> 00:28:40,136
and I'm going to try to track


985
00:28:40,136 --> 00:28:41,000
this group of people here.


986
00:28:46,156 --> 00:28:48,000
Let's run it.


987
00:28:54,436 --> 00:28:55,856
As you can see, we can


988
00:28:55,856 --> 00:28:58,706
successfully track the object


989
00:28:58,706 --> 00:29:00,000
that we selected.


990
00:29:06,756 --> 00:29:08,926
Let's look at the more complex


991
00:29:08,926 --> 00:29:09,306
example.


992
00:29:10,716 --> 00:29:12,066
What I want to track here, I


993
00:29:12,066 --> 00:29:13,186
want to track this wakeboarder


994
00:29:13,186 --> 00:29:15,616
guy, and in this case, I'm going


995
00:29:15,616 --> 00:29:16,636
to use my accurate algorithm.


996
00:29:17,966 --> 00:29:18,756
So, I'm going to select my


997
00:29:18,756 --> 00:29:19,500
object,


998
00:29:23,156 --> 00:29:25,000
and I'm going to run it.


999
00:29:30,136 --> 00:29:31,566
As you can see, this object


1000
00:29:31,686 --> 00:29:33,626
changes pretty much everything


1001
00:29:33,626 --> 00:29:35,316
about itself, its shape, the


1002
00:29:35,316 --> 00:29:37,006
location, the colors, everything


1003
00:29:37,006 --> 00:29:37,316
comes.


1004
00:29:37,316 --> 00:29:38,686
We're still able to track it.


1005
00:29:39,156 --> 00:29:39,976
I think this is pretty cool.


1006
00:29:40,516 --> 00:29:46,686
[ Applause ]


1007
00:29:47,186 --> 00:29:48,736
Now, we're going to switch to my


1008
00:29:48,736 --> 00:29:50,086
demo machine and see how the


1009
00:29:50,086 --> 00:29:51,366
actual tracking sequence is


1010
00:29:51,366 --> 00:29:53,000
implemented in this app.


1011
00:30:01,236 --> 00:30:02,426
So, I have the Xcode running,


1012
00:30:02,706 --> 00:30:03,626
and I have my headphones


1013
00:30:03,626 --> 00:30:05,546
connected to it, which is


1014
00:30:05,546 --> 00:30:07,516
running the same app as we just


1015
00:30:07,516 --> 00:30:07,696
saw.


1016
00:30:08,356 --> 00:30:10,356
I'm going to run it in the


1017
00:30:10,356 --> 00:30:11,000
debugger,


1018
00:30:16,656 --> 00:30:18,446
going to select my objects, and


1019
00:30:19,006 --> 00:30:20,896
it's not important what I select


1020
00:30:20,896 --> 00:30:21,846
because we just want to look at


1021
00:30:21,846 --> 00:30:22,416
the sequence.


1022
00:30:23,396 --> 00:30:26,676
And I'm going to run it.


1023
00:30:26,806 --> 00:30:29,096
So, I have a breakpoint set up


1024
00:30:29,096 --> 00:30:30,256
here and it breaks in the


1025
00:30:30,256 --> 00:30:32,226
perform tracking function, which


1026
00:30:32,226 --> 00:30:33,536
is the most important function


1027
00:30:33,536 --> 00:30:34,056
of this app.


1028
00:30:34,746 --> 00:30:35,596
That's the function that


1029
00:30:35,596 --> 00:30:36,826
implements the actual sequence.


1030
00:30:37,396 --> 00:30:39,716
Let's see what we do here.


1031
00:30:40,466 --> 00:30:42,986
First, we're creating our video


1032
00:30:42,986 --> 00:30:43,236
reader.


1033
00:30:44,086 --> 00:30:45,216
Then, we are reading first


1034
00:30:45,216 --> 00:30:46,596
frame, and we're discarding that


1035
00:30:46,596 --> 00:30:47,836
frame because that frame was


1036
00:30:47,836 --> 00:30:48,916
used to select the objects.


1037
00:30:50,396 --> 00:30:51,436
There's the cancellation flag


1038
00:30:51,436 --> 00:30:51,676
here.


1039
00:30:52,466 --> 00:30:54,256
Then, I'm going to initialize


1040
00:30:54,256 --> 00:30:55,686
the collection of my input


1041
00:30:55,686 --> 00:30:56,406
observations.


1042
00:30:56,526 --> 00:30:57,716
Remember, as we saw an example


1043
00:30:57,716 --> 00:30:58,206
in the slides.


1044
00:31:01,016 --> 00:31:02,536
Then, I have my bookkeeping to


1045
00:31:02,536 --> 00:31:04,366
be able to display results in a


1046
00:31:04,366 --> 00:31:06,756
graphical user interface, which


1047
00:31:06,756 --> 00:31:09,566
are kept in the trackedPolyRect


1048
00:31:10,086 --> 00:31:10,186
type.


1049
00:31:10,776 --> 00:31:12,716
Then, I'm going to run the


1050
00:31:12,716 --> 00:31:14,686
switch on the type, and the type


1051
00:31:14,686 --> 00:31:15,766
is something that comes from the


1052
00:31:15,766 --> 00:31:16,896
user interface, and in this


1053
00:31:16,896 --> 00:31:17,816
case, we're working with


1054
00:31:17,996 --> 00:31:18,426
objects.


1055
00:31:19,856 --> 00:31:22,126
Now, we selected two objects.


1056
00:31:23,436 --> 00:31:24,676
So, this is the information


1057
00:31:24,676 --> 00:31:26,136
coming from the user interface.


1058
00:31:26,556 --> 00:31:27,936
We should see these two objects


1059
00:31:27,936 --> 00:31:28,330
here.


1060
00:31:32,046 --> 00:31:33,326
Okay, there are two of them.


1061
00:31:33,476 --> 00:31:35,656
So, this loop will run two


1062
00:31:35,656 --> 00:31:36,096
times.


1063
00:31:36,426 --> 00:31:37,676
It will initialize input


1064
00:31:37,676 --> 00:31:38,436
observations.


1065
00:31:38,716 --> 00:31:39,936
It'll create detected object


1066
00:31:39,936 --> 00:31:41,526
observation as also shown in the


1067
00:31:41,526 --> 00:31:44,766
slides by passing bounding box


1068
00:31:44,766 --> 00:31:44,926
in.


1069
00:31:46,316 --> 00:31:47,556
And we initialize our


1070
00:31:47,556 --> 00:31:49,536
bookkeeping structures.


1071
00:31:50,116 --> 00:31:51,266
Let's run it.


1072
00:31:58,116 --> 00:31:59,526
Let's look at the observation


1073
00:31:59,746 --> 00:32:00,826
object.


1074
00:32:07,576 --> 00:32:09,006
There are a couple of fields


1075
00:32:09,006 --> 00:32:09,866
that are important here.


1076
00:32:10,106 --> 00:32:11,406
This is the unique ID that we


1077
00:32:11,406 --> 00:32:11,866
discussed.


1078
00:32:11,966 --> 00:32:14,236
And then it's our bounding box


1079
00:32:14,476 --> 00:32:15,606
in normalize organize.


1080
00:32:18,076 --> 00:32:19,716
Now, if I run through, I'm going


1081
00:32:19,716 --> 00:32:21,486
to hit this breakpoint because


1082
00:32:21,486 --> 00:32:23,256
this case we're not using


1083
00:32:23,286 --> 00:32:24,426
[inaudible] rectangles.


1084
00:32:26,116 --> 00:32:27,756
This is where I create my


1085
00:32:27,756 --> 00:32:28,726
sequence request handler.


1086
00:32:29,246 --> 00:32:32,126
Now, I have my frame counter,


1087
00:32:32,806 --> 00:32:35,276
I have my flag if something has


1088
00:32:35,276 --> 00:32:37,486
failed, and I'm finally going to


1089
00:32:37,486 --> 00:32:38,916
start my tracking sequence.


1090
00:32:39,226 --> 00:32:40,636
As you can see, this is an


1091
00:32:40,636 --> 00:32:42,006
infinite loop, and the


1092
00:32:42,006 --> 00:32:43,256
conditions to get out of that


1093
00:32:43,256 --> 00:32:44,656
loop is if the cancellation was


1094
00:32:44,656 --> 00:32:46,676
requested, or if the movie has


1095
00:32:46,676 --> 00:32:47,000
ended.


1096
00:32:51,046 --> 00:32:53,566
I'm going to initialize my rect


1097
00:32:54,976 --> 00:32:56,766
structure to keep the


1098
00:32:56,766 --> 00:32:57,876
information for the graphical


1099
00:32:57,876 --> 00:32:59,246
user in this interface to be


1100
00:32:59,246 --> 00:33:01,846
displayed later, and I'm going


1101
00:33:01,846 --> 00:33:04,066
to start iterating over my input


1102
00:33:04,066 --> 00:33:05,606
observations, which we have to.


1103
00:33:06,396 --> 00:33:07,306
For each one, I'm going to


1104
00:33:07,306 --> 00:33:08,766
create a track object request.


1105
00:33:15,106 --> 00:33:16,676
I'm going to advance my request


1106
00:33:16,676 --> 00:33:17,486
to the collection of all


1107
00:33:17,486 --> 00:33:19,576
requests, and we have to in this


1108
00:33:19,916 --> 00:33:20,000
case.


1109
00:33:22,236 --> 00:33:24,606
Going to break off the loop, and


1110
00:33:24,606 --> 00:33:26,176
finally, I'm ready to process my


1111
00:33:26,176 --> 00:33:26,716
requests.


1112
00:33:27,346 --> 00:33:28,476
Now, if you can see the


1113
00:33:28,476 --> 00:33:29,676
performed request, the perform


1114
00:33:29,956 --> 00:33:31,986
function accepts a collection of


1115
00:33:31,986 --> 00:33:32,446
requests.


1116
00:33:33,206 --> 00:33:35,176
In the slides, we only used a


1117
00:33:35,176 --> 00:33:37,326
single request to be passed into


1118
00:33:37,326 --> 00:33:38,476
that collection, but here we're


1119
00:33:38,476 --> 00:33:39,916
going to track two requests at


1120
00:33:39,916 --> 00:33:40,446
the same time.


1121
00:33:40,876 --> 00:33:44,486
I'm going to perform it.


1122
00:33:44,756 --> 00:33:46,156
Now, since the requests are


1123
00:33:46,156 --> 00:33:48,186
performed, I'm going to start


1124
00:33:48,186 --> 00:33:49,596
looking at the results, and I'm


1125
00:33:49,596 --> 00:33:50,706
going to do that by looking at


1126
00:33:50,706 --> 00:33:52,606
the results property of each


1127
00:33:54,776 --> 00:33:54,896
one.


1128
00:33:55,096 --> 00:33:55,916
So, I'm going to get results


1129
00:33:55,916 --> 00:33:56,406
property.


1130
00:33:56,626 --> 00:33:57,876
I'm going to get the first


1131
00:33:57,876 --> 00:33:59,206
object in that property because


1132
00:33:59,206 --> 00:34:00,396
we expect them, the single one


1133
00:34:00,396 --> 00:34:02,766
in there as an observation.


1134
00:34:03,806 --> 00:34:04,926
What I'm going to do here, I'm


1135
00:34:04,926 --> 00:34:06,936
going to look at the confidence


1136
00:34:06,936 --> 00:34:08,976
property of my observation, and


1137
00:34:08,976 --> 00:34:10,406
I set an arbitrary threshold to


1138
00:34:10,406 --> 00:34:11,036
0.5.


1139
00:34:12,156 --> 00:34:13,315
So, if it's above the threshold,


1140
00:34:13,596 --> 00:34:15,585
I'm going to paint the bounding


1141
00:34:15,585 --> 00:34:17,616
box with solid line, and if it's


1142
00:34:17,616 --> 00:34:18,846
below the threshold, I'm going


1143
00:34:18,846 --> 00:34:19,866
to paint it with a dashed line.


1144
00:34:19,866 --> 00:34:21,196
So, I have, so I can have an


1145
00:34:21,196 --> 00:34:22,856
indication if something is going


1146
00:34:23,036 --> 00:34:23,255
wrong.


1147
00:34:26,116 --> 00:34:27,616
The rest is simple bookkeeping.


1148
00:34:27,716 --> 00:34:30,216
I'm just going to populate my


1149
00:34:30,216 --> 00:34:32,636
rect structure, and this is the


1150
00:34:32,636 --> 00:34:33,795
last step, which is very


1151
00:34:33,795 --> 00:34:34,966
important where I take the


1152
00:34:34,966 --> 00:34:36,076
observation from the current


1153
00:34:36,076 --> 00:34:38,916
iteration, and I assign it for


1154
00:34:38,916 --> 00:34:39,686
the next iteration.


1155
00:34:43,596 --> 00:34:44,866
I'm going to do it a second


1156
00:34:44,866 --> 00:34:45,136
time.


1157
00:34:46,085 --> 00:34:47,106
I'm going to get to this


1158
00:34:47,106 --> 00:34:47,746
breakpoint.


1159
00:34:49,146 --> 00:34:50,346
Going to display my frame.


1160
00:34:51,946 --> 00:34:53,136
I'm going to sleep for the frame


1161
00:34:53,136 --> 00:34:54,966
rate in seconds time to simulate


1162
00:34:54,966 --> 00:34:55,746
the actual movie.


1163
00:34:56,186 --> 00:34:58,096
And then, before you know it,


1164
00:34:58,296 --> 00:34:59,816
you're in the second iteration


1165
00:35:00,176 --> 00:35:01,766
of your tracking sequence.


1166
00:35:03,736 --> 00:35:05,276
So, let's get back to the slides


1167
00:35:05,946 --> 00:35:06,000
now.


1168
00:35:11,516 --> 00:35:11,776
Thank you.


1169
00:35:12,516 --> 00:35:16,000
[ Applause ]


1170
00:35:18,636 --> 00:35:19,846
So, let's look at what's


1171
00:35:19,846 --> 00:35:21,096
important to remember from what


1172
00:35:21,096 --> 00:35:21,786
we have just seen.


1173
00:35:23,186 --> 00:35:25,966
First, how to initialize initial


1174
00:35:25,966 --> 00:35:28,416
object for tracking, and we saw


1175
00:35:28,416 --> 00:35:28,936
two ways.


1176
00:35:28,976 --> 00:35:30,266
There's automatic way, which is


1177
00:35:30,266 --> 00:35:31,666
usually done by running certain


1178
00:35:31,666 --> 00:35:33,356
detectors and getting bounding


1179
00:35:33,356 --> 00:35:33,946
boxes out.


1180
00:35:34,776 --> 00:35:36,056
And the second is manual, which


1181
00:35:36,056 --> 00:35:37,256
usually comes from the user


1182
00:35:37,256 --> 00:35:38,000
input.


1183
00:35:52,916 --> 00:35:54,926
We also saw that we used a


1184
00:35:54,926 --> 00:35:57,646
single tracking request per


1185
00:35:57,816 --> 00:35:58,456
tracked object.


1186
00:35:58,856 --> 00:35:59,966
The relationship here is


1187
00:35:59,966 --> 00:36:00,466
one-to-one.


1188
00:36:03,396 --> 00:36:04,656
We also saw that there are two


1189
00:36:04,656 --> 00:36:05,506
types of trackers.


1190
00:36:05,806 --> 00:36:06,916
One is the general purpose


1191
00:36:06,916 --> 00:36:08,396
tracker, and another one is


1192
00:36:08,396 --> 00:36:10,216
rectangular object tracker.


1193
00:36:12,396 --> 00:36:13,576
We also learned that there are


1194
00:36:13,576 --> 00:36:15,636
two algorithms for each tracker


1195
00:36:15,636 --> 00:36:15,906
type.


1196
00:36:16,356 --> 00:36:18,116
There is fast and accurate, and


1197
00:36:18,116 --> 00:36:20,366
this represents the tradeoff


1198
00:36:20,366 --> 00:36:21,646
between speed and accuracy.


1199
00:36:21,966 --> 00:36:24,766
And last but not least, we


1200
00:36:24,866 --> 00:36:25,946
looked at how to use a


1201
00:36:25,946 --> 00:36:28,116
confidence level property to


1202
00:36:28,116 --> 00:36:29,586
judge whether we should or


1203
00:36:29,586 --> 00:36:30,716
should not trust our results.


1204
00:36:34,516 --> 00:36:35,796
What are the limits of


1205
00:36:35,796 --> 00:36:37,046
implementing tracking sequence


1206
00:36:37,046 --> 00:36:37,446
in Vision?


1207
00:36:38,006 --> 00:36:42,406
First, let's talk about number


1208
00:36:42,496 --> 00:36:43,646
of trackers.


1209
00:36:45,136 --> 00:36:46,866
How many objects can you track


1210
00:36:46,866 --> 00:36:47,546
simultaneously?


1211
00:36:48,446 --> 00:36:49,796
Well, in Vision we have a limit


1212
00:36:50,066 --> 00:36:53,186
that is set to 16 trackers for


1213
00:36:53,186 --> 00:36:53,666
each type.


1214
00:36:54,006 --> 00:36:55,346
So, you can have 16 general


1215
00:36:55,346 --> 00:36:57,446
purpose object trackers and 16


1216
00:36:58,076 --> 00:36:59,206
rectangular object trackers.


1217
00:37:00,306 --> 00:37:01,826
If you try to allocate more,


1218
00:37:01,826 --> 00:37:02,806
you'll get an error back.


1219
00:37:03,976 --> 00:37:06,556
So, if it happens, you probably


1220
00:37:06,556 --> 00:37:07,526
need to release some of the


1221
00:37:07,526 --> 00:37:08,446
trackers that you're already


1222
00:37:08,446 --> 00:37:08,776
using.


1223
00:37:09,506 --> 00:37:12,576
How to do that?


1224
00:37:12,576 --> 00:37:14,426
First way is you can set a last


1225
00:37:14,426 --> 00:37:16,576
frame property under request and


1226
00:37:16,576 --> 00:37:18,366
feed that request into the


1227
00:37:18,366 --> 00:37:19,716
request handler for processing.


1228
00:37:20,186 --> 00:37:21,436
That way, the request handler


1229
00:37:21,436 --> 00:37:23,006
will know that the tracker


1230
00:37:23,006 --> 00:37:24,206
associated with this request


1231
00:37:24,206 --> 00:37:25,416
object should be released.


1232
00:37:26,286 --> 00:37:27,936
Another way is to release the


1233
00:37:27,936 --> 00:37:29,196
entire sequence request handler;


1234
00:37:29,466 --> 00:37:31,136
in this case, all the trackers


1235
00:37:31,136 --> 00:37:32,396
associated with that request


1236
00:37:32,396 --> 00:37:34,000
handler will be released.


1237
00:37:38,086 --> 00:37:39,646
Now, let's say you've


1238
00:37:39,646 --> 00:37:40,566
implemented the tracking


1239
00:37:40,566 --> 00:37:41,046
signals.


1240
00:37:41,356 --> 00:37:42,206
What are the potential


1241
00:37:42,206 --> 00:37:43,456
challenges that you may face?


1242
00:37:44,486 --> 00:37:46,666
Well, as you've seen, objects in


1243
00:37:46,666 --> 00:37:47,836
tracking sequence can change


1244
00:37:47,836 --> 00:37:49,276
pretty much everything about


1245
00:37:49,276 --> 00:37:49,836
themselves.


1246
00:37:50,076 --> 00:37:50,966
They can change their shape,


1247
00:37:50,966 --> 00:37:53,616
appearance, color, location, and


1248
00:37:53,616 --> 00:37:54,566
that represents a great


1249
00:37:54,566 --> 00:37:55,606
challenge for the algorithm.


1250
00:37:56,606 --> 00:37:57,546
So, what can you do here?


1251
00:37:58,536 --> 00:38:00,066
Well, one unfortunate answer is


1252
00:38:00,066 --> 00:38:01,246
that there's no one size that


1253
00:38:01,246 --> 00:38:02,916
fits all solution here, but you


1254
00:38:02,916 --> 00:38:03,846
can try a couple of things.


1255
00:38:04,326 --> 00:38:05,536
First, you can play with fast or


1256
00:38:05,536 --> 00:38:06,986
accurate, and you can figure out


1257
00:38:06,986 --> 00:38:09,186
that your particular use case


1258
00:38:09,266 --> 00:38:10,736
works better with a particular


1259
00:38:10,736 --> 00:38:11,176
algorithm.


1260
00:38:14,956 --> 00:38:16,546
If you're in charge of selecting


1261
00:38:16,546 --> 00:38:18,966
bounding box, try to find a


1262
00:38:18,966 --> 00:38:21,486
select salient object in the


1263
00:38:22,636 --> 00:38:22,766
same.


1264
00:38:22,976 --> 00:38:23,956
Which confidence threshold to


1265
00:38:23,956 --> 00:38:24,236
use?


1266
00:38:25,386 --> 00:38:26,676
Again, there is no single answer


1267
00:38:26,676 --> 00:38:26,936
here.


1268
00:38:27,266 --> 00:38:28,286
You will find that some use


1269
00:38:28,286 --> 00:38:29,366
cases work with certain


1270
00:38:29,366 --> 00:38:30,816
thresholds while other use cases


1271
00:38:30,816 --> 00:38:32,746
work with other thresholds.


1272
00:38:34,656 --> 00:38:36,106
There's one more technique that


1273
00:38:36,106 --> 00:38:36,836
I could recommend.


1274
00:38:37,146 --> 00:38:37,996
Let's say you have a long


1275
00:38:37,996 --> 00:38:39,086
tracking sequence, and for the


1276
00:38:39,086 --> 00:38:40,556
sake of this example, 1,000


1277
00:38:40,556 --> 00:38:40,936
frames.


1278
00:38:42,266 --> 00:38:43,616
If you start that tracking


1279
00:38:43,616 --> 00:38:45,486
sequence, your object that you


1280
00:38:45,486 --> 00:38:46,976
selected in the first frame will


1281
00:38:46,976 --> 00:38:48,236
start deviating, and it'll


1282
00:38:48,236 --> 00:38:50,496
change everything about itself


1283
00:38:50,996 --> 00:38:52,756
the more you go off of that


1284
00:38:52,756 --> 00:38:53,376
initial frame.


1285
00:38:54,356 --> 00:38:55,786
What you can do instead, you can


1286
00:38:55,786 --> 00:38:57,186
break that sequence into smaller


1287
00:38:57,186 --> 00:38:58,606
subsequences, let's say 50


1288
00:38:58,606 --> 00:38:59,136
frames each.


1289
00:38:59,706 --> 00:39:01,576
You run your detector, you track


1290
00:39:01,576 --> 00:39:02,946
that object for 50 frames.


1291
00:39:03,356 --> 00:39:05,186
You rerun the detector; you run


1292
00:39:05,186 --> 00:39:06,546
it again for 50 frames, and you


1293
00:39:06,546 --> 00:39:08,766
keep doing just like that.


1294
00:39:08,886 --> 00:39:10,176
From the end user point of view,


1295
00:39:10,466 --> 00:39:12,036
it'll look like you're tracking


1296
00:39:12,086 --> 00:39:12,786
a single object.


1297
00:39:13,726 --> 00:39:15,336
But what you do instead, what


1298
00:39:15,336 --> 00:39:16,846
you do inside instead, you're


1299
00:39:16,846 --> 00:39:18,416
tracking smaller sequences, and


1300
00:39:18,416 --> 00:39:20,586
that's a smarter way of running


1301
00:39:20,586 --> 00:39:21,500
and tracking sequence.


1302
00:39:27,336 --> 00:39:28,356
Let's summarize what we have


1303
00:39:28,356 --> 00:39:28,756
seen today.


1304
00:39:30,306 --> 00:39:31,846
First, we talked about why you'd


1305
00:39:31,846 --> 00:39:33,526
use Vision, and we talked about


1306
00:39:33,526 --> 00:39:34,716
a multi-platform framework,


1307
00:39:35,346 --> 00:39:36,876
privacy-oriented, which offers


1308
00:39:36,876 --> 00:39:38,756
simple and consistent interface.


1309
00:39:41,176 --> 00:39:42,796
Second, we talked about what's


1310
00:39:42,796 --> 00:39:45,076
new, and we introduced a new


1311
00:39:45,386 --> 00:39:46,756
orientation-agnostic face


1312
00:39:46,756 --> 00:39:47,166
detector.


1313
00:39:48,126 --> 00:39:49,556
We talked also about revisions.


1314
00:39:50,976 --> 00:39:52,826
Then, we talked about how to


1315
00:39:52,826 --> 00:39:54,796
interact with Vision API, and we


1316
00:39:54,796 --> 00:39:56,546
discussed requests, request


1317
00:39:56,546 --> 00:39:58,446
handlers, and observations.


1318
00:39:58,656 --> 00:40:01,626
And finally, we looked at how to


1319
00:40:01,626 --> 00:40:03,396
implement tracking sequence in


1320
00:40:03,856 --> 00:40:04,000
Vision.


1321
00:40:05,436 --> 00:40:06,886
For more information, I


1322
00:40:06,886 --> 00:40:08,046
recommend you to refer to this


1323
00:40:08,046 --> 00:40:09,976
link on the slide.


1324
00:40:10,556 --> 00:40:12,176
I can also recommend you to stay


1325
00:40:12,176 --> 00:40:13,226
for the next session, which will


1326
00:40:13,226 --> 00:40:14,396
be at 3 o'clock in this room


1327
00:40:14,646 --> 00:40:16,026
where Frank will cover details


1328
00:40:16,026 --> 00:40:17,116
of integration of Vision and


1329
00:40:17,116 --> 00:40:17,566
CoreML.


1330
00:40:17,896 --> 00:40:19,226
This is especially important if


1331
00:40:19,226 --> 00:40:20,086
you want to deploy your own


1332
00:40:20,086 --> 00:40:20,546
models.


1333
00:40:21,246 --> 00:40:22,396
That session will also cover


1334
00:40:22,396 --> 00:40:24,576
some details about Vision


1335
00:40:24,576 --> 00:40:25,736
Framework that were not covered


1336
00:40:25,736 --> 00:40:26,296
by this session.


1337
00:40:27,636 --> 00:40:28,676
And we'll also have Vison Lab


1338
00:40:28,706 --> 00:40:30,166
tomorrow, which is 3 to 5.


1339
00:40:31,176 --> 00:40:33,056
Thank you and have a great rest


1340
00:40:33,056 --> 00:40:34,000
of your WWDC.


1341
00:40:34,846 --> 00:40:38,500
[ Applause ]

