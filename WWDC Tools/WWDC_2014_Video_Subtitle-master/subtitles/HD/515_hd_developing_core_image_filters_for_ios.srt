1
00:00:00,506 --> 00:00:12,756
[ Silence ]


2
00:00:13,256 --> 00:00:14,066
>> Good afternoon, everyone.


3
00:00:14,206 --> 00:00:17,776
Name is Alexandre Naaman and
I'm here today to talk to you


4
00:00:17,776 --> 00:00:20,336
about developing custom
Core Image kernels


5
00:00:20,336 --> 00:00:21,626
and filters on iOS.


6
00:00:21,626 --> 00:00:24,596
So let's start with a
little bit of history.


7
00:00:25,206 --> 00:00:31,616
We've been able to write custom
kernels on Mac OS X since 2005


8
00:00:31,656 --> 00:00:33,116
with the advent of Core Image.


9
00:00:33,116 --> 00:00:35,766
And now, with iOS 8, we're
going to show you how you can do


10
00:00:35,766 --> 00:00:39,176
that on our embedded devices.


11
00:00:39,766 --> 00:00:41,936
So the main motivation,
why would you want


12
00:00:41,936 --> 00:00:43,146
to write custom kernels?


13
00:00:43,146 --> 00:00:46,006
Well, you can - there are
- although we provide many,


14
00:00:46,006 --> 00:00:50,246
many built-in kernels and
filters, there are situations


15
00:00:50,246 --> 00:00:52,446
where you can't use an
existing set of filters


16
00:00:52,446 --> 00:00:54,106
or some combination of
to create the effect


17
00:00:54,106 --> 00:00:55,336
that you're trying to achieve.


18
00:00:55,336 --> 00:00:56,986
So if you were trying
to do something


19
00:00:56,986 --> 00:00:59,276
such a hot pixels effect
or a vignette effect,


20
00:00:59,276 --> 00:01:00,786
which is an example
we're going to go


21
00:01:00,786 --> 00:01:03,176
into complete detail a little
bit later on, that's something


22
00:01:03,176 --> 00:01:04,056
that you wouldn't
have been able to do


23
00:01:04,056 --> 00:01:05,236
without writing a custom kernel.


24
00:01:05,886 --> 00:01:08,546
Or if you wanted to create some
sort of interesting distortion,


25
00:01:08,546 --> 00:01:11,256
such as the Droste deformation
that we showed how to do


26
00:01:11,256 --> 00:01:12,706
in our talk two years ago,


27
00:01:13,016 --> 00:01:14,116
that also wouldn't
have been possible.


28
00:01:14,116 --> 00:01:16,996
But now, on iOS 8, with
custom kernels, it is.


29
00:01:17,606 --> 00:01:19,386
So let's talk a little
bit about our agenda.


30
00:01:20,026 --> 00:01:22,296
First off, we're going to start
about - we're going to talk


31
00:01:22,296 --> 00:01:25,426
about the - some core concepts
involved in image processing


32
00:01:25,426 --> 00:01:26,476
and how to use Core Image.


33
00:01:27,536 --> 00:01:30,936
We're then going to go through a
whole series of examples on how


34
00:01:30,936 --> 00:01:32,906
to write custom kernels
of your own,


35
00:01:32,906 --> 00:01:33,446
and that's where we're going


36
00:01:33,446 --> 00:01:34,786
to spend the majority
of our time today.


37
00:01:35,406 --> 00:01:36,746
And then, at the very
end, we're going to talk


38
00:01:36,746 --> 00:01:39,236
about some platform differences
in between OS X and iOS


39
00:01:39,236 --> 00:01:40,696
and what you need
to keep in mind


40
00:01:40,996 --> 00:01:44,376
when you're writing
kernels for either target.


41
00:01:45,966 --> 00:01:47,916
So key concepts.


42
00:01:48,626 --> 00:01:49,746
And this is going to
sound familiar to you


43
00:01:49,746 --> 00:01:50,876
if you were here for
the earlier talk.


44
00:01:50,876 --> 00:01:53,576
I'm just going to go
over this really quickly


45
00:01:53,706 --> 00:01:55,296
and explain how Core
Image works.


46
00:01:55,616 --> 00:01:58,366
So if you had, for example, an
input image, the original image


47
00:01:58,366 --> 00:02:00,966
on the left, and you wanted
to apply a sepia tone filter,


48
00:02:00,966 --> 00:02:01,886
you could easily do that.


49
00:02:02,836 --> 00:02:05,586
But Core Image lets you apply
much more complicated effects


50
00:02:05,586 --> 00:02:07,626
and create arbitrary
filter graphs


51
00:02:07,626 --> 00:02:09,515
and not just necessarily
daisy chaining images


52
00:02:09,515 --> 00:02:12,886
up in this manner,
but also creating more


53
00:02:12,886 --> 00:02:13,876
complicated graphs.


54
00:02:14,526 --> 00:02:17,146
And these are all
lightweight objects


55
00:02:17,586 --> 00:02:19,346
that eventually get
combined together.


56
00:02:20,806 --> 00:02:23,906
And each one of these
filters can be represented


57
00:02:23,906 --> 00:02:25,626
by some number of kernels.


58
00:02:25,846 --> 00:02:29,866
And internally, what Core Image
does is it will combine these


59
00:02:29,866 --> 00:02:33,306
all to - into one program, such
that we minimize the number


60
00:02:33,306 --> 00:02:34,886
of intermediate buffers
that you might have


61
00:02:35,366 --> 00:02:37,216
and maximize performance,
which is our goal.


62
00:02:40,136 --> 00:02:42,346
So let's talk about the
classes that we're going


63
00:02:42,346 --> 00:02:43,026
to be dealing with today.


64
00:02:43,026 --> 00:02:43,986
And again, if you
were here earlier,


65
00:02:43,986 --> 00:02:45,556
you've got a brief
glimpse of this already.


66
00:02:45,556 --> 00:02:47,766
The first class we're going
to deal with is CIKernel,


67
00:02:47,846 --> 00:02:48,996
which is what we're
going to spend most


68
00:02:48,996 --> 00:02:50,136
of our time working on today.


69
00:02:50,636 --> 00:02:56,506
And it represents the object
that encapsulates the kernel


70
00:02:56,506 --> 00:03:00,336
that you'll be writing to drive
- to interact with your image


71
00:03:01,246 --> 00:03:03,106
and is written in our Core
Image kernel language,


72
00:03:03,106 --> 00:03:04,166
which is based on GLSL.


73
00:03:05,056 --> 00:03:07,896
The next object is a
CIFilter, which you use


74
00:03:07,946 --> 00:03:11,916
to drive the parameters
of the kernel.


75
00:03:12,256 --> 00:03:14,976
And it has any number of
inputs, and they can be images,


76
00:03:15,036 --> 00:03:17,956
NSNumbers, or CIVectors,
and one output,


77
00:03:17,956 --> 00:03:19,076
which is a new output image.


78
00:03:19,636 --> 00:03:23,666
We then have CIImage,
which is different


79
00:03:23,666 --> 00:03:26,546
from other images you may
have seen with other APIs


80
00:03:26,586 --> 00:03:27,956
because it's an immutable object


81
00:03:27,956 --> 00:03:29,686
and only represents
a recipe the image.


82
00:03:29,686 --> 00:03:31,656
So it doesn't actually
contain any real data.


83
00:03:31,656 --> 00:03:34,716
It's just a recipe for how
to produce the final result


84
00:03:35,666 --> 00:03:39,526
and it's also based on Cartesian
coordinates, lower left corner,


85
00:03:40,316 --> 00:03:41,636
and may have infinite bounds.


86
00:03:41,636 --> 00:03:43,346
So it's not necessarily
a bounded rect.


87
00:03:43,346 --> 00:03:44,406
It can be infinite as well.


88
00:03:45,736 --> 00:03:48,026
The final object that
we're going to be dealing


89
00:03:48,026 --> 00:03:52,656
with is a CIContext and
a CIContext is the object


90
00:03:52,656 --> 00:03:55,916
that you use to render all of
your images, your CIImages,


91
00:03:56,186 --> 00:04:00,096
whether that be to CGImage
Ref or to an EAGL context


92
00:04:00,096 --> 00:04:01,826
or whatever other
destination you desire.


93
00:04:03,016 --> 00:04:05,226
So let's take a look at
how you might do this


94
00:04:05,226 --> 00:04:08,676
if you were dealing with
standard C code and dealing


95
00:04:08,676 --> 00:04:10,616
with just, you know, trying


96
00:04:10,616 --> 00:04:13,676
to produce some new output image
given some bucket of bytes.


97
00:04:14,246 --> 00:04:17,296
So you would typically write
some for loop over all the rows


98
00:04:17,296 --> 00:04:20,296
in an image and then
iterate over all the columns.


99
00:04:20,836 --> 00:04:23,896
And then, for each input
pixel, input buffer


100
00:04:23,896 --> 00:04:26,726
at [i][j] produce some - you
know, run your algorithm here,


101
00:04:26,726 --> 00:04:30,376
indicated by processPixel, and
create some new output value,


102
00:04:30,746 --> 00:04:33,966
and put that into your result.


103
00:04:33,966 --> 00:04:36,346
What we like to do inside of
Core Image is abstract all


104
00:04:36,346 --> 00:04:38,156
of that for loop away
for you and have it


105
00:04:38,156 --> 00:04:41,196
such that all you need
to do is concentrate


106
00:04:41,286 --> 00:04:45,046
on your core algorithm, in
this case, processPixel,


107
00:04:45,306 --> 00:04:48,476
and we will take care of running
that in a parallel fashion


108
00:04:48,476 --> 00:04:52,616
for you on the GPU, and running
it as oftenly as possible.


109
00:04:52,616 --> 00:04:54,006
Now, in order to use a CIKernel,


110
00:04:54,576 --> 00:04:57,176
you need to subclass
from CIFilter.


111
00:04:57,616 --> 00:05:00,386
And CIFilter is going to tell
us, given some number of,


112
00:05:00,386 --> 00:05:04,626
let's say, zero or more input
images and some parameters,


113
00:05:04,626 --> 00:05:08,896
how to apply that kernel
onto your input image


114
00:05:09,366 --> 00:05:11,366
and produce one new
output image.


115
00:05:11,366 --> 00:05:17,736
So let's take a look
at the workflow in iOS.


116
00:05:17,986 --> 00:05:19,926
And if you've written
kernels - I'm sorry.


117
00:05:19,926 --> 00:05:22,986
If you've written filters on
iOS or on desktop in the past,


118
00:05:22,986 --> 00:05:24,376
this is going to sound
very similar to you,


119
00:05:24,626 --> 00:05:25,626
but we've got some new things.


120
00:05:25,626 --> 00:05:29,296
So first things first, create an
input image with CIInputImage.


121
00:05:29,796 --> 00:05:31,356
Then, we subclass CIFilter.


122
00:05:31,356 --> 00:05:34,676
We're going to get our
output image eventually,


123
00:05:34,676 --> 00:05:36,166
once we're done running
the CIFilter.


124
00:05:36,686 --> 00:05:38,936
And then, when we have our
output image, we can display it,


125
00:05:38,936 --> 00:05:41,846
as I said earlier, using
either CGImage or -


126
00:05:41,846 --> 00:05:44,246
rendering to CGImage
or an EAGL context.


127
00:05:44,926 --> 00:05:45,936
What's new and what
we're going to talk


128
00:05:45,936 --> 00:05:48,546
about today is how you
create those kernels


129
00:05:48,546 --> 00:05:51,106
and how you apply the parameters
that you have from your filter


130
00:05:51,106 --> 00:05:53,516
to the kernel to get
your final output.


131
00:05:53,996 --> 00:05:58,476
So let's talk about what
exists currently in Core Image.


132
00:05:59,546 --> 00:06:03,676
Right now, in iOS 8, we
have 115 built-in filters.


133
00:06:05,016 --> 00:06:07,646
Take a little closer detail
- closer look at this.


134
00:06:07,646 --> 00:06:11,026
We can see that they're actually
- from this - set of 115,


135
00:06:11,026 --> 00:06:15,326
there are 78, which are actually
just purely modifying the color


136
00:06:15,326 --> 00:06:17,056
of the images.


137
00:06:18,226 --> 00:06:21,206
There are another 27, which
are pure geometry distortions.


138
00:06:22,006 --> 00:06:25,866
And then, there are a final
seven that are convolutions,


139
00:06:26,546 --> 00:06:28,306
which brings us to
our next point,


140
00:06:28,306 --> 00:06:31,486
what is the anatomy
of a CIKernel on iOS?


141
00:06:31,816 --> 00:06:34,886
So in iOS and on OS X, we
now have a CIKernel class,


142
00:06:35,626 --> 00:06:39,916
but on iOS, we now have
two new classes that allow


143
00:06:39,916 --> 00:06:43,246
for greater performance and
are specializations of CIKernel


144
00:06:43,246 --> 00:06:46,806
and allow us to do higher
performance optimizations


145
00:06:46,806 --> 00:06:48,576
than we do currently elsewhere.


146
00:06:49,166 --> 00:06:52,646
So we have CIColorKernel and
CIWarpKernel and we're going


147
00:06:52,646 --> 00:06:55,466
to talk about three of those
today in order of difficulty.


148
00:06:56,826 --> 00:06:59,196
So let's look a little
deeper into the interface


149
00:06:59,196 --> 00:07:00,366
for what a CIKernel looks like,


150
00:07:00,366 --> 00:07:01,926
and you can see there are
really only two methods


151
00:07:02,256 --> 00:07:03,096
that we care about.


152
00:07:03,466 --> 00:07:05,536
The first one is
to create a kernel,


153
00:07:05,536 --> 00:07:06,626
you call kernelWithString.


154
00:07:07,326 --> 00:07:09,406
And then, to create
a new CIImage


155
00:07:09,406 --> 00:07:13,566
after having running your
kernel, you call applyWithExtent


156
00:07:13,566 --> 00:07:14,706
and a few other parameters.


157
00:07:14,706 --> 00:07:16,846
And again, it's important
to remember


158
00:07:17,316 --> 00:07:19,986
that calling apply doesn't
actually render anything.


159
00:07:20,296 --> 00:07:22,506
It's just a recipe so you
can daisy chain these up,


160
00:07:22,866 --> 00:07:24,856
create whatever graph you
want, and no work is performed


161
00:07:24,856 --> 00:07:27,666
until the last moment when you
actually need those pixels.


162
00:07:28,996 --> 00:07:32,016
So what is CIKernel's language?


163
00:07:32,116 --> 00:07:35,686
Well, it's based on GLSL and
it has extensions for imaging.


164
00:07:35,686 --> 00:07:39,346
So to deal with tiling
and all kinds


165
00:07:39,656 --> 00:07:41,636
of other optimizations
we've put in.


166
00:07:42,196 --> 00:07:44,726
It also - all the inputs
and outputs are floats.


167
00:07:45,246 --> 00:07:46,726
So fairly easy to use.


168
00:07:46,726 --> 00:07:50,176
Let's now take a look
at what is involved


169
00:07:50,176 --> 00:07:51,626
in writing a CIColorKernel.


170
00:07:53,136 --> 00:07:55,476
So as I was saying,
all the inputs


171
00:07:55,476 --> 00:07:59,446
for CIColorKernel are going to
be float data and that doesn't -


172
00:07:59,446 --> 00:08:01,486
it - regardless of what
your input data is,


173
00:08:01,486 --> 00:08:05,526
whether it's RGBA8 or 16-bit
ends or float data, it will come


174
00:08:05,526 --> 00:08:10,486
into the kernel as float data,
as a vec4, and the output


175
00:08:10,486 --> 00:08:14,816
from every CIFilter is
also going to be a vec4.


176
00:08:15,026 --> 00:08:15,686
So let's take a look


177
00:08:15,686 --> 00:08:18,346
at the simplest possible
example we could come up with,


178
00:08:18,916 --> 00:08:20,026
which actually does nothing.


179
00:08:20,026 --> 00:08:21,256
So this is a no op.


180
00:08:21,256 --> 00:08:22,246
It just takes an input.


181
00:08:22,246 --> 00:08:24,936
In this case, it's going to be
an underscore underscore sample,


182
00:08:25,346 --> 00:08:26,586
and you can see we
just returned -


183
00:08:26,586 --> 00:08:30,756
which is effectively just a
vec4, and we just return s.rgba.


184
00:08:30,756 --> 00:08:33,006
So if we were to apply this
filter to the input image


185
00:08:33,006 --> 00:08:36,676
on the left, we would get the
exact same image on the output.


186
00:08:37,275 --> 00:08:39,806
We can make things a
little more interesting


187
00:08:40,326 --> 00:08:41,746
and just swap the red
and green channels.


188
00:08:41,746 --> 00:08:43,246
So this is a very
simple process.


189
00:08:43,706 --> 00:08:48,106
We just take our red channel and
put it in the location of the -


190
00:08:48,106 --> 00:08:51,606
where the green was and take
the green channel and put


191
00:08:51,606 --> 00:08:52,636
in the location where
the red was.


192
00:08:52,636 --> 00:08:56,026
And if we were to apply this
kernel to our input image,


193
00:08:56,526 --> 00:08:58,526
we get a new output image,
and you can clearly see


194
00:08:58,526 --> 00:09:01,166
that the macaroon in the
foreground has changed colors


195
00:09:01,166 --> 00:09:04,306
and same thing for the green.


196
00:09:05,516 --> 00:09:07,186
We can make things a little
more interesting and so,


197
00:09:07,186 --> 00:09:08,506
what it looks like
when you actually want


198
00:09:08,546 --> 00:09:10,916
to have an input parameter
that controls how much


199
00:09:10,916 --> 00:09:11,976
of this effect gets applied.


200
00:09:12,506 --> 00:09:15,616
So here we have a new variable
called amount that's applied -


201
00:09:15,616 --> 00:09:17,636
that's used in our kernel.


202
00:09:18,486 --> 00:09:21,216
And we just use a mix function
to do linear interpolation


203
00:09:21,216 --> 00:09:24,966
in between the original
unmodified pixel value,


204
00:09:25,526 --> 00:09:28,926
our final destination value
as if it was at value 1.0,


205
00:09:28,926 --> 00:09:31,646
and then the input value amount
that is going to be something


206
00:09:31,646 --> 00:09:32,686
that goes between 0 and 1.


207
00:09:32,986 --> 00:09:35,086
And if we were to apply this
kernel and vary the value


208
00:09:35,086 --> 00:09:39,916
between 0 and 1 interactively,
you would get very quickly a,


209
00:09:40,116 --> 00:09:43,026
you know, an animated blend


210
00:09:43,026 --> 00:09:44,946
in between these
two extreme images.


211
00:09:46,086 --> 00:09:47,566
And that's pretty much
all you need to do


212
00:09:47,566 --> 00:09:49,726
to write a color kernel on iOS.


213
00:09:50,746 --> 00:09:56,026
The next thing we need to
do, once we've done our work


214
00:09:56,026 --> 00:09:58,196
in kernel land, running
the CIKernel,


215
00:09:58,636 --> 00:10:00,976
is we need to subclass CIFilter
in order to drive that kernel.


216
00:10:01,766 --> 00:10:03,416
So in this case, we
derive from CIFilter.


217
00:10:03,416 --> 00:10:06,166
We've created a new filter
called SwapRedGreenFilter.


218
00:10:07,106 --> 00:10:10,446
It has two properties, the first
property being the input image


219
00:10:10,446 --> 00:10:11,436
that we're going
to be working on


220
00:10:11,676 --> 00:10:14,256
and the second property
is the input amount.


221
00:10:14,256 --> 00:10:17,946
So how much of that along
(0,1) do we want to go?


222
00:10:19,346 --> 00:10:21,616
So let's take a look at the
methods that we're going


223
00:10:21,616 --> 00:10:22,636
to be implementing today.


224
00:10:23,286 --> 00:10:24,336
First things first, we're going


225
00:10:24,336 --> 00:10:26,116
to be using this throughout
our presentation today.


226
00:10:26,116 --> 00:10:27,316
We're going to have the
convenience function


227
00:10:27,316 --> 00:10:29,626
for creating a kernel such that
we don't recreate these kernels


228
00:10:30,066 --> 00:10:31,676
at every frame, because
we don't want to do that.


229
00:10:32,736 --> 00:10:34,676
We're going to have a
customAttributes method,


230
00:10:34,676 --> 00:10:37,436
which is oftentimes used
to drive UI elements,


231
00:10:37,436 --> 00:10:39,806
such as what we saw in Core
Image Funhouse earlier,


232
00:10:40,316 --> 00:10:41,006
in the previous talk.


233
00:10:41,846 --> 00:10:45,276
And the method that you
absolutely must implement,


234
00:10:45,276 --> 00:10:46,366
which is outputImage, and that's


235
00:10:46,606 --> 00:10:48,156
where you take all
your input parameters


236
00:10:48,746 --> 00:10:52,626
and you drive your kernel
to produce an output image.


237
00:10:52,706 --> 00:10:55,736
So let's take a look at
the actual implementation.


238
00:10:56,636 --> 00:10:59,736
As you can see, creating a
CIColorKernel is just done


239
00:10:59,736 --> 00:11:01,736
by calling CIColorKernel
kernelWithString:,


240
00:11:01,736 --> 00:11:03,656
and passing along
our kernel code.


241
00:11:03,656 --> 00:11:08,536
The next thing we need to
do is call self myKernel,


242
00:11:08,836 --> 00:11:12,726
and then we apply that and
we pass in two arguments,


243
00:11:12,726 --> 00:11:14,546
the input image, which
maps to the first parameter


244
00:11:14,546 --> 00:11:16,776
of our kernel, and
an input amount,


245
00:11:16,776 --> 00:11:18,746
which maps to our second
parameter of our kernel.


246
00:11:19,216 --> 00:11:20,636
And that is literally
all we need to do


247
00:11:20,636 --> 00:11:22,876
to create a custom
color kernel on iOS.


248
00:11:24,066 --> 00:11:27,266
So now, let's look at a slightly
more complicated example,


249
00:11:27,996 --> 00:11:31,436
where we, in addition
to modifying colors,


250
00:11:32,306 --> 00:11:35,846
we also use position
to determine how much


251
00:11:35,846 --> 00:11:36,826
of an effect should be applied.


252
00:11:36,826 --> 00:11:39,006
So let's pretend we wanted
to do a vignette effect


253
00:11:39,006 --> 00:11:43,666
and take the image on the
left and produce a new image


254
00:11:43,666 --> 00:11:47,706
on the right that looked
like it had been vignetted.


255
00:11:48,716 --> 00:11:51,806
So in this case, you can see
that the - we want the pixels


256
00:11:51,806 --> 00:11:54,136
at the center of the
image to remain unmodified


257
00:11:54,536 --> 00:11:56,906
and as we go further out towards
the corners of the image,


258
00:11:57,276 --> 00:11:59,576
we want those to be
as dark as possible.


259
00:12:00,986 --> 00:12:03,366
So we can think of those as
being, like, values between 1


260
00:12:03,366 --> 00:12:06,496
and 0 and we're going


261
00:12:07,116 --> 00:12:14,716
to be linearly interpolating
along that vector.


262
00:12:14,716 --> 00:12:17,096
So if we were to look at what
an image looked like if we were


263
00:12:17,096 --> 00:12:20,256
to create that 0 to 1
mapping for the entire image,


264
00:12:20,626 --> 00:12:22,936
we were to get this gray
image in the middle here.


265
00:12:23,296 --> 00:12:24,706
And then, if we take
our image on the left


266
00:12:24,706 --> 00:12:26,166
and we multiple the red, green,


267
00:12:26,166 --> 00:12:29,566
blue values by that
new computed value,


268
00:12:29,736 --> 00:12:30,996
we would get our
vignetted effect.


269
00:12:30,996 --> 00:12:31,926
And it's really that simple.


270
00:12:32,526 --> 00:12:33,756
So now, let's take a look


271
00:12:33,756 --> 00:12:37,176
at how we use position
information inside of a kernel.


272
00:12:37,226 --> 00:12:39,426
So this is the signature for
our kernel and we're going to go


273
00:12:39,426 --> 00:12:42,136
over through each step about how
we would create a simple color


274
00:12:42,136 --> 00:12:43,286
kernel that depends on position.


275
00:12:44,526 --> 00:12:47,626
So as I mentioned
earlier, CIImages may


276
00:12:47,626 --> 00:12:49,886
or may not be - have
a (0,0) origin.


277
00:12:50,226 --> 00:12:52,896
In this case, you can see that
the image is not at the origin,


278
00:12:52,966 --> 00:12:55,196
and what we need to do is
find out where the center


279
00:12:55,196 --> 00:12:56,886
of the image is because
every pixel that's going


280
00:12:56,886 --> 00:12:58,916
to get darkened is with
respect to the center.


281
00:12:58,946 --> 00:13:00,526
So we need to know
how far away we are.


282
00:13:02,156 --> 00:13:05,056
The next thing we can do is we
can take the size of the image


283
00:13:05,196 --> 00:13:08,506
and just divide that in two, and
we have a vector that takes us


284
00:13:08,506 --> 00:13:12,506
from the lower left corner
of the image to the center.


285
00:13:12,506 --> 00:13:14,426
And then, if we add these
two vectors together,


286
00:13:14,426 --> 00:13:20,876
we have a new vector called
center offset, which takes us


287
00:13:20,876 --> 00:13:23,366
from the origin of the image
to the center of our image.


288
00:13:24,166 --> 00:13:28,426
We then are going to compute one
more value, which we're going


289
00:13:28,426 --> 00:13:31,796
to be passing into our
kernel, which is the extent


290
00:13:31,796 --> 00:13:33,636
of the image divided by
two, and that's going


291
00:13:33,686 --> 00:13:37,736
to be the longest length
of any point in our image,


292
00:13:38,136 --> 00:13:40,796
and we're going to be
dividing values by that


293
00:13:40,796 --> 00:13:41,876
such that we can
determine how much


294
00:13:41,876 --> 00:13:42,846
of the effect needs
to be applied.


295
00:13:44,156 --> 00:13:47,906
So as I was saying earlier,
we have many extensions inside


296
00:13:47,906 --> 00:13:48,946
of Core Image to
deal with imaging.


297
00:13:49,366 --> 00:13:52,716
One of them is called destCoord
and this is going to tell you


298
00:13:52,716 --> 00:13:54,956
which current pixel
you're trying


299
00:13:54,956 --> 00:13:57,306
to render in global space.


300
00:13:58,676 --> 00:14:01,536
So what we need to do is
figure out how far away


301
00:14:01,536 --> 00:14:04,136
from the center is every
single destCoord that's going


302
00:14:04,136 --> 00:14:04,746
to get evaluated.


303
00:14:04,746 --> 00:14:06,556
And this function
will get called


304
00:14:06,556 --> 00:14:09,096
on every single fragment you're
trying to render in the image.


305
00:14:10,386 --> 00:14:12,476
So you can see here,
it's a simple matter


306
00:14:12,476 --> 00:14:14,126
of just subtracting one
vector from the other.


307
00:14:14,126 --> 00:14:16,696
We just take destCoord
minus centerOffset


308
00:14:16,696 --> 00:14:19,036
and we get a new vector
called vecFromCenter.


309
00:14:20,576 --> 00:14:23,306
So inside the kernel, this
is what it looks like.


310
00:14:24,396 --> 00:14:26,056
We're then going to get
the length of that vector,


311
00:14:26,396 --> 00:14:28,926
called distance in this case.


312
00:14:29,406 --> 00:14:31,966
We compute a darkening amount
by doing distance divided


313
00:14:31,966 --> 00:14:34,016
by radius, which,
like, half our diagonal


314
00:14:34,016 --> 00:14:35,286
of the original rectangle.


315
00:14:35,666 --> 00:14:37,866
One minus that is going to
give us our darkening amount.


316
00:14:38,756 --> 00:14:42,376
And then, finally, we
call - we return a vec4


317
00:14:42,526 --> 00:14:46,556
that takes our input sample,
s, multiplies the RGB value


318
00:14:46,556 --> 00:14:48,796
by that darkening amount,
and maintains alpha as is.


319
00:14:49,336 --> 00:14:51,086
And we have the vignetting
effect.


320
00:14:51,816 --> 00:14:53,286
So now, let's take a
look at what we need


321
00:14:53,286 --> 00:14:55,336
to do in Objective-C land.


322
00:14:57,016 --> 00:15:00,756
First things first, the
dod, which stands for domain


323
00:15:00,756 --> 00:15:02,746
of definition, and we're going
to talk in more detail what


324
00:15:02,746 --> 00:15:06,726
that means in a bit, but this
is how much - what is the extent


325
00:15:06,726 --> 00:15:07,706
of the output image going to be?


326
00:15:07,706 --> 00:15:08,406
And in this case, it's -


327
00:15:08,756 --> 00:15:10,786
our output image is the same
size as our input image.


328
00:15:11,266 --> 00:15:13,756
So that's constant.


329
00:15:13,756 --> 00:15:18,226
We're then going to compute our
radius and then create a vec2,


330
00:15:18,656 --> 00:15:21,046
which takes us to the
center of the image.


331
00:15:21,626 --> 00:15:26,256
And then, all we need to do
is call self myKernel apply


332
00:15:26,256 --> 00:15:30,176
WithExtent dod and then pass in
an array of arguments, which,


333
00:15:30,396 --> 00:15:32,806
again, you can see the input
image matches the first


334
00:15:32,806 --> 00:15:33,806
parameter of our kernel,


335
00:15:34,376 --> 00:15:36,806
centerOffset matches
the second parameter


336
00:15:37,866 --> 00:15:39,466
and radius matches
the third parameter.


337
00:15:39,466 --> 00:15:42,426
So that's how we pass
parameters from Objective-C land


338
00:15:42,426 --> 00:15:45,216
into our kernel language lan.


339
00:15:45,826 --> 00:15:48,016
So let's talk a little bit more
about domain of definition.


340
00:15:49,306 --> 00:15:51,236
Oftentimes, domain of
definition is equal


341
00:15:51,236 --> 00:15:52,186
to the input image size.


342
00:15:52,526 --> 00:15:54,286
But there are situations when
that's not going to be the case.


343
00:15:54,586 --> 00:15:56,436
So if, for example, we
have two input images


344
00:15:56,806 --> 00:16:00,396
and we were doing a sourceOver,
you can image that if either one


345
00:16:00,396 --> 00:16:04,176
of these images didn't have a
(0,0) origin, the output image


346
00:16:04,176 --> 00:16:06,156
that you would want to
create would be larger.


347
00:16:06,516 --> 00:16:08,246
And so, you would want to
take the union of those two


348
00:16:09,106 --> 00:16:10,286
and that's what's all
you need to think of.


349
00:16:10,286 --> 00:16:13,516
What are the non-zero pixels
that your kernel is going


350
00:16:13,516 --> 00:16:17,016
to be producing by taking a
given set of input images?


351
00:16:17,726 --> 00:16:19,586
And that is what a
domain of definition is.


352
00:16:20,016 --> 00:16:21,806
And as a parameter, you
have to always specify.


353
00:16:22,776 --> 00:16:25,106
And that's really all you
need to know about how


354
00:16:25,106 --> 00:16:27,376
to write color kernels on iOS.


355
00:16:27,776 --> 00:16:30,426
So now, let's talk
about warp kernels,


356
00:16:30,656 --> 00:16:33,636
which is our second
subclass of CIKernel


357
00:16:33,716 --> 00:16:36,106
and let's you do geometry
modifications to an image.


358
00:16:37,556 --> 00:16:41,906
So in addition to
specifying DOD,


359
00:16:42,286 --> 00:16:44,806
you also need to specify
an ROI, and we're going


360
00:16:44,806 --> 00:16:45,796
to explain what that
is in a minute.


361
00:16:45,796 --> 00:16:47,416
But let's take a
look at the workflow.


362
00:16:47,506 --> 00:16:50,356
The workflow is basically
that you get an input position


363
00:16:50,356 --> 00:16:52,306
and you're asked to produce
a new output position.


364
00:16:52,546 --> 00:16:54,126
And those are both
going to be vec2s.


365
00:16:55,556 --> 00:16:58,576
So let's, once again, look
at the simplest example,


366
00:16:58,906 --> 00:17:00,976
which is a kernel
that does nothing


367
00:17:01,276 --> 00:17:02,676
and just returns destCoord.


368
00:17:03,316 --> 00:17:07,126
If we were to apply that kernel
to our input image, no change.


369
00:17:07,566 --> 00:17:10,356
And so, if we were to look at
a random pixel in our image,


370
00:17:10,626 --> 00:17:13,146
what we always need to think
about is, in our output image,


371
00:17:13,506 --> 00:17:15,925
where does that pixel come
from in our input image?


372
00:17:15,925 --> 00:17:17,836
And that is the equation
that we need to come up.


373
00:17:17,836 --> 00:17:21,175
In this case, you can see
that it's just identity.


374
00:17:21,175 --> 00:17:23,226
There's no change, which is why
we can just return destCoord.


375
00:17:23,746 --> 00:17:28,326
Let's take a slightly more
interesting example, where,


376
00:17:28,326 --> 00:17:29,986
instead of just returning
destCoord,


377
00:17:29,986 --> 00:17:32,466
we're going to flip the image
around the center of it.


378
00:17:32,466 --> 00:17:36,626
In this case, it should be
fairly clear that if we look


379
00:17:36,626 --> 00:17:39,646
at a pixel near the shoulder
of this woman on the right


380
00:17:39,646 --> 00:17:42,846
and the output image, the
- where we need to read


381
00:17:42,846 --> 00:17:44,706
from in the input image
is not the same location.


382
00:17:45,356 --> 00:17:46,826
Instead, we're going
to be reading


383
00:17:46,826 --> 00:17:47,726
from a different location.


384
00:17:47,996 --> 00:17:51,206
The y-value won't be changing,
but the x-value is different.


385
00:17:51,556 --> 00:17:54,706
So destCoord.y is fine,
destCoord.x needs to change.


386
00:17:55,416 --> 00:17:56,036
How do we do that?


387
00:17:56,036 --> 00:17:56,986
Well, we have an x value,


388
00:17:56,986 --> 00:18:00,106
destCoord.x. We know what
the width of the image is.


389
00:18:00,106 --> 00:18:01,926
We can pass that in as a
parameter to our kernel.


390
00:18:03,276 --> 00:18:06,286
And using that, we can
do imageWidth minus x


391
00:18:06,286 --> 00:18:08,696
and that gives us the location
in our original input image


392
00:18:09,046 --> 00:18:10,326
from where we want to read.


393
00:18:10,446 --> 00:18:14,406
And if we do that, you can see
that the kernel above, mirrorX,


394
00:18:15,096 --> 00:18:16,386
that's all we need to apply.


395
00:18:16,876 --> 00:18:18,776
We just take destCoord,
imageWidth minus x


396
00:18:18,776 --> 00:18:21,406
for our x coordinate, and
return the same value in y


397
00:18:21,406 --> 00:18:22,896
and we get a mirroring effect.


398
00:18:24,496 --> 00:18:30,426
So let's take a look at what
we need to do in Objective-C.


399
00:18:31,166 --> 00:18:32,946
So now, instead of
creating a color kernel,


400
00:18:32,946 --> 00:18:34,356
we create a CIWarpKernel.


401
00:18:35,016 --> 00:18:36,586
We pass along the source
code we had earlier


402
00:18:37,306 --> 00:18:39,626
and then we call apply.


403
00:18:40,406 --> 00:18:44,356
And now, apply you'll see has
one additional parameter we need


404
00:18:44,356 --> 00:18:45,806
to pass, which is
an ROI callback.


405
00:18:46,096 --> 00:18:48,556
And I'm going to - the next
thing we're going to do is talk


406
00:18:48,556 --> 00:18:51,076
about what is an ROI callback
and why do we need to do


407
00:18:51,076 --> 00:18:53,376
that for warp kernels
and why it's important.


408
00:18:54,676 --> 00:18:57,596
So ROI stands for
region of interest.


409
00:18:57,916 --> 00:19:01,006
The basic idea is that
internally, Core Image is going


410
00:19:01,006 --> 00:19:04,136
to tile your image and
perform smaller renders,


411
00:19:04,966 --> 00:19:07,146
such that we can deal
with larger images


412
00:19:07,146 --> 00:19:08,676
and do things - optimally
on the GPU.


413
00:19:09,346 --> 00:19:12,896
Now, as I'm sure you can
imagine, what we need to do


414
00:19:12,896 --> 00:19:14,446
when we're producing
a rectangle,


415
00:19:14,446 --> 00:19:17,286
let's say rectangle 5 here,
is determine where the data


416
00:19:17,286 --> 00:19:18,796
in the original input
image comes from,


417
00:19:18,796 --> 00:19:20,076
such that we can load that.


418
00:19:20,896 --> 00:19:23,706
And we can't figure that out on
our own and you need to help us


419
00:19:23,706 --> 00:19:26,206
to provide that information
for us.


420
00:19:26,486 --> 00:19:28,686
And you do that by
providing an ROI callback,


421
00:19:28,836 --> 00:19:30,206
which is the additional
parameter that you need


422
00:19:30,206 --> 00:19:32,056
to specify for a warp kernel.


423
00:19:33,286 --> 00:19:35,216
So in this case, it
should be fairly obvious


424
00:19:35,216 --> 00:19:37,186
if we take our mirrored
kernel that,


425
00:19:37,186 --> 00:19:39,546
if we look at the
rectangle on the output image


426
00:19:40,026 --> 00:19:41,936
and the rectangle on the
input image, that the -


427
00:19:41,936 --> 00:19:45,726
we overlay our coordinate
system over these once again,


428
00:19:46,076 --> 00:19:48,126
we can see that the width of
the rectangle isn't changing.


429
00:19:48,996 --> 00:19:50,696
The height of the
rectangle isn't changing.


430
00:19:51,536 --> 00:19:53,616
The origin and y of the
rectangle isn't changing.


431
00:19:53,776 --> 00:19:55,296
But we do have a new origin.


432
00:19:56,136 --> 00:19:59,746
So all we need to do, given an
output rectangle 5 on the right,


433
00:20:00,256 --> 00:20:02,016
we need to figure out
where the one on the left


434
00:20:02,016 --> 00:20:04,686
and the input image comes from,
is compute a new rectangle,


435
00:20:04,686 --> 00:20:09,416
a new origin, and that's simply
equal to the image width plus -


436
00:20:09,416 --> 00:20:13,456
sorry, minus the origin and
the width of the rectangle


437
00:20:13,456 --> 00:20:14,446
that we're currently
trying to render.


438
00:20:15,146 --> 00:20:17,946
And that is basically all we
need to do for our ROI function.


439
00:20:19,206 --> 00:20:21,256
So now, let's take a look


440
00:20:21,256 --> 00:20:23,886
at a little more detail
of our mirror kernel.


441
00:20:24,306 --> 00:20:26,316
Now, it - in this case,
we're going to start off


442
00:20:26,316 --> 00:20:27,626
by doing a check that
I mentioned earlier.


443
00:20:27,626 --> 00:20:29,856
We - that CIImages may
be of infinite extent.


444
00:20:30,136 --> 00:20:33,476
And in order to keep the
kernel a little simple, we're -


445
00:20:33,626 --> 00:20:36,666
we decided to just show you what
it looks like if you are dealing


446
00:20:36,666 --> 00:20:38,056
with flipping around
the center of the image.


447
00:20:38,056 --> 00:20:40,936
In this case, it
doesn't deal with images


448
00:20:40,936 --> 00:20:42,926
that have infinite extent, so
we're just going to return nil.


449
00:20:43,216 --> 00:20:44,706
This wouldn't be a difficult
modification to make,


450
00:20:44,706 --> 00:20:46,596
but too long for
doing on a slide.


451
00:20:47,676 --> 00:20:50,456
So first things first, inside
of our output image method


452
00:20:50,456 --> 00:20:51,036
for the mirror kernel,


453
00:20:51,036 --> 00:20:52,016
we're going to make
sure we're not dealing


454
00:20:52,016 --> 00:20:53,176
with an image of
infinite extent.


455
00:20:54,006 --> 00:20:55,276
We're then going to
get a few parameters


456
00:20:55,276 --> 00:20:56,366
that we're going to be reusing.


457
00:20:56,966 --> 00:20:59,606
So first things first,
we're going to create


458
00:20:59,606 --> 00:21:04,356
and AffineTransform that
moves our image to the origin


459
00:21:04,966 --> 00:21:10,426
and then applies that
translation onto the image


460
00:21:10,426 --> 00:21:11,616
to create a new output image.


461
00:21:12,486 --> 00:21:15,786
We then apply our mirror
kernel and once we're done,


462
00:21:15,786 --> 00:21:18,016
we create a new translation that
moves it back to where it was.


463
00:21:18,016 --> 00:21:19,746
In our case, where we're
looking at the previous slide,


464
00:21:19,746 --> 00:21:21,656
there was no actual translation,
but if the image wasn't


465
00:21:21,656 --> 00:21:23,306
as (0,0) we would
have had to do that.


466
00:21:23,306 --> 00:21:26,646
And it's oftentimes easier
to think of a kernel in terms


467
00:21:26,646 --> 00:21:29,116
of how would this be either
when its image is centered


468
00:21:29,116 --> 00:21:31,256
or if it was at (0,0)
and then do the work


469
00:21:31,256 --> 00:21:35,106
about moving the image
in Object-C world


470
00:21:35,106 --> 00:21:36,306
than it is to do in the kernel.


471
00:21:38,276 --> 00:21:40,506
So let's take a look


472
00:21:40,656 --> 00:21:42,886
at a slightly more
complicated kernel.


473
00:21:43,446 --> 00:21:46,096
So let's pretend you had an
input image or some input video


474
00:21:46,556 --> 00:21:50,376
and the size of this
image was 1024x768,


475
00:21:50,756 --> 00:21:56,266
but what you really wanted was
an image that was wider and was


476
00:21:56,356 --> 00:21:59,156
of - in the width of 1280.


477
00:22:00,296 --> 00:22:02,086
So we can do that with
an anamorphic stretch


478
00:22:02,946 --> 00:22:05,826
and we're going to do that
by maintaining the center


479
00:22:05,826 --> 00:22:08,386
of the image and just stretching
it out further as you get away -


480
00:22:08,386 --> 00:22:13,026
further away from the center.


481
00:22:13,026 --> 00:22:17,436
I should be fairly clear that,
based on this vector field,


482
00:22:18,566 --> 00:22:22,936
that the y-values for
this kernel aren't going


483
00:22:22,936 --> 00:22:23,466
to change as well.


484
00:22:23,466 --> 00:22:25,116
We're only going to be
modifying values in X.


485
00:22:25,376 --> 00:22:27,996
So we can think about
this problem purely


486
00:22:27,996 --> 00:22:29,416
in terms of x-values.


487
00:22:30,436 --> 00:22:32,726
So let's take a look at
a little bit of math.


488
00:22:33,626 --> 00:22:36,026
It helps oftentimes to
have invertible functions


489
00:22:36,356 --> 00:22:38,296
and let's take a look
at how we're going


490
00:22:38,296 --> 00:22:40,786
to model this problem
in our head.


491
00:22:40,786 --> 00:22:42,586
So let's pretend we
have an input value, x,


492
00:22:42,586 --> 00:22:44,576
and some output value, f(x).


493
00:22:46,146 --> 00:22:48,476
If we weren't - and we're
going to use these with respect


494
00:22:48,476 --> 00:22:49,366
to the center of the image.


495
00:22:49,366 --> 00:22:50,596
All this math is going to be


496
00:22:50,596 --> 00:22:51,466
with respect to the
center image.


497
00:22:51,466 --> 00:22:54,746
So it's going to go from
minus width/2 to width/2.


498
00:22:54,876 --> 00:22:58,026
If we were not to modify
the scale of this image,


499
00:22:58,026 --> 00:23:00,146
so if we were taking an input
image of size, you know,


500
00:23:00,146 --> 00:23:05,976
1024x768 and producing 1024x768,
we would just have identity.


501
00:23:06,226 --> 00:23:10,086
So a slope of 1, some
input value xi is going


502
00:23:10,126 --> 00:23:11,916
to produce a new
- the same value


503
00:23:11,916 --> 00:23:14,976
on the y-axis, f(xi)
is equal to xi.


504
00:23:15,056 --> 00:23:19,206
But what we want instead is
that as we get further away


505
00:23:19,206 --> 00:23:20,116
from the center of the image,


506
00:23:20,466 --> 00:23:22,526
we want our points
to be moved more.


507
00:23:23,326 --> 00:23:26,186
And we can do that by
creating a curve like this,


508
00:23:26,186 --> 00:23:29,126
which maintains a slope of 1
through the center of the image.


509
00:23:30,066 --> 00:23:34,096
And the equation
for this is just x


510
00:23:34,096 --> 00:23:37,276
over 1 minus absolute value
of x/k, and we'll talk


511
00:23:37,276 --> 00:23:38,796
about that k constant
in a moment.


512
00:23:39,846 --> 00:23:42,296
And this is the same equation
that we're going to use


513
00:23:42,296 --> 00:23:44,336
to compute the DOD, or
domain of definition,


514
00:23:44,336 --> 00:23:45,196
that we spoke about earlier.


515
00:23:47,256 --> 00:23:50,586
So now, if we take that
equation, we put a source value


516
00:23:50,586 --> 00:23:52,956
of x into it, we get new
destination value of X,


517
00:23:52,956 --> 00:23:54,716
which shows how far
away we moved.


518
00:23:56,356 --> 00:24:00,116
In this case, the
equation is really handy


519
00:24:00,116 --> 00:24:01,546
because it's very
easy to invert.


520
00:24:01,546 --> 00:24:03,066
So if we were to
isolate the value of x


521
00:24:03,066 --> 00:24:04,896
in the previous equation
from sourceToDest(x),


522
00:24:05,456 --> 00:24:07,796
we would get a new equation
called destToSource(x),


523
00:24:08,166 --> 00:24:11,286
which would just
be 1 over - sorry,


524
00:24:11,286 --> 00:24:15,666
x/1 plus absolute value of x/k.


525
00:24:17,146 --> 00:24:18,466
And this is the function
that we're going


526
00:24:18,466 --> 00:24:25,046
to be using internally in
our kernel and our ROI math.


527
00:24:25,716 --> 00:24:27,826
Because, as I said earlier, you
always have to think in terms


528
00:24:27,826 --> 00:24:32,786
of where does this pixel
come from in the input?


529
00:24:32,786 --> 00:24:35,186
So how do we compute k?


530
00:24:35,306 --> 00:24:36,396
It's a relatively simple matter.


531
00:24:36,396 --> 00:24:38,976
We just do desiredWidth,
so in this case 1280,


532
00:24:38,976 --> 00:24:41,166
divided by inputWidth, 1024.


533
00:24:41,166 --> 00:24:42,276
We get some scale value.


534
00:24:42,846 --> 00:24:46,836
The k value is just equal to
inputWidth/1 minus 1/scale.


535
00:24:47,926 --> 00:24:50,826
And then, if we were to plug
these values into our equations,


536
00:24:50,826 --> 00:24:54,816
we would see that sourceToDest
of 1024 would gives us 1280


537
00:24:54,816 --> 00:24:58,746
and to destToSource of
1280 would gives us 1024.


538
00:24:58,746 --> 00:25:01,466
So all the math works out.


539
00:25:01,726 --> 00:25:03,906
Now, what does a
kernel look like?


540
00:25:05,216 --> 00:25:06,266
It's relatively simply.


541
00:25:06,266 --> 00:25:08,266
We get to reuse our equation
that we talked about earlier.


542
00:25:09,536 --> 00:25:11,416
First things first, we're
going to translate it


543
00:25:11,416 --> 00:25:13,816
such that we're working
with respect to the center.


544
00:25:14,046 --> 00:25:16,636
We then apply our equation
and then translate it back.


545
00:25:16,776 --> 00:25:19,166
And that's all we need to do to
create to an anamorphic stretch.


546
00:25:20,536 --> 00:25:23,426
But we do have to
specify an ROI function.


547
00:25:23,726 --> 00:25:26,616
So let's talk about what
an ROI function might look


548
00:25:26,616 --> 00:25:28,386
like for this kernel.


549
00:25:29,666 --> 00:25:33,386
So if we have an input rectangle
r, we're going to be asked


550
00:25:33,386 --> 00:25:36,326
to produce some input,
rectangle r'.


551
00:25:37,106 --> 00:25:39,946
So for a given rectangle
we're trying to render,


552
00:25:39,946 --> 00:25:42,026
where does the rectangle in
the input image come from?


553
00:25:42,386 --> 00:25:43,776
Now, if you didn't have
an invertible function,


554
00:25:43,776 --> 00:25:45,266
you could always
return something larger,


555
00:25:45,576 --> 00:25:48,766
but that might hurt you
if you were trying to deal


556
00:25:48,766 --> 00:25:49,726
with very large images.


557
00:25:49,726 --> 00:25:51,316
So it's helpful to
try to get this to be


558
00:25:51,456 --> 00:25:52,826
as optimal as possible.


559
00:25:53,086 --> 00:25:55,696
In this case, we have
easily invertible functions,


560
00:25:55,696 --> 00:25:58,976
so we're going to be able
to compute this exactly.


561
00:25:58,976 --> 00:26:00,246
So let's take a look
at the left -


562
00:26:00,246 --> 00:26:01,846
and again, nothing changes in Y.


563
00:26:01,846 --> 00:26:04,156
So all we need to worry about
is what's happening along


564
00:26:04,156 --> 00:26:04,896
the x-axis.


565
00:26:05,866 --> 00:26:08,456
So we have our left point,
which is equal to r.origin.x


566
00:26:09,406 --> 00:26:11,696
from our original input
- output rectangle,


567
00:26:11,766 --> 00:26:14,606
and we want to find
out where our r' is.


568
00:26:14,606 --> 00:26:17,826
We just need to put it through
our equation for destToSource


569
00:26:17,826 --> 00:26:19,016
and we get a new
left point prime.


570
00:26:19,486 --> 00:26:22,346
And then, if we look at
the point at the other end


571
00:26:22,346 --> 00:26:25,756
of our input rectangle,
our - so - which is equal


572
00:26:25,756 --> 00:26:27,876
to r.origin.x plus the width


573
00:26:27,876 --> 00:26:29,566
of the rectangle we're
currently trying to render,


574
00:26:30,026 --> 00:26:32,176
we can put that through
our same equation


575
00:26:32,386 --> 00:26:34,456
and get a new right point prime.


576
00:26:35,016 --> 00:26:38,366
Should be fairly obvious.


577
00:26:38,366 --> 00:26:39,916
We have all the information
we need now


578
00:26:40,286 --> 00:26:45,296
to produce the rectangle for our
ROI function and it's just going


579
00:26:45,296 --> 00:26:47,836
to be computed by calculating
a new width, which is equal


580
00:26:47,836 --> 00:26:51,196
to right point prime
minus left point prime,


581
00:26:51,486 --> 00:26:53,356
and then we just
return a new rectangle,


582
00:26:53,406 --> 00:26:58,066
which has the left point prime
as its origin, the same origin


583
00:26:58,066 --> 00:27:00,196
in y that we had for the input,


584
00:27:00,866 --> 00:27:02,226
a new width, and
the same height.


585
00:27:02,696 --> 00:27:07,646
And that's how you would
provide your ROI function


586
00:27:08,316 --> 00:27:09,076
for this kernel.


587
00:27:10,126 --> 00:27:13,926
So let's take a look
at how we get


588
00:27:13,926 --> 00:27:17,496
to reuse our code once
again from our kernel.


589
00:27:18,506 --> 00:27:21,706
We have our equation and if
you look at the code here,


590
00:27:21,706 --> 00:27:24,436
now we're back in
Objective-C land and we got


591
00:27:24,436 --> 00:27:27,556
to reuse the exact
same math, just written


592
00:27:27,556 --> 00:27:29,396
in C instead of CIKernel
language.


593
00:27:30,136 --> 00:27:33,926
We can create a function
that just does the equivalent


594
00:27:33,926 --> 00:27:36,046
of what we've shown in the
previous slide in pseudo-code,


595
00:27:36,406 --> 00:27:39,966
and returns a new rectangle,
given three input parameters,


596
00:27:40,446 --> 00:27:46,096
input rectangle r, a float
center, and a float value k,


597
00:27:46,096 --> 00:27:47,386
which is our constant
in the equation.


598
00:27:48,916 --> 00:27:50,156
The domain of definition,


599
00:27:50,476 --> 00:27:52,036
similarly can reuse
the same math


600
00:27:52,036 --> 00:27:53,026
that we talked about earlier.


601
00:27:53,436 --> 00:27:54,936
And instead of using


602
00:27:54,976 --> 00:28:00,666
as a denominator 1 plus absolute
value of x/k, we use 1-x/k,


603
00:28:00,666 --> 00:28:02,036
but it's exactly
the same otherwise.


604
00:28:02,566 --> 00:28:06,656
And we can take that same
pseudo-code and apply it


605
00:28:06,656 --> 00:28:09,336
to any given input
rectangle r to figure


606
00:28:09,336 --> 00:28:12,896
out what the output rectangle r'
would be that we were producing,


607
00:28:13,826 --> 00:28:16,756
given a certain scale
and the center.


608
00:28:16,756 --> 00:28:18,246
So now, let's take a look
at the outputImage method,


609
00:28:18,976 --> 00:28:20,566
which is what we used
to drive our kernel.


610
00:28:21,196 --> 00:28:24,816
We need to compute three
constants that we're going


611
00:28:24,816 --> 00:28:27,946
to pass into our kernel,
and it's oftentimes good


612
00:28:27,946 --> 00:28:30,956
to compute whatever - as much
as we can outside of the kernel


613
00:28:30,956 --> 00:28:32,276
if it's a constant
and isn't changing


614
00:28:32,276 --> 00:28:33,456
on a per fragment basis.


615
00:28:33,886 --> 00:28:37,476
So in this case, we have our -
a value k that we can compute


616
00:28:37,476 --> 00:28:39,976
in Objective-C land that
gets computed just once,


617
00:28:39,976 --> 00:28:42,346
which is great, and then we're
going to compute the center,


618
00:28:42,346 --> 00:28:45,306
which also we can compute
outside of the kernel, and then,


619
00:28:45,306 --> 00:28:48,446
finally, the DOD, which is
what are the output pixels


620
00:28:48,446 --> 00:28:49,646
that we're going to
be actually rendering?


621
00:28:50,236 --> 00:28:53,486
And then, all we need to
do is call applyWithExtent


622
00:28:53,486 --> 00:28:56,216
on the kernel that we
created given the DOD,


623
00:28:56,216 --> 00:28:59,456
and now we have an ROI callback,
which is a block callback,


624
00:29:00,096 --> 00:29:04,876
that has three parameters that
we pass in rect, center and k.


625
00:29:04,876 --> 00:29:05,716
Rect is given to us.


626
00:29:05,756 --> 00:29:08,956
And in the case of a warp
kernel, index is always going


627
00:29:08,956 --> 00:29:10,526
to be equal to 0 because
there's only one image.


628
00:29:10,846 --> 00:29:12,776
We'll talk later
about other examples


629
00:29:12,776 --> 00:29:14,296
about how this can get a
little more complicated.


630
00:29:14,296 --> 00:29:17,166
And then, finally, we pass our
two parameters to our kernel,


631
00:29:17,496 --> 00:29:21,546
center and k, and
that's all we need to do.


632
00:29:21,766 --> 00:29:24,216
So earlier, I alluded to one
more function that's useful


633
00:29:24,216 --> 00:29:26,006
for dealing with UI elements,


634
00:29:26,036 --> 00:29:28,306
and that is the customAttributes
method.


635
00:29:31,576 --> 00:29:34,246
The customAttributes method
lets you return a dictionary


636
00:29:34,726 --> 00:29:37,936
and a whole bunch of keys, such
as what is this filter going


637
00:29:37,936 --> 00:29:39,316
to - what's its display name,


638
00:29:39,646 --> 00:29:41,186
what kind of categories
does it apply to?


639
00:29:41,186 --> 00:29:42,916
So for example, this
is a distortion effect.


640
00:29:42,916 --> 00:29:45,056
It would apply equally
well on video


641
00:29:45,056 --> 00:29:46,616
or still images, et
cetera, et cetera.


642
00:29:47,056 --> 00:29:50,086
And then, for each input
parameter, you can talk


643
00:29:50,086 --> 00:29:52,126
about what are its limits,


644
00:29:52,126 --> 00:29:53,856
and this will help
us automatically put


645
00:29:53,856 --> 00:29:54,916
up UI for your elements.


646
00:29:54,916 --> 00:29:56,746
So if you were using this
in the context of something


647
00:29:56,746 --> 00:29:58,766
like CI Funhouse, it
would be very easy


648
00:29:58,766 --> 00:29:59,926
to just interact
with your kernel.


649
00:30:01,776 --> 00:30:05,976
So that's all I have
to say so far


650
00:30:06,366 --> 00:30:08,316
about color kernels
and warp kernels.


651
00:30:08,686 --> 00:30:10,006
Let's do a brief overview.


652
00:30:10,686 --> 00:30:15,766
So in the case of color kernels
we have zero or n input images.


653
00:30:16,776 --> 00:30:19,676
The input type is
going to be an --


654
00:30:19,676 --> 00:30:24,246
sample which is effectively
just a vec4.


655
00:30:24,876 --> 00:30:28,196
The output type is
going to be a vec4.


656
00:30:28,786 --> 00:30:31,646
You do have to specify a
domain of definition or DOD.


657
00:30:31,646 --> 00:30:36,636
And you do not have to specify
a region of interest function.


658
00:30:37,216 --> 00:30:41,116
In the case of a warp kernel
there's only ever one image


659
00:30:41,116 --> 00:30:42,036
that you'll be modifying.


660
00:30:42,616 --> 00:30:45,716
You can get to that location
that you're currently trying


661
00:30:45,716 --> 00:30:47,506
to render by calling
the function destCoord


662
00:30:48,236 --> 00:30:50,776
which is going to
give you a vec2.


663
00:30:50,776 --> 00:30:53,026
The output image is
basically just going


664
00:30:53,026 --> 00:30:54,676
to be a vec2 location
once again.


665
00:30:55,496 --> 00:31:00,636
You do have to specify a DOD and
a region of interest function.


666
00:31:00,966 --> 00:31:03,856
The next thing we're
going to talk


667
00:31:03,856 --> 00:31:06,236
about is the more
general-purpose kernels


668
00:31:07,166 --> 00:31:08,426
which are just CIKernels,


669
00:31:08,656 --> 00:31:10,106
and they have the
properties listed below.


670
00:31:10,326 --> 00:31:12,256
And on that note I'm going to
hand it off to Tony who's going


671
00:31:12,256 --> 00:31:13,596
to explain that in
a lot more detail.


672
00:31:14,006 --> 00:31:14,276
Thank you.


673
00:31:15,516 --> 00:31:19,856
[ Applause ]


674
00:31:20,356 --> 00:31:21,406
>> All right, thank you, Alex.


675
00:31:21,406 --> 00:31:22,886
Good afternoon, everyone.


676
00:31:22,886 --> 00:31:24,716
My name is Tony, and
what I'm going to talk


677
00:31:24,716 --> 00:31:26,546
about now is the
third and final type


678
00:31:26,546 --> 00:31:28,066
of kernels called
general kernels.


679
00:31:28,806 --> 00:31:33,006
So here - here again
are the three types


680
00:31:33,006 --> 00:31:35,276
of kernels we support in
iOS, and what we've seen


681
00:31:35,276 --> 00:31:38,456
so far are the first two,
color and warp, which allow you


682
00:31:38,456 --> 00:31:40,266
to implement the
majority of filters


683
00:31:40,266 --> 00:31:41,866
with as little code as possible.


684
00:31:42,026 --> 00:31:44,496
And now the third type called
general kernels basically


685
00:31:44,496 --> 00:31:45,856
completes the set
by allowing you


686
00:31:45,856 --> 00:31:47,546
to implement any kind of filter.


687
00:31:50,176 --> 00:31:52,916
So when would you need to
write a general kernel?


688
00:31:53,296 --> 00:31:56,166
Well, it's simply whenever
you cannot express your kernel


689
00:31:56,166 --> 00:31:57,976
as either a color or a warp.


690
00:31:59,036 --> 00:32:01,916
One scenario could be that your
kernel needs multiple samples


691
00:32:01,916 --> 00:32:05,236
of your input image, so for
example, any type of blur


692
00:32:05,236 --> 00:32:07,316
or convolution filter
would need that kernel.


693
00:32:07,426 --> 00:32:10,296
And a second - a
second scenario would be


694
00:32:10,296 --> 00:32:12,536
that your kernel contains
a dependent texture read.


695
00:32:13,006 --> 00:32:16,286
And by that, what I mean is,
you have to sample from image A


696
00:32:16,286 --> 00:32:19,826
in order to determine where
to sample from image B.


697
00:32:20,156 --> 00:32:22,456
And in a moment we'll take a
look at a couple of examples


698
00:32:22,456 --> 00:32:24,356
that actually illustrate
these two use cases.


699
00:32:25,166 --> 00:32:25,926
But first let's just go


700
00:32:25,926 --> 00:32:28,026
over some basic principles
behind general kernels.


701
00:32:29,106 --> 00:32:31,566
If you recall this diagram
earlier for color kernels,


702
00:32:31,906 --> 00:32:34,386
this shows that you can have
one or more input image -


703
00:32:34,886 --> 00:32:37,526
images to your kernel
along with an output image.


704
00:32:37,906 --> 00:32:40,926
But the key difference here
is that instead of each input


705
00:32:40,926 --> 00:32:44,186
to your kernel being just
an individual color sample,


706
00:32:44,666 --> 00:32:46,936
what you actually get
instead is a sampler object


707
00:32:47,236 --> 00:32:49,506
from which you can take as
many samples as you like


708
00:32:49,506 --> 00:32:52,036
and order them however you need.


709
00:32:52,036 --> 00:32:53,626
So let's take a look at
how you would actually go


710
00:32:53,626 --> 00:32:54,776
about spreading a
general kernel.


711
00:32:55,826 --> 00:32:57,986
So here we have a
very simple kernel


712
00:32:57,986 --> 00:32:59,186
that effectively does nothing.


713
00:32:59,596 --> 00:33:03,436
It takes an input image as
a sampler, samples from it,


714
00:33:03,726 --> 00:33:05,356
and returns the color unaltered.


715
00:33:06,026 --> 00:33:08,656
But in order to sample from
this input image you have


716
00:33:08,656 --> 00:33:11,206
to provide the coordinate
in sampler space


717
00:33:11,266 --> 00:33:12,726
and not in destination space.


718
00:33:13,076 --> 00:33:15,036
And there are several
reasons why the two spaces


719
00:33:15,036 --> 00:33:15,546
are different.


720
00:33:15,726 --> 00:33:17,396
One could be your
input image is tiled,


721
00:33:17,396 --> 00:33:20,006
but at the very minimum
the sampler space is


722
00:33:20,006 --> 00:33:23,366
in a coordinate space
that's between zero and one.


723
00:33:24,246 --> 00:33:25,866
But instead of having
to call destCoord


724
00:33:25,866 --> 00:33:27,906
and samplerTransform
every single time,


725
00:33:28,336 --> 00:33:31,716
you could also conveniently call
another CI language extension


726
00:33:31,716 --> 00:33:35,316
called samplerCoord,
and these two pieces


727
00:33:35,316 --> 00:33:37,316
of kernel functions are
actually effectively the same,


728
00:33:37,316 --> 00:33:40,086
and in fact compile up to
the same kernel program.


729
00:33:41,086 --> 00:33:43,566
So now you might wonder why
would you use samplerTransform


730
00:33:43,566 --> 00:33:45,016
when you can just
call samplerCoord


731
00:33:45,016 --> 00:33:46,336
and write less code?


732
00:33:46,626 --> 00:33:49,216
Well, let's imagine
you have a kernel here


733
00:33:49,216 --> 00:33:51,876
that actually does something,
and in this case it's just going


734
00:33:51,876 --> 00:33:55,006
to apply an offset of two
pixels in a vertical direction.


735
00:33:55,376 --> 00:33:57,456
And let's walk through
what would happen in this -


736
00:33:57,496 --> 00:33:58,866
if this kernel were
to be executed.


737
00:33:59,896 --> 00:34:02,776
So assume we have an input image
here that's just 600 pixels wide


738
00:34:02,776 --> 00:34:05,606
by 400 in your destination
space, and we're just going


739
00:34:05,606 --> 00:34:08,315
to render that out to with
the exact same dimensions.


740
00:34:08,866 --> 00:34:11,775
And assuming this image -
input image is not tiled,


741
00:34:11,775 --> 00:34:13,806
our sampler space is
just going to be normal -


742
00:34:13,806 --> 00:34:15,886
in normalized coordinates
between - with a range


743
00:34:15,886 --> 00:34:17,326
of zero to 1 in both axes.


744
00:34:18,346 --> 00:34:21,356
And let's imagine we're asked
to render out this pixel


745
00:34:21,356 --> 00:34:24,966
in the center, which has a
value of 300 in x and 200 in y.


746
00:34:25,846 --> 00:34:26,436
In the first call,


747
00:34:26,436 --> 00:34:29,126
the samplerCoord will
actually transform this value


748
00:34:29,126 --> 00:34:32,545
over to sampler space and give
you a value of (0.5, 0.5).


749
00:34:33,196 --> 00:34:34,976
And then if you were
to apply that offset


750
00:34:34,976 --> 00:34:38,806
in that space you'll get
a value of (0.5, 2.5).


751
00:34:39,436 --> 00:34:41,626
And as you can tell
you'll end up sampling


752
00:34:41,626 --> 00:34:44,166
from outside the image, and
the result you'll get will


753
00:34:44,166 --> 00:34:44,926
be incorrect.


754
00:34:45,255 --> 00:34:48,295
Instead what you want
to write is a kernel


755
00:34:48,295 --> 00:34:48,916
that looks like this.


756
00:34:49,246 --> 00:34:51,815
So again, let's walk through
what would happen in this case


757
00:34:51,815 --> 00:34:52,936
if the kernel was executed.


758
00:34:53,016 --> 00:34:55,146
You're going to first
call destCoord,


759
00:34:55,146 --> 00:34:57,096
which will give you a
value of 300 and 200.


760
00:34:57,216 --> 00:35:00,446
And then you're going to apply
the offset in that space,


761
00:35:00,846 --> 00:35:03,236
and you'll get a
value of 300 and 202.


762
00:35:03,716 --> 00:35:05,996
Then you're going to call
samplerTransform with that,


763
00:35:06,326 --> 00:35:09,816
and it'll give you a
value of 0.5 and 0.505.


764
00:35:10,006 --> 00:35:12,666
And as you can tell, this will
give you the correct location


765
00:35:12,666 --> 00:35:13,286
to sample from.


766
00:35:14,466 --> 00:35:18,236
So this is the right way to
apply an offset in your sample.


767
00:35:18,236 --> 00:35:21,996
So now that we got the
basics out of the way,


768
00:35:21,996 --> 00:35:23,366
let's take a look
at some examples


769
00:35:23,366 --> 00:35:24,756
that are a little
bit more interesting.


770
00:35:25,156 --> 00:35:28,926
The first one we're going to
look at is a motion blur filter,


771
00:35:29,106 --> 00:35:30,076
and this is an example


772
00:35:30,106 --> 00:35:32,286
where your kernel actually
requires multiple samples.


773
00:35:32,356 --> 00:35:34,976
So imagine we had an
input image like this,


774
00:35:35,446 --> 00:35:37,746
and in our kernel we're
going to compute the average


775
00:35:37,746 --> 00:35:40,676
of N samples along a
bi-directional vector.


776
00:35:40,676 --> 00:35:42,886
And in this particular
example we're just going


777
00:35:42,886 --> 00:35:44,806
to apply a horizontal
motion blur.


778
00:35:44,976 --> 00:35:47,336
And if you were to run this
kernel on all the pixels


779
00:35:47,336 --> 00:35:49,786
of this image you would get a
result that looks like that.


780
00:35:50,486 --> 00:35:52,486
So let's take a look at
what the kernel function


781
00:35:52,486 --> 00:35:53,866
for this would look like.


782
00:35:55,156 --> 00:35:58,806
So here we're going to define
our motion blur kernel called


783
00:35:58,806 --> 00:36:01,216
motionBlur, and return
a vec 4, and it's going


784
00:36:01,216 --> 00:36:02,116
to take two arguments.


785
00:36:02,156 --> 00:36:04,406
The first one is your
input image as a sampler,


786
00:36:04,966 --> 00:36:07,586
and a velocity vector that
will describe the direction


787
00:36:07,586 --> 00:36:08,426
in which you want to blur.


788
00:36:08,896 --> 00:36:12,126
And then we're going to
arbitrarily define a number


789
00:36:12,126 --> 00:36:13,856
of samples to take
in each direction.


790
00:36:13,856 --> 00:36:15,916
In this case it'll
be 10, but which -


791
00:36:16,076 --> 00:36:17,226
but it may be larger depending


792
00:36:17,226 --> 00:36:19,486
on what your maximum
blur radius is.


793
00:36:20,196 --> 00:36:22,306
Then we're going to
declare a variable S


794
00:36:22,426 --> 00:36:23,696
to accumulate all our samples.


795
00:36:23,696 --> 00:36:25,476
And we're going to
first call destCoord


796
00:36:25,476 --> 00:36:26,796
to get the current destination


797
00:36:26,796 --> 00:36:28,046
of the location we're
rendering to.


798
00:36:28,216 --> 00:36:31,606
And we're going to initialize
offset at the opposite end


799
00:36:31,606 --> 00:36:32,576
of your velocity vector.


800
00:36:33,096 --> 00:36:36,206
Then we're going to loop
through starting with one end


801
00:36:36,206 --> 00:36:38,986
of your velocity vector, take
10 samples along the way,


802
00:36:39,306 --> 00:36:42,746
applying the offset in each
iteration, take the center pixel


803
00:36:42,746 --> 00:36:44,536
which - which corresponds
to your destCoord,


804
00:36:44,586 --> 00:36:47,496
and then take another 10
samples on the other direction.


805
00:36:47,916 --> 00:36:51,816
And then once you've got all
your samples accumulated you


806
00:36:51,816 --> 00:36:53,246
just need to average
them all and -


807
00:36:53,376 --> 00:36:55,606
and that will give
you your final result.


808
00:36:56,556 --> 00:36:58,636
So again, you would
put this all together


809
00:36:58,636 --> 00:37:00,016
with a CIFilter subclass.


810
00:37:00,566 --> 00:37:02,756
To initialize that
kernel that we just saw,


811
00:37:02,756 --> 00:37:05,786
you just call CIKernel
kernelWithString and path


812
00:37:05,786 --> 00:37:07,856
of the source that we
just - that we saw earlier


813
00:37:07,886 --> 00:37:08,576
in the previous slide.


814
00:37:08,656 --> 00:37:10,956
And that string could
either be hard coded


815
00:37:10,956 --> 00:37:13,466
in your Objective-C file or
loaded from a file off this.


816
00:37:14,046 --> 00:37:16,706
And then in your
output image function


817
00:37:17,066 --> 00:37:20,026
for this case our filter has
two parameters, an input radius


818
00:37:20,076 --> 00:37:22,446
and an input angle from
which you can derive your


819
00:37:22,446 --> 00:37:23,296
velocity vector.


820
00:37:23,986 --> 00:37:27,456
And then you just call
apply on that kernel,


821
00:37:27,626 --> 00:37:31,406
giving it those arguments as
well as a DOD and a region


822
00:37:31,406 --> 00:37:33,626
of interest callback function
which we'll see in a moment.


823
00:37:34,006 --> 00:37:35,226
But first let's take
a look at how


824
00:37:35,226 --> 00:37:38,006
to calculate the
DOD for this filter.


825
00:37:38,756 --> 00:37:40,886
So again, here is the input
image with given extent.


826
00:37:40,886 --> 00:37:43,496
And if you were to
focus on the pixels


827
00:37:43,496 --> 00:37:45,936
that are just outside
the edge of that image,


828
00:37:46,266 --> 00:37:47,676
these pixels were
initially clear,


829
00:37:48,106 --> 00:37:51,586
but because those pixels end
up sampling inside the image


830
00:37:52,026 --> 00:37:54,576
when the filter is applied it
will actually become non-clear


831
00:37:54,576 --> 00:37:56,146
pixels, and so your domain


832
00:37:56,206 --> 00:38:01,016
of definition here is basically
expanded out in both directions


833
00:38:01,346 --> 00:38:03,796
that is the distance
of the velocity vector.


834
00:38:04,276 --> 00:38:06,676
And in this case this is
just along the x direction.


835
00:38:07,086 --> 00:38:09,996
But for the general case your -
the expression that you can use


836
00:38:09,996 --> 00:38:13,246
for your DOD is just that.


837
00:38:13,286 --> 00:38:17,976
Similarly for the ROI if you
were to consider a region


838
00:38:17,976 --> 00:38:20,676
that we need to render to that's
outlined here in - in blue


839
00:38:21,206 --> 00:38:25,136
and focus on one of the edges
of the - of this region,


840
00:38:25,136 --> 00:38:27,416
and imagine if you were to
- if you needed to render


841
00:38:27,416 --> 00:38:29,566
out that pixel in
our kernel we need


842
00:38:29,566 --> 00:38:32,436
to sample along the
bi-directional vector


843
00:38:32,906 --> 00:38:35,616
and take N number of
samples along that vector.


844
00:38:36,506 --> 00:38:38,796
You'll end up with a
region that you would need


845
00:38:38,796 --> 00:38:39,736
for that input image


846
00:38:39,776 --> 00:38:41,906
that corresponds to
the region in red.


847
00:38:42,436 --> 00:38:46,036
And so again, the ROI
callback function would have an


848
00:38:46,036 --> 00:38:49,926
expression that - that is in
this case the same as your DOD.


849
00:38:49,926 --> 00:38:50,736
And the reason for that is


850
00:38:50,776 --> 00:38:53,586
because your blur kernel is
symmetric in all directions.


851
00:38:55,936 --> 00:38:58,266
But now let's take this
effect one step further.


852
00:38:59,016 --> 00:39:01,876
Imagine you had this input
image where you did not want


853
00:39:01,876 --> 00:39:04,066
to apply the motion
blur uniformly


854
00:39:04,066 --> 00:39:05,386
across the entire image.


855
00:39:05,956 --> 00:39:08,746
Instead what you want is, keep
the vehicle in this image nice


856
00:39:08,746 --> 00:39:11,586
and sharp and blur out the
background of the image.


857
00:39:12,246 --> 00:39:15,176
And on top of that, you
don't want to apply the blur


858
00:39:15,226 --> 00:39:17,486
in the same direction for
all pixels; instead you want


859
00:39:17,486 --> 00:39:18,616
to blur them out radially


860
00:39:18,996 --> 00:39:22,796
to achieve an effect
that looks like this.


861
00:39:22,796 --> 00:39:26,336
And so one way to imagine
this image is a camera that's


862
00:39:26,336 --> 00:39:28,506
anchored to the car as it's
traveling through the road,


863
00:39:28,816 --> 00:39:31,046
and the picture was snapped, and
you got the blurry background.


864
00:39:32,236 --> 00:39:35,256
And so in order to achieve this
effect what you actually need is


865
00:39:35,256 --> 00:39:38,366
a mask image that not
only masks out the vehicle


866
00:39:38,576 --> 00:39:39,696
but provides a vector field


867
00:39:39,696 --> 00:39:41,846
that describes your
per-pixel blur velocity.


868
00:39:42,376 --> 00:39:45,006
So let's step through - let's
break down this filter step


869
00:39:45,006 --> 00:39:46,676
by step to see how we
would implement it.


870
00:39:46,676 --> 00:39:49,746
So you start with your input
image, and you're going


871
00:39:49,746 --> 00:39:52,976
to generate a mask from that
to - to mask out the images -


872
00:39:53,126 --> 00:39:54,466
the pixels that you
not want to blur.


873
00:39:54,586 --> 00:40:00,686
And then using that mask image
you can generate a vector field


874
00:40:01,326 --> 00:40:04,476
that will describe on a
per-pixel basis the velocity


875
00:40:04,476 --> 00:40:06,786
that you want to blur your
- apply your motion blur.


876
00:40:07,386 --> 00:40:10,646
And in this case the velocity
vectors are encoded in the red


877
00:40:10,646 --> 00:40:12,786
and green channels in
this image, and the pixels


878
00:40:12,786 --> 00:40:14,626
that are gray basically
represent a


879
00:40:14,626 --> 00:40:16,136
zero-velocity vector.


880
00:40:16,136 --> 00:40:21,056
Now you can - that's - you can
generate this mask image either


881
00:40:21,056 --> 00:40:23,566
offline, or you can even
write a color kernel


882
00:40:23,566 --> 00:40:24,536
to generate this image.


883
00:40:24,876 --> 00:40:26,726
But let's assume for
the - this example


884
00:40:26,726 --> 00:40:28,176
that we already have
this mask image.


885
00:40:29,226 --> 00:40:31,896
Then in our kernel what
you need to do first is,


886
00:40:32,146 --> 00:40:34,956
read from this mask image
to get your velocity vector,


887
00:40:36,336 --> 00:40:39,006
and then you would sample
from your input image


888
00:40:39,246 --> 00:40:42,286
and apply the same motion blur
effect that we just saw using


889
00:40:42,286 --> 00:40:43,766
that per-pixel velocity vector.


890
00:40:43,766 --> 00:40:45,436
And if you were to
run that kernel,


891
00:40:45,686 --> 00:40:49,226
that will give you the resulting
image that we just saw.


892
00:40:49,436 --> 00:40:52,626
So let's see how you would
implement this kernel function.


893
00:40:53,436 --> 00:40:56,636
So here again was the motion
blur kernel that we saw earlier,


894
00:40:56,636 --> 00:40:59,586
and the nice thing about CI's
kernel language is you can reuse


895
00:40:59,586 --> 00:41:02,126
this function in this new
kernel by converting it


896
00:41:02,126 --> 00:41:03,116
into a helper function.


897
00:41:03,566 --> 00:41:05,176
And this function has
the exact same code


898
00:41:05,176 --> 00:41:07,316
that we saw earlier
minus the kernel keyword.


899
00:41:07,526 --> 00:41:09,536
And then you can
just layer on top


900
00:41:09,536 --> 00:41:10,836
of that your new kernel function


901
00:41:10,836 --> 00:41:13,066
that we have called
motionBlurWithMask,


902
00:41:13,766 --> 00:41:16,016
which in this case will
take an input image as well


903
00:41:16,016 --> 00:41:18,756
as a mask image and a
parameter called radius


904
00:41:18,756 --> 00:41:20,736
that will specify your
maximum blur radius.


905
00:41:21,156 --> 00:41:23,696
And then in your kernel, the
first thing that you do is read


906
00:41:23,696 --> 00:41:27,596
from that mask image which
will contain the vector field


907
00:41:27,596 --> 00:41:28,546
in the R and G channels.


908
00:41:28,546 --> 00:41:31,636
And because those values are
stored in a range of zero


909
00:41:31,636 --> 00:41:34,266
to 1 you need to
de-normalize it to a range


910
00:41:34,426 --> 00:41:35,876
between "-1" and "+1".


911
00:41:36,386 --> 00:41:37,616
And once you got


912
00:41:37,616 --> 00:41:39,906
that directional vector you
just multiply that with radius


913
00:41:39,906 --> 00:41:41,186
to get a velocity vector.


914
00:41:41,336 --> 00:41:44,336
And then you just pass
that velocity vector


915
00:41:44,336 --> 00:41:46,096
into that motionBlur
helper function,


916
00:41:46,096 --> 00:41:48,246
and that will do the
calculation for you


917
00:41:48,246 --> 00:41:50,366
and give you the final
result that you want.


918
00:41:50,786 --> 00:41:54,436
And again, you put this all
together with CIFilter subclass


919
00:41:54,436 --> 00:41:56,236
which here is actually
very similar


920
00:41:56,236 --> 00:41:58,356
to the first example
that we just saw.


921
00:41:58,706 --> 00:41:59,656
The difference here -


922
00:41:59,656 --> 00:42:01,986
the difference here
is the slight change


923
00:42:01,986 --> 00:42:03,776
in the DOD calculation
where instead


924
00:42:03,776 --> 00:42:05,356
of a velocity vector we have -


925
00:42:05,606 --> 00:42:07,076
we just have an input
radius parameter


926
00:42:07,516 --> 00:42:10,746
that basically represents
the maximum velocity vector


927
00:42:10,746 --> 00:42:11,626
in your vector field.


928
00:42:12,656 --> 00:42:15,286
And the other difference here is
when you apply the kernel the -


929
00:42:15,746 --> 00:42:19,456
the roiCallback function
actually needs the


930
00:42:19,456 --> 00:42:20,266
index parameter.


931
00:42:20,266 --> 00:42:22,106
And this is the first
example where we see


932
00:42:22,106 --> 00:42:24,146
that because we have more
than one input images.


933
00:42:24,906 --> 00:42:26,806
So let's take a look at what
the roiCallback function


934
00:42:26,806 --> 00:42:27,456
for that looks like.


935
00:42:27,816 --> 00:42:31,376
Well, it's actually
pretty straightforward.


936
00:42:31,376 --> 00:42:34,196
You just need to check the
index parameter for which your -


937
00:42:34,496 --> 00:42:36,356
for which the ROI
is being called for.


938
00:42:36,736 --> 00:42:39,306
And if the index is equal
to zero that corresponds


939
00:42:39,306 --> 00:42:41,696
to our input image, and you
would return the same expression


940
00:42:41,696 --> 00:42:42,446
that we saw earlier.


941
00:42:43,116 --> 00:42:47,566
But if index - index is
equal to 1 that corresponds


942
00:42:47,566 --> 00:42:51,016
to our mask image, and for this
it's actually even more simple,


943
00:42:51,016 --> 00:42:52,636
you just return the
same input rect


944
00:42:52,636 --> 00:42:55,326
because we just take one sample


945
00:42:55,326 --> 00:42:57,126
from our mask image
using sampleCoord,


946
00:42:57,356 --> 00:42:59,676
and so that maps one to
one to the same location.


947
00:42:59,676 --> 00:43:03,646
So as you can see from
these two examples,


948
00:43:04,036 --> 00:43:07,356
we can implement any kind of
filter using general kernels,


949
00:43:07,356 --> 00:43:08,476
no matter how complex they are.


950
00:43:08,686 --> 00:43:11,266
And the reason for that
is because it was designed


951
00:43:11,266 --> 00:43:12,826
to be a desktop-class
kernel type


952
00:43:13,396 --> 00:43:16,366
that has the exact same language
syntax and semantics as OS X.


953
00:43:16,366 --> 00:43:19,036
And as - and as a
byproduct of that,


954
00:43:19,086 --> 00:43:21,386
you can actually port these
general kernels back and forth


955
00:43:21,386 --> 00:43:23,576
between the two platforms
with very little effort.


956
00:43:24,406 --> 00:43:26,756
And in fact some of the
new - new built-in filters


957
00:43:26,756 --> 00:43:28,546
that David mentioned
earlier were actually ported


958
00:43:28,546 --> 00:43:30,376
over to iOS using
general kernels,


959
00:43:31,116 --> 00:43:32,876
namely the glass
distortion filter


960
00:43:33,576 --> 00:43:35,276
and the histogram
display filter.


961
00:43:35,986 --> 00:43:37,776
So with the great flexibility


962
00:43:37,776 --> 00:43:40,476
that general kernels offer
you there are some performance


963
00:43:40,476 --> 00:43:42,546
and memory considerations
to keep in mind.


964
00:43:43,586 --> 00:43:46,496
With respect to performance, one
thing you should be aware of is


965
00:43:47,136 --> 00:43:50,506
in order to get, pass sampler
objects to your general kernel,


966
00:43:50,826 --> 00:43:53,306
we have to render
out each input image


967
00:43:53,306 --> 00:43:54,646
to an intermediate buffer first.


968
00:43:55,086 --> 00:43:57,356
And so effectively
each input image


969
00:43:57,356 --> 00:44:00,216
to your CIKernel adds
an extra render pass


970
00:44:00,246 --> 00:44:01,066
to your filter graph.


971
00:44:01,376 --> 00:44:03,366
And because we need to render


972
00:44:03,366 --> 00:44:04,906
out intermediate
buffers you may need


973
00:44:04,906 --> 00:44:06,946
to decide what format
is most appropriate


974
00:44:06,946 --> 00:44:08,056
for a given situation.


975
00:44:08,536 --> 00:44:11,206
In the case of your
working space being null,


976
00:44:11,206 --> 00:44:12,876
i.e. your color management
is off,


977
00:44:13,666 --> 00:44:17,536
you can just safely use
the 8-bit RGBA format


978
00:44:17,536 --> 00:44:20,256
without worrying about any
quantization errors being


979
00:44:20,256 --> 00:44:22,056
introduced in your
image pipeline.


980
00:44:22,056 --> 00:44:25,266
But in the case of your
working space being the default


981
00:44:25,266 --> 00:44:25,736
within your Rec.


982
00:44:25,736 --> 00:44:29,316
709 you can use the
default 8-bit format,


983
00:44:30,276 --> 00:44:32,806
but that would require
a conversion from linear


984
00:44:32,806 --> 00:44:35,646
to sRGB space when writing
out the intermediate buffer,


985
00:44:35,946 --> 00:44:38,346
and vice versa when reading back
from the intermediate buffer.


986
00:44:39,356 --> 00:44:42,356
Alternatively, and this is
new in iOS 8, is the ability


987
00:44:42,356 --> 00:44:46,236
to specify a 16-bit half-flow
format, and so you can do that


988
00:44:46,236 --> 00:44:49,556
and not - and avoid having it
incur the cost of a conversion


989
00:44:49,556 --> 00:44:50,576
at every single pixel,


990
00:44:51,026 --> 00:44:52,546
but it would require twice
the amount of memory.


991
00:44:52,716 --> 00:44:54,526
So the right choice
will ultimately depend


992
00:44:54,526 --> 00:44:58,026
on what your requirements are.


993
00:44:58,236 --> 00:45:02,236
Now with these considerations in
mind you should be careful not


994
00:45:02,236 --> 00:45:05,916
to think that every type of
filter needs to be implemented


995
00:45:05,956 --> 00:45:08,136
with the general kernel,
even if it's a complex one.


996
00:45:09,396 --> 00:45:14,566
Consider, for example, a square
kaleidoscope filter which,


997
00:45:14,566 --> 00:45:16,826
by the way, is very similar
to the kaleidoscope filter


998
00:45:16,826 --> 00:45:18,196
on the photo booth, but instead


999
00:45:18,196 --> 00:45:20,766
of repeating triangles we
just have repeating squares


1000
00:45:21,556 --> 00:45:22,776
and - like so.


1001
00:45:23,436 --> 00:45:25,376
So at first glance
you might think


1002
00:45:25,376 --> 00:45:27,696
that this filter would
need a general kernel


1003
00:45:28,136 --> 00:45:30,886
because it contains both
a geometric transformation


1004
00:45:31,436 --> 00:45:33,746
that warps the space that
you're sampling from as well


1005
00:45:33,746 --> 00:45:38,086
as a color kernel - as
well as a color falloff.


1006
00:45:38,516 --> 00:45:40,496
And so you cannot
represent this kernel


1007
00:45:40,496 --> 00:45:42,526
with either a warp
or a color kernel.


1008
00:45:43,776 --> 00:45:46,706
So you can use a general kernel,
which is fine, but we'll see


1009
00:45:46,706 --> 00:45:48,536
in this case that you
actually don't have to.


1010
00:45:49,506 --> 00:45:51,746
Let's see if there's a
better way to implement this.


1011
00:45:53,236 --> 00:45:55,946
If you were to break down
this filter into stages,


1012
00:45:55,946 --> 00:45:59,456
you will notice that the first
stage is just the geometric


1013
00:45:59,456 --> 00:46:03,136
transformation for which you
can just apply a warp kernel.


1014
00:46:03,756 --> 00:46:07,646
And then the second stage is
the color falloff or attenuation


1015
00:46:07,646 --> 00:46:11,316
from the center, and for that
you can apply a color kernel.


1016
00:46:11,886 --> 00:46:14,876
And so in this example
you can see


1017
00:46:14,876 --> 00:46:17,136
that you can just chain together
a warp and a color kernel


1018
00:46:17,496 --> 00:46:18,806
and achieve - and
get the same effect.


1019
00:46:18,806 --> 00:46:22,266
And this is actually the better
way to implement this filter


1020
00:46:22,556 --> 00:46:24,346
for some of the reasons -
for some of the advantages


1021
00:46:24,346 --> 00:46:28,576
that we heard earlier with using
these specialized kernel types.


1022
00:46:30,276 --> 00:46:33,596
So here are the - here
is the kernel code -


1023
00:46:33,596 --> 00:46:34,856
kernel function for
the warp kernel.


1024
00:46:34,856 --> 00:46:37,226
But in - in the interest of
time we're not - I'm not going


1025
00:46:37,226 --> 00:46:39,156
to bother walking through
all the math that's involved


1026
00:46:39,156 --> 00:46:39,426
in this.


1027
00:46:39,846 --> 00:46:42,186
But I recommend that you
review this on your own later,


1028
00:46:42,436 --> 00:46:44,696
or even copy and paste it
into your own custom filter


1029
00:46:44,696 --> 00:46:46,986
to convince yourself that
it all works correctly.


1030
00:46:48,556 --> 00:46:51,486
Similarly, this is the kernel
function for the color kernel


1031
00:46:51,906 --> 00:46:53,516
which you can review
at your leisure.


1032
00:46:53,956 --> 00:46:56,276
But assuming we have the two
kernel functions already written


1033
00:46:56,276 --> 00:46:57,426
let's actually take a look


1034
00:46:57,426 --> 00:46:58,846
at how you would put
them all together.


1035
00:47:00,576 --> 00:47:03,066
So you start with your input
image, and the first thing is


1036
00:47:03,066 --> 00:47:04,156
to apply the warp kernel.


1037
00:47:04,286 --> 00:47:08,186
And if you were to run
that for all the pixels,


1038
00:47:08,186 --> 00:47:09,596
you would get your
intermediate image,


1039
00:47:09,746 --> 00:47:11,446
which just has the
geometric transformation.


1040
00:47:12,136 --> 00:47:14,516
And for this example the DOD


1041
00:47:14,516 --> 00:47:16,786
for this filter is
actually an infinite rect


1042
00:47:16,786 --> 00:47:19,426
because the repeating
squares extend


1043
00:47:19,426 --> 00:47:20,986
out indefinitely
in all directions.


1044
00:47:22,196 --> 00:47:25,546
In the ROI callback function for
this is actually very simple.


1045
00:47:25,546 --> 00:47:28,066
It's just a constant
rect that is defined


1046
00:47:28,066 --> 00:47:33,006
by this little orange
rectangle in the input image,


1047
00:47:33,786 --> 00:47:35,876
and that's because all
the pixels that need


1048
00:47:35,876 --> 00:47:37,396
to be rendered just
needs to sample


1049
00:47:37,396 --> 00:47:38,726
from that small little region.


1050
00:47:39,526 --> 00:47:43,976
And then the next step is
to apply your color kernel,


1051
00:47:45,026 --> 00:47:47,556
passing in as input the
result from your warp kernel,


1052
00:47:49,036 --> 00:47:50,716
and the result that
you get after applying


1053
00:47:50,716 --> 00:47:52,746
that is the final
result that you want.


1054
00:47:52,796 --> 00:47:55,406
And again, the DOD for your
final result is infinite


1055
00:47:55,476 --> 00:47:58,076
because the warp kernel
image was also infinite.


1056
00:47:58,546 --> 00:48:03,566
So the key takeaway from all
this is you should only write a


1057
00:48:03,566 --> 00:48:06,716
general kernel when needed,
namely the the scenarios we saw


1058
00:48:06,716 --> 00:48:08,126
with the motion blur examples.


1059
00:48:09,226 --> 00:48:12,496
But if you're not sure, you
can also write a general kernel


1060
00:48:12,496 --> 00:48:14,106
initially for rapid prototyping,


1061
00:48:14,476 --> 00:48:15,646
but then you should
try replacing it


1062
00:48:15,646 --> 00:48:18,556
with some combination of warp
and color kernels to get the -


1063
00:48:18,876 --> 00:48:20,096
for the sake of better
performance


1064
00:48:20,096 --> 00:48:21,366
and lower memory usage.


1065
00:48:21,836 --> 00:48:24,576
And with that I'm going to
hand it back over to Alex just


1066
00:48:24,576 --> 00:48:26,406
to say a few more words
before we wrap up.


1067
00:48:26,706 --> 00:48:26,956
Thank you.


1068
00:48:27,516 --> 00:48:32,166
[ Applause ]


1069
00:48:32,666 --> 00:48:33,106
>> Thank you, Tony.


1070
00:48:34,166 --> 00:48:38,506
Okay, so let's quickly talk
about platform differences.


1071
00:48:38,946 --> 00:48:40,326
I have some good news.


1072
00:48:40,746 --> 00:48:43,826
There is only one slide about
the platform differences.


1073
00:48:43,826 --> 00:48:45,806
They actually aren't
that dramatic.


1074
00:48:46,276 --> 00:48:47,796
There are some slight
differences, for example,


1075
00:48:47,796 --> 00:48:49,306
what type of renderers
are supported,


1076
00:48:49,666 --> 00:48:54,656
also the kernel language
on iOS allows control flow,


1077
00:48:54,656 --> 00:48:57,326
so you can express
more complicated things


1078
00:48:57,326 --> 00:48:58,046
in the language.


1079
00:48:58,546 --> 00:49:03,776
We have three kinds of classes
to do kernels on iOS whereas


1080
00:49:03,776 --> 00:49:05,566
on OS X we have just one.


1081
00:49:06,776 --> 00:49:09,426
You cannot specify
a sampler mode


1082
00:49:10,266 --> 00:49:12,096
on iOS, but you can on OS X.


1083
00:49:12,366 --> 00:49:13,326
Filter shape is different.


1084
00:49:13,326 --> 00:49:18,516
It's only a rectangle on iOS
versus a filter shape on OS X.


1085
00:49:19,416 --> 00:49:23,366
The ROI function on iOS is
done via a block pointer,


1086
00:49:23,696 --> 00:49:30,286
whereas on OS X it's done as
a selector from the filter.


1087
00:49:30,286 --> 00:49:33,496
And then there is some
tiny, tiny differences.


1088
00:49:33,496 --> 00:49:37,846
CIFilter setDefaults gets
called automatically on iOS,


1089
00:49:38,286 --> 00:49:40,956
whereas on OS X you need to do
that explicitly on your own.


1090
00:49:41,056 --> 00:49:43,196
And then finally,


1091
00:49:43,606 --> 00:49:47,356
the customAttributes method
is a class method on iOS


1092
00:49:47,706 --> 00:49:51,326
and is an instant method
- instance method on OS X.


1093
00:49:51,916 --> 00:49:54,426
So let's talk about what
we've learned today.


1094
00:49:55,596 --> 00:50:00,236
First things first, we learned
how to write color, warp,


1095
00:50:00,236 --> 00:50:03,706
and general purpose kernels.


1096
00:50:04,166 --> 00:50:07,536
We went through a number of
examples that showed you how


1097
00:50:07,536 --> 00:50:09,816
to start thinking about what
a domain of definition is


1098
00:50:09,866 --> 00:50:11,626
for your kernel,
and then also how


1099
00:50:11,626 --> 00:50:13,386
to write a region of
interest function.


1100
00:50:13,976 --> 00:50:16,586
And what's great about the
way we've implemented things


1101
00:50:16,586 --> 00:50:19,936
on iOS is that you - we
are going to force you


1102
00:50:19,936 --> 00:50:22,546
to write an ROI function
when you have to,


1103
00:50:23,106 --> 00:50:26,466
so it's not something that you
can accidentally forget to do.


1104
00:50:26,816 --> 00:50:28,896
So we think that's a great plus.


1105
00:50:28,956 --> 00:50:31,936
On the ROI function, one thing
I would really like for you


1106
00:50:31,936 --> 00:50:34,796
to remember is that it is really
important for you to do this


1107
00:50:34,796 --> 00:50:36,806
if you want to get good
performance when dealing


1108
00:50:36,806 --> 00:50:38,026
with very large images.


1109
00:50:38,606 --> 00:50:42,046
And then finally we talked


1110
00:50:42,046 --> 00:50:49,366
about platform differences very
briefly in between iOS and OS X.


1111
00:50:49,416 --> 00:50:52,486
So on that note I would
like to invite you all to -


1112
00:50:52,816 --> 00:50:55,026
if you have any additional
questions you can email


1113
00:50:55,026 --> 00:50:55,666
Allan Schaffer.


1114
00:50:56,256 --> 00:51:02,396
We have some resources at DTS,
and there's also the dev forums,


1115
00:51:02,396 --> 00:51:04,306
which we all look at to see


1116
00:51:04,306 --> 00:51:06,546
if anyone have questions
with Core Image.


1117
00:51:07,316 --> 00:51:09,216
There are a few additional
sessions which may be


1118
00:51:09,216 --> 00:51:12,466
of interest to you if you're
interested in writing kernels


1119
00:51:12,466 --> 00:51:15,166
of your own, including the
"Introducing Photo Frameworks"


1120
00:51:15,966 --> 00:51:20,616
which took place earlier today,
and David's talk from earlier


1121
00:51:21,126 --> 00:51:23,546
that took place just right here.


1122
00:51:24,636 --> 00:51:25,996
We're really looking forward


1123
00:51:25,996 --> 00:51:28,256
to seeing all the
effects you are going


1124
00:51:28,256 --> 00:51:30,686
to create using custom kernels,


1125
00:51:30,686 --> 00:51:33,256
and hope you enjoy
using them on iOS 8.


1126
00:51:33,626 --> 00:51:34,296
Thank you very much.


1127
00:51:34,296 --> 00:51:35,796
Once again, I hope you enjoy
the rest of the conference.


1128
00:51:36,428 --> 00:51:38,428
[ Applause ]

