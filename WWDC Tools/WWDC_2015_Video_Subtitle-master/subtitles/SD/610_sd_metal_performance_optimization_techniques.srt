1
00:00:25,516 --> 00:00:31,016
[ Applause ]


2
00:00:31,516 --> 00:00:32,536
>> PHILIP BENNETT: Good morning,


3
00:00:32,536 --> 00:00:36,176
and welcome to Metal Performance
Optimization Techniques.


4
00:00:36,526 --> 00:00:39,446
I'm Phil Bennett of the GPU
Software Performance Group,


5
00:00:39,936 --> 00:00:42,936
and I will be joined shortly by
our special guest Serhat Tekin


6
00:00:43,016 --> 00:00:46,916
from the GPU Software
Developer Technologies Group


7
00:00:46,916 --> 00:00:50,876
and he will be giving a demo
of a great new tool you can use


8
00:00:50,876 --> 00:00:52,126
to profile your Metal apps.


9
00:00:52,126 --> 00:00:54,606
I'm sure you're going
to love it.


10
00:00:54,996 --> 00:00:58,616
So, Metal at the WWDC,
the story so far.


11
00:00:59,196 --> 00:01:03,136
In What's New in Metal Part 1,
we covered great new features


12
00:01:03,226 --> 00:01:10,186
that have been added to Metal
as of iOS 9 and OS X El Capitan.


13
00:01:10,286 --> 00:01:11,816
In What's New in Metal Part 2,


14
00:01:11,906 --> 00:01:14,526
we introduced two new
frameworks, MetalKit


15
00:01:15,036 --> 00:01:16,506
and Metal performance shaders.


16
00:01:16,866 --> 00:01:19,296
These make developing
Metal apps even easier.


17
00:01:20,506 --> 00:01:22,396
In this our final session,


18
00:01:22,546 --> 00:01:26,706
we will be reviewing what tools
are available for debugging


19
00:01:26,706 --> 00:01:29,196
and profiling your Metal
apps and we're going


20
00:01:29,196 --> 00:01:30,746
to explore some best practices


21
00:01:30,746 --> 00:01:34,416
from getting optimal performance
from your Metal apps.


22
00:01:35,276 --> 00:01:37,136
So let's take a look
at the tools.


23
00:01:38,986 --> 00:01:42,906
Now, if you have been doing any
Metal app development in iOS,


24
00:01:42,966 --> 00:01:45,836
you are likely to be
familiar with Xcode


25
00:01:45,836 --> 00:01:47,586
and its suite of Metal tools.


26
00:01:48,226 --> 00:01:52,796
Now, we are going
to take a quick look


27
00:01:52,796 --> 00:01:54,056
at the frame debugger.


28
00:01:55,686 --> 00:01:58,596
So what we have here is a
capture of a single frame


29
00:01:58,596 --> 00:02:01,686
from a Metal app,
and on the left,


30
00:02:02,106 --> 00:02:06,206
we have the frame navigator
which shows all of the states


31
00:02:06,206 --> 00:02:08,506
and Draw calls present
in the frame.


32
00:02:08,925 --> 00:02:13,816
These are grouped by render
encoder, command buffer,


33
00:02:13,816 --> 00:02:16,096
and if you have been
using debug labels,


34
00:02:16,096 --> 00:02:19,526
they will be grouped
by debug groups also.


35
00:02:21,406 --> 00:02:24,016
Next we have the render
attachment viewer,


36
00:02:24,086 --> 00:02:27,836
which shows all of the
color attachments associated


37
00:02:27,836 --> 00:02:30,206
with the current render pass
in addition to any depth


38
00:02:30,256 --> 00:02:34,656
and stencil attachments, and it
shows this wire frame highlight


39
00:02:34,696 --> 00:02:35,766
of the current Draw call,


40
00:02:36,066 --> 00:02:38,536
which makes navigating
your frame very convenient.


41
00:02:40,106 --> 00:02:43,456
Next we have the
resource inspector


42
00:02:43,916 --> 00:02:46,836
where you can inspect all of
the resources used by your app,


43
00:02:48,406 --> 00:02:53,106
from buffers to textures
and render attachments.


44
00:02:53,106 --> 00:02:55,676
You can view all
different formats,


45
00:02:55,676 --> 00:02:59,066
you can individual
bitmap levels, cube maps,


46
00:02:59,436 --> 00:03:01,986
TD arrays, it's fully featured.


47
00:03:02,626 --> 00:03:06,586
And then we have the state
inspector, which allows you


48
00:03:06,586 --> 00:03:10,396
to inspect properties of all of
the Metal objects in your app.


49
00:03:11,826 --> 00:03:14,586
Moving on, we have
the GPU report,


50
00:03:15,096 --> 00:03:17,026
which gives you a frames
per second measurement


51
00:03:17,026 --> 00:03:21,766
of the current frame and gives
you timings for CPU and GPU.


52
00:03:22,006 --> 00:03:27,266
In addition, it also shows
the most expensive render


53
00:03:27,266 --> 00:03:30,456
and compute encoders in your
frame so you can help narrow


54
00:03:30,456 --> 00:03:33,746
down which shaders and
which Draw calls are the


55
00:03:33,746 --> 00:03:34,536
most expensive.


56
00:03:36,676 --> 00:03:40,676
And finally, we have the
shader profiler and editor.


57
00:03:41,236 --> 00:03:44,456
And this is a wonderful
tool for both debugging


58
00:03:44,456 --> 00:03:48,156
and profiling your shaders as it
allows you to tweak your shaders


59
00:03:48,326 --> 00:03:51,426
and recompile them on the
fly, thus saving you having


60
00:03:51,526 --> 00:03:52,816
to recompile your app.


61
00:03:53,336 --> 00:03:54,436
It's really useful.


62
00:03:56,286 --> 00:03:58,206
And as you probably
are aware now,


63
00:03:58,266 --> 00:04:00,566
all of these great
tools are now available


64
00:04:00,566 --> 00:04:05,606
for debugging your Metal
apps on OS X El Capitan.


65
00:04:05,716 --> 00:04:09,276
So Instruments is a
great companion to Xcode


66
00:04:09,326 --> 00:04:11,936
as it allows you to profile
your app's performance


67
00:04:12,316 --> 00:04:16,005
across the entire system,
and now we are enabling you


68
00:04:16,005 --> 00:04:20,426
to profile Metal performance
in a similar manner with this,


69
00:04:20,426 --> 00:04:22,886
the Metal System
Trace Instruments.


70
00:04:23,396 --> 00:04:25,956
It's a brand-new tool for iOS 9.


71
00:04:26,466 --> 00:04:28,376
It allows you to
profile your Metal apps


72
00:04:28,636 --> 00:04:30,346
across your CPU and GPU.


73
00:04:30,346 --> 00:04:31,436
Let's take a look here.


74
00:04:32,236 --> 00:04:37,376
We can start by profiling Metal
API usage in the application,


75
00:04:38,686 --> 00:04:42,156
down to the driver,
right onto the GPU


76
00:04:42,156 --> 00:04:45,046
where we can see the
individual processing phases,


77
00:04:45,046 --> 00:04:47,596
verse X fragments, and
optionally computes,


78
00:04:48,346 --> 00:04:50,306
and then onto the
actual display hardware.


79
00:04:51,066 --> 00:04:54,176
Now, here to give
us a demonstration


80
00:04:54,176 --> 00:04:55,176
of this great new tool,


81
00:04:55,176 --> 00:04:58,026
please welcome Serhat
Tekin to the stage.


82
00:04:59,016 --> 00:05:03,236
[ Applause ]


83
00:05:03,736 --> 00:05:05,586
>> SERHAT TEKIN: Thank you,
Philip, and hello, everyone.


84
00:05:06,606 --> 00:05:08,916
I have something really
cool to show you today,


85
00:05:08,916 --> 00:05:11,666
and it's brand new,
it's our latest addition


86
00:05:11,666 --> 00:05:15,616
to our Metal development
tools, Metal System Trace.


87
00:05:16,656 --> 00:05:19,356
Metal System Trace is
a performance analysis


88
00:05:19,356 --> 00:05:24,086
and tracing tool for your
Metal iOS apps and is available


89
00:05:24,086 --> 00:05:25,096
as part of Instruments.


90
00:05:26,056 --> 00:05:29,286
It lets you get a system-wide
overview of your application


91
00:05:29,326 --> 00:05:35,636
over time also giving you an
in-depth look at the graphics


92
00:05:35,636 --> 00:05:37,406
down to the microsecond level.


93
00:05:37,406 --> 00:05:39,226
It's important that
I should stress this.


94
00:05:40,396 --> 00:05:43,236
This is available for the first
time ever on our platform.


95
00:05:43,456 --> 00:05:46,836
This is all thanks
to Xcode 7 and iOS 9.


96
00:05:47,486 --> 00:05:50,696
So without further ado, let's
go ahead and give it a shot.


97
00:05:52,266 --> 00:05:55,206
So I'm going to launch
Instruments,


98
00:05:55,546 --> 00:05:57,476
and we are at the
template chooser.


99
00:05:58,426 --> 00:06:01,556
You can notice that we have
a new template icon here,


100
00:06:01,556 --> 00:06:03,296
Metal icon for Metal
System Trace.


101
00:06:03,296 --> 00:06:06,246
I will go ahead and choose that.


102
00:06:06,446 --> 00:06:08,026
Those of you familiar


103
00:06:08,026 --> 00:06:11,676
with Instruments will realize
I just created a new document


104
00:06:11,736 --> 00:06:15,486
with four instruments
in it, as you can see


105
00:06:15,486 --> 00:06:16,986
on the left-hand side
of the timeline here.


106
00:06:18,036 --> 00:06:20,806
I will give you a quick tour of
these instruments and the data


107
00:06:20,806 --> 00:06:22,236
that they present
on the timeline.


108
00:06:22,236 --> 00:06:26,626
So let's go ahead and select
my Metal app on the iPad


109
00:06:26,626 --> 00:06:32,116
as my target app
and start recording.


110
00:06:33,176 --> 00:06:33,946
All right.


111
00:06:34,726 --> 00:06:37,256
Now, Metal System
Trace is set to record


112
00:06:37,256 --> 00:06:39,636
in one instrument
called Windowed Mode.


113
00:06:39,896 --> 00:06:43,036
It's essentially capturing
the trace into a ring buffer.


114
00:06:43,036 --> 00:06:45,436
This lets you record
indefinitely.


115
00:06:45,536 --> 00:06:50,366
And the important point here
is that when you see a problem


116
00:06:50,366 --> 00:06:52,566
that you want to investigate,
you can stop recording.


117
00:06:53,296 --> 00:06:55,886
At that point, Instruments
will gather all


118
00:06:55,886 --> 00:06:58,736
of the trace data collected,
process it for a while,


119
00:06:58,736 --> 00:07:00,946
and they will end up with a
timeline that looks like this.


120
00:07:01,016 --> 00:07:04,736
So there is quite a lot of stuff
going on here, so I will zoom


121
00:07:04,736 --> 00:07:05,806
in to get a better look.


122
00:07:06,876 --> 00:07:09,146
I can do that by holding
down the Option key


123
00:07:09,836 --> 00:07:12,556
and selecting an area of
interest in the timeline


124
00:07:12,556 --> 00:07:13,456
that I want to zoom in.


125
00:07:14,486 --> 00:07:17,526
I can navigate the timeline
using the tracker gestures,


126
00:07:17,886 --> 00:07:22,436
two fingers swipe to
scroll and pinch to zoom.


127
00:07:23,016 --> 00:07:24,966
And you can see that
I get more detail


128
00:07:24,966 --> 00:07:29,806
on the timeline as
I zoom further in.


129
00:07:30,176 --> 00:07:32,076
So what are we looking at here?


130
00:07:33,076 --> 00:07:36,456
Essentially what we have
here is an in-depth look


131
00:07:36,456 --> 00:07:40,746
of your Metal application's
graphics workload over time


132
00:07:40,746 --> 00:07:43,926
across all of the layers
of the graphics stack.


133
00:07:44,596 --> 00:07:48,636
The different colors that we go


134
00:07:48,636 --> 00:07:53,016
through in the timeline
represent different workloads


135
00:07:53,016 --> 00:07:53,936
for individual frames.


136
00:07:55,036 --> 00:07:57,726
And the tracks themselves
are fairly intuitive.


137
00:07:58,616 --> 00:08:02,636
Each box you see here represents
an item's trace relative start


138
00:08:02,636 --> 00:08:05,846
time, end time, and
how long it took.


139
00:08:06,406 --> 00:08:09,236
Starting from the top
and working our way down,


140
00:08:09,236 --> 00:08:12,946
we have your application's
usage of the Metal framework.


141
00:08:13,876 --> 00:08:18,266
Next, we have the graphics
driver processing your command


142
00:08:18,266 --> 00:08:21,716
buffers, and if you have any
shader compilation activity


143
00:08:21,716 --> 00:08:25,436
midframe, it also
shows up in the track.


144
00:08:25,436 --> 00:08:28,086
This is followed by
the GPU hardware track,


145
00:08:28,556 --> 00:08:30,466
which shows your Render


146
00:08:30,466 --> 00:08:33,186
and Compute commands
executing on the GPU.


147
00:08:33,706 --> 00:08:37,116
And finally we have the
display surfaces track.


148
00:08:37,116 --> 00:08:40,316
Essentially, this is your frame
getting displayed on the device.


149
00:08:40,476 --> 00:08:42,806
All right.


150
00:08:43,506 --> 00:08:47,266
So another thing you can
see here is these labels.


151
00:08:47,386 --> 00:08:52,276
Now, note that these two labels
here, shadow buffer and G-buffer


152
00:08:52,276 --> 00:08:57,056
and lighting, are labels I
assigned myself to my encoders


153
00:08:57,056 --> 00:09:00,486
in my Metal code using the
encoder's Label property.


154
00:09:01,726 --> 00:09:06,636
These labels propagate their
way down the pipeline along


155
00:09:06,636 --> 00:09:08,456
with the workload they
are associated with,


156
00:09:08,796 --> 00:09:10,296
which makes it very easy


157
00:09:10,296 --> 00:09:12,126
to track your scenes
rendering passes here


158
00:09:12,126 --> 00:09:13,156
in Metal System Trace.


159
00:09:13,156 --> 00:09:15,136
I highly recommend
taking advantage of this.


160
00:09:15,916 --> 00:09:19,176
And if anything is too
small to fit its label,


161
00:09:20,056 --> 00:09:23,936
you can always go hover over
the ruler and see a tool tip


162
00:09:24,006 --> 00:09:29,856
that displays both the label and
the duration at the same time.


163
00:09:30,066 --> 00:09:36,176
The order of the tracks
here basically map


164
00:09:36,346 --> 00:09:40,096
to the same order your Metal
commands would work their way


165
00:09:40,226 --> 00:09:41,756
down the graphics pipeline.


166
00:09:42,306 --> 00:09:46,486
So let us go ahead and
follow this command buffer


167
00:09:46,916 --> 00:09:47,466
down the pipe.


168
00:09:47,466 --> 00:09:53,886
So at the top track I can
see my application's use


169
00:09:53,926 --> 00:09:56,136
of Metal command
buffers and encoders,


170
00:09:56,966 --> 00:10:00,316
specifically what I see
here is the creation time


171
00:10:00,316 --> 00:10:02,976
and submission time for
both my command buffers


172
00:10:03,046 --> 00:10:04,336
and rendering compute encoders.


173
00:10:05,376 --> 00:10:07,746
At the top I have
my command buffer,


174
00:10:08,296 --> 00:10:14,986
and at the bottom I have my
relevant encoders created


175
00:10:14,986 --> 00:10:17,616
by this command buffer
directly nested underneath.


176
00:10:18,336 --> 00:10:24,116
Now, note this arrow here
at the submission time


177
00:10:24,116 --> 00:10:27,376
of the command buffer
going to the next track.


178
00:10:28,226 --> 00:10:30,156
Dependencies between
different levels


179
00:10:30,156 --> 00:10:32,296
of the pipeline are
represented by these arrows


180
00:10:32,396 --> 00:10:33,826
in Metal System Trace.


181
00:10:34,436 --> 00:10:37,406
So, for instance, when this
command buffer is submitted,


182
00:10:37,876 --> 00:10:40,926
its next stop is going to be
the graphics display driver,


183
00:10:40,926 --> 00:10:44,926
if I can zoom in there
and get a better look.


184
00:10:45,866 --> 00:10:47,776
Look at how much
we are taking here.


185
00:10:47,776 --> 00:10:50,916
It's really, really
fast, and they are still


186
00:10:50,916 --> 00:10:52,856
on the CPU side barely
consuming anything.


187
00:10:54,066 --> 00:11:00,246
Similarly, I can go and follow
the arrows once the encoders are


188
00:11:00,246 --> 00:11:00,986
done processing.


189
00:11:01,146 --> 00:11:04,006
The encoders are going to get
submitted to the GPU track.


190
00:11:05,066 --> 00:11:06,676
Following the arrows
the same way,


191
00:11:07,476 --> 00:11:12,526
I can see my encoders
getting processed on my GPU.


192
00:11:13,546 --> 00:11:17,106
This GPU track is separated
into three different lanes,


193
00:11:17,166 --> 00:11:18,536
one for vertex processing,


194
00:11:18,536 --> 00:11:20,826
one for fragment,
and one for compute.


195
00:11:22,026 --> 00:11:26,506
So, for instance, here I can see
my shadow buffer rendering code


196
00:11:26,506 --> 00:11:29,146
for my shadow buffer pass going


197
00:11:29,146 --> 00:11:31,646
through its vertex
processing phase and moving


198
00:11:31,646 --> 00:11:34,226
on to the fragment phase,
which happens to overlap


199
00:11:34,226 --> 00:11:35,876
with my G-buffer and
lighting phase as well.


200
00:11:36,406 --> 00:11:39,646
Something that is desirable.


201
00:11:39,646 --> 00:11:45,076
A quick note here is that the
vertex fragment also compute


202
00:11:45,666 --> 00:11:51,106
processing costs have more than
just the shader processing time.


203
00:11:51,266 --> 00:11:53,636
For instance, we
are running on iOS,


204
00:11:53,856 --> 00:11:56,216
and it's a tile-based
deferred architecture,


205
00:11:56,626 --> 00:11:59,066
so the vertex processing
cost is going


206
00:11:59,066 --> 00:12:03,436
to include the tiling
cost as well.


207
00:12:03,436 --> 00:12:05,996
It's something to keep in mind.


208
00:12:05,996 --> 00:12:13,346
Finally, once my frame is done
rendering, the surface is going


209
00:12:13,346 --> 00:12:15,486
to end up on the
display, which is shown


210
00:12:15,486 --> 00:12:17,446
in the track at the bottom.


211
00:12:18,776 --> 00:12:22,576
Essentially, it's showing me
what time my frame was swapped


212
00:12:22,576 --> 00:12:24,576
onto the display and how
long it stayed there.


213
00:12:25,616 --> 00:12:28,236
Underneath that, we
have the resync track,


214
00:12:29,276 --> 00:12:32,426
which shows us the
resync intervals separated


215
00:12:32,426 --> 00:12:39,366
by these spikes that correspond
to individual resync events.


216
00:12:39,476 --> 00:12:42,926
Finally, at the bottom,
we have our detail view.


217
00:12:43,906 --> 00:12:44,996
The detail view is similar


218
00:12:44,996 --> 00:12:46,856
to what you would see
in other instruments.


219
00:12:46,856 --> 00:12:49,336
It offers contextual
detail based


220
00:12:49,336 --> 00:12:50,936
on the instrument use selected.


221
00:12:51,516 --> 00:12:52,426
For instance right now,


222
00:12:52,426 --> 00:12:55,046
I have the Metal application
instrument selected,


223
00:12:55,116 --> 00:12:59,006
so I can go ahead and expand
this to see all of my frames


224
00:12:59,466 --> 00:13:01,556
and all of the command
buffers and encoders along


225
00:13:01,556 --> 00:13:02,676
with the hierarchy involved.


226
00:13:03,556 --> 00:13:07,746
This track is useful if you want
to see, say, precise timing.


227
00:13:07,816 --> 00:13:09,156
If I go to the encoder list,


228
00:13:09,606 --> 00:13:11,226
precise creation
submission timings


229
00:13:11,226 --> 00:13:13,096
or what process something
originated from.


230
00:13:13,296 --> 00:13:15,806
It's very useful.


231
00:13:15,996 --> 00:13:21,576
Cool! So this timeline look


232
00:13:22,636 --> 00:13:27,316
at the graphics pipeline is
an incredibly powerful tool.


233
00:13:27,606 --> 00:13:31,446
It's available for the first
time with iOS 9 and Metal.


234
00:13:32,786 --> 00:13:35,586
So how do you use this to
help you solve your problems?


235
00:13:36,056 --> 00:13:37,876
Or how does a problem app look?


236
00:13:37,876 --> 00:13:40,456
Let me go ahead and
open a different trace


237
00:13:40,666 --> 00:13:41,636
to show you that.


238
00:13:42,116 --> 00:13:45,686
In a couple of minutes, Philip
will go into a lot more detail


239
00:13:45,686 --> 00:13:48,446
than I will about
Metal performance


240
00:13:49,316 --> 00:13:52,826
and how you can use this
tool for that purpose.


241
00:13:53,896 --> 00:13:55,976
But I'm going to give
you a quick overview


242
00:13:55,976 --> 00:14:00,426
of the tool's workflow and
a quick couple of tips.


243
00:14:00,696 --> 00:14:03,676
First and foremost, you
need to be concerned


244
00:14:03,676 --> 00:14:05,706
about your CPU and
GPU parallelism.


245
00:14:06,846 --> 00:14:09,296
You can see that this
trace that I opened,


246
00:14:09,576 --> 00:14:11,536
labeled Problem Run
appropriately,


247
00:14:12,286 --> 00:14:15,866
is already sparser than
the last trace we took.


248
00:14:16,286 --> 00:14:18,956
This is because we have
a number of sync points


249
00:14:20,526 --> 00:14:22,466
where the CPU is actually
waiting on the GPU.


250
00:14:22,516 --> 00:14:24,496
You need to make sure
you eliminate these.


251
00:14:26,236 --> 00:14:32,486
Also, another useful thing
to look for is the pattern


252
00:14:32,486 --> 00:14:33,816
that you see on the timeline.


253
00:14:34,326 --> 00:14:37,916
These frames are all part of the
same scene, so they are going


254
00:14:37,916 --> 00:14:39,716
to have really high
temporal locality.


255
00:14:40,466 --> 00:14:42,846
Any divergence you
see might point


256
00:14:42,846 --> 00:14:44,636
at a problem you
should investigate.


257
00:14:45,176 --> 00:14:48,646
Another important thing is
the display surfaces track.


258
00:14:50,106 --> 00:14:55,966
So ideally, if your frame rate
target is 60 frames per second,


259
00:14:56,106 --> 00:14:59,676
these surfaces should
be staying on display


260
00:15:00,596 --> 00:15:02,576
for a single VSync interval.


261
00:15:03,146 --> 00:15:07,466
So we should be seeing
surfaces getting swapped


262
00:15:07,466 --> 00:15:08,656
at every VSync interval.


263
00:15:08,936 --> 00:15:11,476
This particular frame, for
instance, stayed on for three,


264
00:15:11,476 --> 00:15:13,396
so we are running at 20 fps.


265
00:15:16,336 --> 00:15:21,166
Another thing that pretty useful
is the shader compilation track


266
00:15:21,466 --> 00:15:23,976
directly shows you if the
shader compiler is kicking


267
00:15:23,976 --> 00:15:25,896
in at any time during
your trace.


268
00:15:26,616 --> 00:15:27,566
One thing that you want


269
00:15:27,566 --> 00:15:31,326
to particularly avoid
is submitting work


270
00:15:31,326 --> 00:15:34,006
to the shader compiler
midframe because it's going


271
00:15:34,006 --> 00:15:37,396
to waste CPU cycles you
can use on other things.


272
00:15:38,076 --> 00:15:40,806
Phil will explain this in a
couple more minutes in detail.


273
00:15:41,746 --> 00:15:46,946
Finally, you should aim to
profile early and often.


274
00:15:47,826 --> 00:15:51,306
A workflow like this will
help you figure out problems


275
00:15:51,816 --> 00:15:54,406
as they occur and make
it easier to fix them.


276
00:15:54,406 --> 00:15:58,556
And Xcode helps you with that by
offering a profile launch option


277
00:15:58,616 --> 00:15:59,716
for your build products.


278
00:16:00,176 --> 00:16:03,246
It's going to automatically
build a release version


279
00:16:03,246 --> 00:16:05,346
of your app, installed
on the device,


280
00:16:05,346 --> 00:16:08,986
and start an instruments run
with a template of your choice.


281
00:16:10,366 --> 00:16:10,996
All right.


282
00:16:11,086 --> 00:16:13,776
So you have our first look
at Metal System Trace.


283
00:16:15,096 --> 00:16:19,106
Available for all of your
Metal-capable iOS devices


284
00:16:19,106 --> 00:16:19,436
out there.


285
00:16:20,546 --> 00:16:21,346
Please give it a try.


286
00:16:21,346 --> 00:16:24,046
We are looking forward to
your feedback and suggestions.


287
00:16:24,676 --> 00:16:27,606
Now, I will leave the
stage back to Phil,


288
00:16:28,136 --> 00:16:32,816
who will demonstrate a couple
of key Metal performance issues


289
00:16:33,276 --> 00:16:35,486
and how you can use our
tools to identify these.


290
00:16:36,056 --> 00:16:36,336
Thank you.


291
00:16:37,476 --> 00:16:43,196
[ Applause ]


292
00:16:43,696 --> 00:16:44,276
>> PHILIP BENNETT:
Thank you, Serhat,


293
00:16:44,276 --> 00:16:45,526
that was very informative.


294
00:16:46,926 --> 00:16:51,066
Now, we are going to cover the
aforementioned Metal performance


295
00:16:51,186 --> 00:16:56,376
best practices, and we
are going to use the tools


296
00:16:56,376 --> 00:16:58,646
to see how we can diagnose


297
00:16:58,716 --> 00:17:00,966
and hopefully follow
these best practices.


298
00:17:01,386 --> 00:17:06,656
So let me introduce our sample
app, or rather a system trace


299
00:17:06,656 --> 00:17:10,685
of our sample app, and
immediately we can see


300
00:17:10,685 --> 00:17:12,736
that there are several
performance issues.


301
00:17:13,165 --> 00:17:15,376
To begin with, there
is no parallelism


302
00:17:15,376 --> 00:17:17,435
between the CPU and the GPU.


303
00:17:17,976 --> 00:17:21,435
These are incredibly
powerful devices,


304
00:17:21,526 --> 00:17:23,066
and the only way you are going


305
00:17:23,066 --> 00:17:25,086
to obtain the maximum
performance is


306
00:17:25,086 --> 00:17:26,526
by having them run
independently,


307
00:17:26,935 --> 00:17:29,166
whereas here they seem to
be waiting on the other.


308
00:17:30,616 --> 00:17:33,276
So we can see there
is a massive stall


309
00:17:33,276 --> 00:17:35,536
between processing
frames on the CPU.


310
00:17:35,536 --> 00:17:37,756
There is a whopping
22 milliseconds.


311
00:17:37,756 --> 00:17:39,016
We shouldn't have any stalls.


312
00:17:39,326 --> 00:17:40,056
What's going on there?


313
00:17:40,056 --> 00:17:45,646
And if we look at the actual
active period of the CPU,


314
00:17:46,306 --> 00:17:48,566
it exceeds our frame deadline.


315
00:17:48,596 --> 00:17:50,586
We were hoping for
60 frames per second.


316
00:17:50,586 --> 00:17:53,136
So we had to get everything
done within 16 milliseconds.


317
00:17:53,516 --> 00:17:54,506
And we have blown past that.


318
00:17:55,606 --> 00:17:57,986
And things don't look much
better on the GPU side, either.


319
00:17:58,576 --> 00:18:02,626
There is a lengthy stall in
proportion to what is on the CPU


320
00:18:02,626 --> 00:18:05,706
because the CPU has been
spending all its time doing


321
00:18:05,706 --> 00:18:07,896
nothing of note and
hasn't been able to queue


322
00:18:08,076 --> 00:18:09,226
up work for the next frame.


323
00:18:09,926 --> 00:18:15,556
Furthermore, the active GPU
period overshoots the frame


324
00:18:15,556 --> 00:18:19,646
deadline, and we are shooting
for 60 frames per second,


325
00:18:19,646 --> 00:18:21,156
but it looks like we
are only getting 20.


326
00:18:22,696 --> 00:18:24,676
So what can we do about this?


327
00:18:25,776 --> 00:18:28,096
Well, let's go back to basics.


328
00:18:28,536 --> 00:18:32,206
Let's first examine one
of the key principles


329
00:18:32,206 --> 00:18:34,586
of Metal design and performance.


330
00:18:35,786 --> 00:18:39,076
And that's creating
your expensive objects


331
00:18:39,076 --> 00:18:40,156
in state upfront.


332
00:18:44,586 --> 00:18:48,726
Now, in a legacy app, typically
what would happen would be


333
00:18:49,006 --> 00:18:53,436
during content loading, the app
would compile all of its shaders


334
00:18:53,436 --> 00:18:57,476
from source, and that could be
dozens or even hundreds of them,


335
00:18:57,476 --> 00:18:59,926
and this is a rather
time-consuming operation.


336
00:19:01,226 --> 00:19:04,246
Now, this is only half of the
shared accompilation story


337
00:19:04,906 --> 00:19:08,016
because the shaders
themselves need to be compiled


338
00:19:08,016 --> 00:19:13,826
into a GPU pipeline
state in combination


339
00:19:13,826 --> 00:19:15,546
with the various state used.


340
00:19:16,346 --> 00:19:20,156
So what some apps
might attempt to do is


341
00:19:20,156 --> 00:19:22,316
to do something known
as prewarming.


342
00:19:22,316 --> 00:19:26,936
Now, normally the device
compilation would occur


343
00:19:26,936 --> 00:19:30,836
when the shaders and states
were first used in a Draw call.


344
00:19:31,406 --> 00:19:32,446
That's bad news.


345
00:19:32,446 --> 00:19:35,906
Imagine you have a racing game
and suddenly you turn a corner


346
00:19:35,906 --> 00:19:37,966
and it draws in a
lot of new objects


347
00:19:37,966 --> 00:19:39,116
and the frame rate drops.


348
00:19:39,116 --> 00:19:40,046
That's really bad.


349
00:19:40,506 --> 00:19:47,746
So what prewarming does is you
issue a load of W Draw calls


350
00:19:47,746 --> 00:19:50,956
with various combinations of
graphic states and shaders


351
00:19:51,526 --> 00:19:56,226
in the hope that the driver
will compile the relevant GPU


352
00:19:56,226 --> 00:19:57,106
pipeline state.


353
00:19:57,106 --> 00:19:58,756
So when the time comes


354
00:19:58,756 --> 00:20:02,636
to actually draw using this
combination state and shaders,


355
00:20:02,636 --> 00:20:05,756
everything is ready to go and
you don't get a frame rate drop.


356
00:20:06,876 --> 00:20:08,566
Now, in the actual
rendering loop,


357
00:20:08,566 --> 00:20:11,506
there would typically be
your setting of states,


358
00:20:12,096 --> 00:20:13,986
and if you actually
get around to any,


359
00:20:13,986 --> 00:20:16,006
maybe you will do some
Draw calls as well.


360
00:20:17,456 --> 00:20:22,426
So the Metal approach is to
move the expensive stuff ahead


361
00:20:22,426 --> 00:20:22,956
of time.


362
00:20:23,966 --> 00:20:26,906
Shaders can be compiled
from source offline.


363
00:20:27,726 --> 00:20:30,066
That's already saving
a chunk of work.


364
00:20:31,636 --> 00:20:34,796
We move state's definition
ahead of time.


365
00:20:35,006 --> 00:20:37,056
You define your state.


366
00:20:37,426 --> 00:20:40,346
The GPU pipeline
state is compiled


367
00:20:40,346 --> 00:20:42,376
into these state objects.


368
00:20:43,216 --> 00:20:46,596
So when you come to actually do
the Draw calls, there is none


369
00:20:46,596 --> 00:20:50,326
of that device compilation
nonsense, so there is no need


370
00:20:50,326 --> 00:20:51,596
for a shade of warming anymore.


371
00:20:51,736 --> 00:20:52,886
It's a thing of the past.


372
00:20:53,746 --> 00:20:56,906
That leaves the rendering
loop free for Draw calls.


373
00:20:56,906 --> 00:20:58,676
Loads of Draw calls.


374
00:21:00,016 --> 00:21:01,606
So fundamentally,


375
00:21:02,476 --> 00:21:05,896
Metal facilitates
upfront state definition


376
00:21:06,336 --> 00:21:10,556
by decoupling expensive state
validation and compilation


377
00:21:11,046 --> 00:21:13,556
from the Draw commands, thus
allowing you to pull this


378
00:21:13,556 --> 00:21:16,216
out of the rendering loop
and keep the rendering loop


379
00:21:16,216 --> 00:21:17,736
for actual Draw calls.


380
00:21:18,326 --> 00:21:23,626
Now, the expensive-to-create
state is encapsulated


381
00:21:23,676 --> 00:21:27,406
in these immutable state
objects, and the intention is


382
00:21:27,406 --> 00:21:30,546
that you will create these
once and reuse them many times.


383
00:21:31,726 --> 00:21:34,676
Now, getting back
to our sample app,


384
00:21:35,936 --> 00:21:39,616
here we see there is some shader
compilation going on midframe,


385
00:21:39,786 --> 00:21:41,756
and we are wasting about
a millisecond here.


386
00:21:42,636 --> 00:21:43,736
That's no good at all.


387
00:21:43,736 --> 00:21:49,676
And if we look at the
Xcode's frame debugger,


388
00:21:49,676 --> 00:21:53,116
look at all of this
happening in a single frame.


389
00:21:53,116 --> 00:21:55,556
Look at all of these objects.


390
00:21:55,626 --> 00:21:56,886
We don't want any of this.


391
00:21:56,886 --> 00:22:00,546
All that you should be
seeing is this, the creation


392
00:22:00,546 --> 00:22:03,476
of the command buffer for
the frame and the acquisition


393
00:22:03,476 --> 00:22:04,816
of the drawable and its texture.


394
00:22:05,316 --> 00:22:07,536
All of the rest is
completely superfluous.


395
00:22:08,756 --> 00:22:12,526
So let's cover these
expensive objects


396
00:22:12,526 --> 00:22:13,856
and when you should create them.


397
00:22:13,856 --> 00:22:16,296
And we are going to begin
with shader libraries.


398
00:22:17,306 --> 00:22:21,346
These are your library
of compiled shaders.


399
00:22:22,366 --> 00:22:26,056
Now, what you really want to do
is compile all of them offline.


400
00:22:27,036 --> 00:22:31,596
You can use Xcode,
any Metal source files


401
00:22:31,796 --> 00:22:33,936
in your project will
automatically be compiled


402
00:22:34,096 --> 00:22:35,706
into the default library.


403
00:22:36,626 --> 00:22:42,516
Now, your app may have its
own custom content pipeline,


404
00:22:42,806 --> 00:22:45,116
and you might not necessarily
want to use this approach.


405
00:22:45,676 --> 00:22:48,916
So for that, we provide
command-line tools,


406
00:22:48,916 --> 00:22:51,746
which you can integrate
into your pipeline.


407
00:22:52,446 --> 00:22:56,936
If you absolutely cannot
avoid compiling your shaders


408
00:22:56,936 --> 00:23:01,816
from source in runtime, the
best you can do is create


409
00:23:01,816 --> 00:23:02,796
them asynchronously.


410
00:23:03,996 --> 00:23:08,296
So you create the library,
and in the meantime, your app,


411
00:23:08,586 --> 00:23:09,816
or rather, the calling threads,


412
00:23:10,136 --> 00:23:12,826
can get on with doing
something else,


413
00:23:12,926 --> 00:23:16,526
and once the shader
library has been created,


414
00:23:17,006 --> 00:23:18,926
your app will be
asynchronously notified.


415
00:23:19,566 --> 00:23:25,266
Now, one of the first
objects you will be creating


416
00:23:25,266 --> 00:23:27,546
in your app will be the
device and command queue.


417
00:23:28,436 --> 00:23:34,416
And these represent the GPU
you will be using and its queue


418
00:23:34,416 --> 00:23:36,386
of ordered command buffers.


419
00:23:37,856 --> 00:23:40,106
Now, as we said, you want


420
00:23:40,106 --> 00:23:42,366
to create these during
app initialization


421
00:23:42,366 --> 00:23:44,756
and because they are
expensive to create,


422
00:23:44,816 --> 00:23:47,846
you want to reuse them
throughout the lifetime


423
00:23:47,846 --> 00:23:48,276
of your app.


424
00:23:49,466 --> 00:23:52,796
And, of course, you want
to create one per GPU used.


425
00:23:52,876 --> 00:23:57,246
Now, next is the
interesting stuff, the render


426
00:23:57,246 --> 00:24:01,396
and compute pipeline state,
which encapsulates all


427
00:24:01,396 --> 00:24:03,946
of the programmable
GPU pipeline states,


428
00:24:04,336 --> 00:24:09,836
so it takes all the descriptors,
your vertex formatter scripts,


429
00:24:09,836 --> 00:24:11,686
render buffer formats,
and compiles it


430
00:24:11,686 --> 00:24:14,076
down to the actual
raw pipeline state.


431
00:24:15,316 --> 00:24:17,496
Now, as this is an
expensive operation,


432
00:24:17,496 --> 00:24:20,596
you should be creating
these pipeline objects


433
00:24:20,636 --> 00:24:23,116
when you load your
content, and you should aim


434
00:24:23,116 --> 00:24:24,996
to reuse them as
often as you can.


435
00:24:26,546 --> 00:24:28,116
Now, as with the libraries,


436
00:24:28,166 --> 00:24:31,066
you can also create these
asynchronously using


437
00:24:31,066 --> 00:24:31,786
these methods.


438
00:24:32,056 --> 00:24:34,436
So once created, your
app will be notified


439
00:24:34,486 --> 00:24:37,086
by a completion handler.


440
00:24:37,936 --> 00:24:42,396
One point to mention is that
unless you actually need it,


441
00:24:42,996 --> 00:24:44,946
you shouldn't obtain
the reflection data


442
00:24:45,056 --> 00:24:46,926
as this is an expensive
operation.


443
00:24:46,996 --> 00:24:53,106
So next we have the depth
stencil and sampler states.


444
00:24:53,666 --> 00:24:56,766
These are the fixed-function
GPU pipeline states,


445
00:24:57,496 --> 00:25:01,546
and you should be creating these
when you load your content along


446
00:25:01,626 --> 00:25:02,936
with the other pipeline states.


447
00:25:03,786 --> 00:25:09,566
Now, you may end up with many,
many pieces of depth stencil


448
00:25:09,566 --> 00:25:11,936
and sampler states, but you
needn't worry about this


449
00:25:11,936 --> 00:25:15,486
because some Metal
implementations will internally


450
00:25:15,736 --> 00:25:19,216
hash the states and
create loads of duplicates


451
00:25:19,276 --> 00:25:20,146
so don't worry about that.


452
00:25:22,086 --> 00:25:26,026
Now, next we have the actual
data consumed by the GPU.


453
00:25:26,106 --> 00:25:29,756
You have got your
textures and your buffers.


454
00:25:30,496 --> 00:25:33,226
And you should, once
again, be creating these


455
00:25:33,936 --> 00:25:37,756
when you load your content, and
reuse them as often as possible,


456
00:25:37,876 --> 00:25:42,166
because there is an overhead
associated with both allocating


457
00:25:42,166 --> 00:25:44,026
and deallocating
these resources.


458
00:25:45,046 --> 00:25:48,866
And even dynamic resources,
you might not be able


459
00:25:48,866 --> 00:25:51,846
to fully initialize them
ahead of time, but you should


460
00:25:51,846 --> 00:25:54,816
at least create the
underlying storage.


461
00:25:54,816 --> 00:25:57,696
And we are going to be
covering more on that very soon.


462
00:25:58,876 --> 00:26:02,006
So to briefly recap.


463
00:26:02,096 --> 00:26:06,856
So the most expensive states
obviously should be created


464
00:26:06,856 --> 00:26:09,806
ahead of time, so these
are the shader libraries


465
00:26:09,956 --> 00:26:11,966
that you aim to build offline.


466
00:26:12,996 --> 00:26:15,696
The device and the command
queue, which are created


467
00:26:16,166 --> 00:26:19,976
when you initialize
your app, the render


468
00:26:19,976 --> 00:26:21,326
and compute pipeline states,


469
00:26:22,026 --> 00:26:23,466
created when you
load your content,


470
00:26:24,276 --> 00:26:26,806
as are the fixed
function pipeline state,


471
00:26:26,806 --> 00:26:28,726
the depth stencil
and sampler states,


472
00:26:29,976 --> 00:26:32,506
and then finally the
textures and buffers


473
00:26:32,506 --> 00:26:33,446
that are used by your app.


474
00:26:34,736 --> 00:26:38,896
So we went ahead and we
applied this best practice


475
00:26:38,896 --> 00:26:42,546
to our example app, which you
may remember looked like this.


476
00:26:42,746 --> 00:26:46,496
We had some shader compilation
occurring midframe every frame,


477
00:26:47,606 --> 00:26:48,996
and now we have got none.


478
00:26:49,386 --> 00:26:52,726
So already we have saved about
a millisecond of CPU time.


479
00:26:52,916 --> 00:26:55,146
This is a good start,
but we will see


480
00:26:55,146 --> 00:26:56,116
if we can do better soon.


481
00:26:57,086 --> 00:27:02,086
So in summary, create your
expensive state and objects


482
00:27:02,086 --> 00:27:05,846
up front and aim to reuse them.


483
00:27:05,846 --> 00:27:10,756
Expecially compile your shader
source offline, and you want


484
00:27:10,756 --> 00:27:13,106
to keep the rendering loop
for what it's intended for.


485
00:27:13,106 --> 00:27:14,166
It's for Draw calls.


486
00:27:14,696 --> 00:27:16,076
Get rid of all of
the object creation.


487
00:27:16,786 --> 00:27:22,606
Now, what about the resources
you can't entirely create


488
00:27:22,606 --> 00:27:23,016
up front?


489
00:27:23,016 --> 00:27:26,256
We are talking about
these dynamic resources,


490
00:27:26,856 --> 00:27:27,926
so what do we do about them?


491
00:27:27,996 --> 00:27:30,916
How can we efficiently
create and manage them?


492
00:27:32,286 --> 00:27:35,386
Now, by dynamic resources,
we are talking


493
00:27:35,876 --> 00:27:40,186
about resources which, once
created, may be modified many,


494
00:27:40,186 --> 00:27:43,636
many times by the CPU.


495
00:27:44,076 --> 00:27:51,306
And a good example of this
is buffer shader constants,


496
00:27:51,306 --> 00:27:55,646
and also any dynamic vertex and
index buffers you might have


497
00:27:55,856 --> 00:27:58,896
for things like particles
generated on the CPU,


498
00:27:59,816 --> 00:28:02,236
in addition to dynamic textures,


499
00:28:02,266 --> 00:28:05,066
perhaps your app has some
textures which it modifies


500
00:28:05,066 --> 00:28:06,426
in the CPU between frames.


501
00:28:07,656 --> 00:28:09,206
So ideally given the choice,


502
00:28:09,206 --> 00:28:12,856
you would put these resources
somewhere which is efficient


503
00:28:12,856 --> 00:28:15,486
for both the CPU and
the GPU to access.


504
00:28:16,476 --> 00:28:20,366
And you do this with the
shared storage mode option


505
00:28:20,426 --> 00:28:21,606
when you create your resource.


506
00:28:22,196 --> 00:28:25,256
And this creates
resources in memory shared


507
00:28:25,296 --> 00:28:27,306
by both the CPU and the GPU.


508
00:28:27,826 --> 00:28:31,686
Now, this is actually the
default storage mode on iOS,


509
00:28:31,736 --> 00:28:35,856
iOS devices being unified
memory architecture,


510
00:28:35,996 --> 00:28:39,576
so the same memory is shared
between the CPU and GPU.


511
00:28:40,986 --> 00:28:45,946
Now, the thing about these
shared resources is the CPU has


512
00:28:46,076 --> 00:28:48,076
completely unsynchronized
access to them.


513
00:28:48,486 --> 00:28:53,096
It can modify the data as freely
as it wants through a pointer.


514
00:28:53,946 --> 00:28:58,166
And in fact, it's quite easy
for the CPU to stomp all


515
00:28:58,166 --> 00:29:01,136
over the data which
is in use by the GPU,


516
00:29:01,466 --> 00:29:03,276
which tends to be
pretty catastrophic.


517
00:29:03,776 --> 00:29:04,886
So we want to avoid that.


518
00:29:05,756 --> 00:29:07,246
But how can we achieve this?


519
00:29:07,846 --> 00:29:12,306
Well, the brute force approach
would be to have a single buffer


520
00:29:12,306 --> 00:29:16,936
for the resource, where we
have, say, a buffer of constants


521
00:29:16,936 --> 00:29:21,276
which are updated on the CPU
and consumed later by the GPU.


522
00:29:22,506 --> 00:29:26,136
Now, if the CPU wants to
modify any of the data


523
00:29:26,166 --> 00:29:29,566
in the constants
buffer, it has to wait


524
00:29:29,636 --> 00:29:31,446
until the GPU is
finished with it.


525
00:29:31,446 --> 00:29:34,756
And the only way it can
know that is if it waits


526
00:29:34,826 --> 00:29:38,416
for the command buffer in which
the resource is referenced


527
00:29:39,116 --> 00:29:41,006
to finish processing on the GPU.


528
00:29:41,076 --> 00:29:45,436
And for that, in this case
we use Wait Until Completed.


529
00:29:46,096 --> 00:29:49,796
So we wait around, rather
the CPU waits around,


530
00:29:49,826 --> 00:29:51,716
until the GPU is
finished processing


531
00:29:52,176 --> 00:29:54,766
and then it can go ahead
and modify the buffer,


532
00:29:54,766 --> 00:29:57,166
which is consumed by the
GPU in the next frame.


533
00:29:58,186 --> 00:30:02,376
Now, this is really bad because
not only is the CPU stored


534
00:30:02,376 --> 00:30:05,946
but the GPU is stored as well
because the CPU hasn't had time


535
00:30:05,946 --> 00:30:07,436
to queue up work
for the next frame.


536
00:30:08,086 --> 00:30:13,436
This is what is happening
in the example app.


537
00:30:14,616 --> 00:30:20,326
The CPU is waiting around for
the GPU to finish on each frame.


538
00:30:20,506 --> 00:30:24,046
You are introducing a massive
store period, and, yes,


539
00:30:24,186 --> 00:30:27,186
there is no parallelism
between the CPU and the GPU.


540
00:30:28,156 --> 00:30:30,836
So we need a better
approach clearly,


541
00:30:31,736 --> 00:30:35,406
and you might be tempted to just
create new buffers every frame


542
00:30:35,916 --> 00:30:36,706
as you need them.


543
00:30:37,696 --> 00:30:40,476
But as we learned in
the previous section,


544
00:30:40,476 --> 00:30:42,216
that's not a particularly
good idea


545
00:30:42,246 --> 00:30:44,616
because there is an
overhead associated


546
00:30:44,616 --> 00:30:46,066
with creating each buffer.


547
00:30:46,836 --> 00:30:50,226
And if you have many buffers,
large buffers, this will add up,


548
00:30:50,226 --> 00:30:52,146
so you really don't
want to be doing this.


549
00:30:53,076 --> 00:30:57,686
What you should do instead
is employ a buffer scheme.


550
00:30:58,246 --> 00:31:00,426
Here we have a triple
buffering scheme,


551
00:31:01,076 --> 00:31:05,256
where we have three buffers,
which are updated on the CPU


552
00:31:05,256 --> 00:31:06,786
and then consumed by the GPU.


553
00:31:07,436 --> 00:31:08,306
Why three?


554
00:31:08,876 --> 00:31:12,026
Typically we suggest
that you limit the number


555
00:31:12,026 --> 00:31:16,486
of command buffers in flight
to three, and effectively,


556
00:31:16,486 --> 00:31:20,416
you have one buffer
per command buffer.


557
00:31:21,386 --> 00:31:25,806
And by employing a
semaphore to prevent the CPU


558
00:31:25,806 --> 00:31:29,056
from getting too far ahead
of the GPU, we can ensure


559
00:31:29,056 --> 00:31:33,056
that it's safe to update
the buffers on the CPU


560
00:31:33,636 --> 00:31:37,586
when the GPU wraps
around, when it goes back


561
00:31:37,756 --> 00:31:39,056
to reading the first buffer.


562
00:31:40,126 --> 00:31:43,556
Rather than bore you with
a lot of sample code,


563
00:31:43,556 --> 00:31:46,996
I will point you straight at a
great example we already have.


564
00:31:47,516 --> 00:31:49,856
That is the Metal
Uniform Streaming example,


565
00:31:49,966 --> 00:31:52,236
which shows you exactly
how to do this.


566
00:31:53,426 --> 00:31:56,016
So I recommend you check it out
afterward if you are interested.


567
00:31:57,326 --> 00:31:59,736
Getting back to our example app,


568
00:31:59,926 --> 00:32:03,766
you may remember we had these
very performance-crippling


569
00:32:03,766 --> 00:32:06,066
weights between each
frame on the CPU.


570
00:32:07,286 --> 00:32:12,626
Now, after employing a buffering
scheme to update dynamic data,


571
00:32:13,516 --> 00:32:17,246
we managed to greatly reduce
the gap between processing


572
00:32:17,246 --> 00:32:20,136
on both the CPU and the GPU.


573
00:32:20,686 --> 00:32:23,096
We still have some sort
of synchronization issue,


574
00:32:23,096 --> 00:32:25,246
but we are going to look
into that very shortly.


575
00:32:26,536 --> 00:32:28,586
So we are making good
progress already.


576
00:32:29,726 --> 00:32:32,316
And in summary, you
want to buffer


577
00:32:32,316 --> 00:32:34,296
up your dynamic shared resources


578
00:32:34,546 --> 00:32:37,286
because it's the most
efficient way of updating these


579
00:32:37,286 --> 00:32:43,556
between frames, and you enforce
safety via use of the buffers


580
00:32:43,556 --> 00:32:44,876
and flights that I mentioned.


581
00:32:45,466 --> 00:32:50,326
Now, I'm going to
talk about something


582
00:32:50,866 --> 00:32:53,896
or rather the one thing you
don't actually want to do


583
00:32:53,896 --> 00:32:56,516
up front, and that relates


584
00:32:56,516 --> 00:32:59,276
to when you acquire your
app's drawable service.


585
00:33:01,056 --> 00:33:04,626
Now, the drawable surface is
your app's window on the world,


586
00:33:04,696 --> 00:33:08,446
it's what your app renders
its visible content into,


587
00:33:08,766 --> 00:33:12,796
which is either displayed
directly on the display


588
00:33:13,366 --> 00:33:15,806
or it may be part of a
composition pipeline.


589
00:33:16,796 --> 00:33:20,866
Now, you retrieve the
drawables from the Metal layer


590
00:33:20,866 --> 00:33:23,656
of Core Animation, but there
is only a limited number


591
00:33:23,656 --> 00:33:26,046
of these drawables because
they are actually quite big,


592
00:33:26,916 --> 00:33:30,366
and we don't want to keep loads
of them around nor do we want


593
00:33:30,366 --> 00:33:33,186
to be allocating them
whenever we need them.


594
00:33:33,996 --> 00:33:37,366
So these drawables are
maintained very limited,


595
00:33:37,566 --> 00:33:40,666
and predrawables
are relinquished


596
00:33:40,666 --> 00:33:43,626
at display intervals once
they have been displayed


597
00:33:43,916 --> 00:33:44,516
in the hardware.


598
00:33:45,666 --> 00:33:51,126
And each stage of the display
pipeline may actually be holding


599
00:33:51,126 --> 00:33:54,906
onto a drawable at any point
from your app, to a GPU,


600
00:33:54,906 --> 00:33:57,256
to Core Animation if you
have any compositing,


601
00:33:57,786 --> 00:34:01,616
to the actual display hardware.


602
00:34:01,726 --> 00:34:04,946
Now, your app grabs a
drawable surface typically


603
00:34:05,276 --> 00:34:07,126
by calling the next
drawable method.


604
00:34:07,866 --> 00:34:11,565
If you are using MetalKit,
this will be performed


605
00:34:11,646 --> 00:34:14,466
when you call Current
Render Pass Descriptor.


606
00:34:16,085 --> 00:34:20,775
Now, the method will only return
once a drawable is available,


607
00:34:21,505 --> 00:34:24,676
and if there happens to be a
drawable available at the time,


608
00:34:24,726 --> 00:34:26,016
it will return immediately.


609
00:34:26,166 --> 00:34:29,505
Great, you can go on and
continue with the frame.


610
00:34:29,976 --> 00:34:32,216
However, if there are
none available your app,


611
00:34:32,866 --> 00:34:35,356
or rather the calling
for it, will be blocked


612
00:34:35,436 --> 00:34:39,946
until at least the next display
interval waiting for a drawable.


613
00:34:39,946 --> 00:34:41,085
This can be a long time.


614
00:34:41,235 --> 00:34:42,616
It's 60 frames per second.


615
00:34:42,616 --> 00:34:44,616
We are talking 16 milliseconds.


616
00:34:45,666 --> 00:34:48,326
So that's very bad news.


617
00:34:48,596 --> 00:34:52,366
So is this what our
example app was doing?


618
00:34:52,366 --> 00:34:56,966
Is this the explanation for
these huge gaps in execution?


619
00:34:58,086 --> 00:34:59,486
Well, let's see what Xcode says.


620
00:35:00,556 --> 00:35:03,806
So we go to the frame
navigator, and we take a look


621
00:35:04,056 --> 00:35:06,036
at the frame navigator here.


622
00:35:06,086 --> 00:35:08,986
And Xcode seems to
have a problem


623
00:35:08,986 --> 00:35:10,926
with our shadow buffer encoder.


624
00:35:11,716 --> 00:35:13,646
See a little warning there.


625
00:35:14,976 --> 00:35:16,386
So if we take a closer look,


626
00:35:17,416 --> 00:35:20,266
we see that indeed we are
actually calling the next


627
00:35:20,266 --> 00:35:22,606
drawable method earlier
than we should do.


628
00:35:23,246 --> 00:35:25,366
The next code offers
some very sage advice


629
00:35:25,366 --> 00:35:28,556
that we should only call it when
we actually need the drawable.


630
00:35:29,676 --> 00:35:32,556
So how does this fit in
with our example app?


631
00:35:34,176 --> 00:35:38,146
Well, we have several passes
here in our example app,


632
00:35:38,146 --> 00:35:41,406
and we were acquiring the
drawable right at the start


633
00:35:41,406 --> 00:35:44,276
of each frame before
the shadow pass.


634
00:35:44,276 --> 00:35:48,196
This is far too early, because
right up until the last pass,


635
00:35:48,196 --> 00:35:49,846
we are drawing everything
off screen,


636
00:35:50,326 --> 00:35:54,266
and we don't need a drawable
right up until we come


637
00:35:54,406 --> 00:35:56,126
to render the UI pass.


638
00:35:56,676 --> 00:36:01,036
So the best place to acquire the
next drawable is naturally right


639
00:36:01,036 --> 00:36:04,446
before the UI pass.


640
00:36:04,656 --> 00:36:09,686
So we went ahead and we made
the change, we moved our call


641
00:36:09,686 --> 00:36:13,456
to next drawable
later, and let's see


642
00:36:13,456 --> 00:36:14,746
if that solved our problem.


643
00:36:15,196 --> 00:36:17,906
Well, as you can
already see, yes, it did!


644
00:36:18,456 --> 00:36:22,786
We removed our second
synchronization point,


645
00:36:23,416 --> 00:36:26,276
and now we don't have any
stalls between processing


646
00:36:26,276 --> 00:36:29,116
on the frame processing
on the CPU.


647
00:36:29,596 --> 00:36:30,936
That's a massive improvement.


648
00:36:31,466 --> 00:36:36,756
So the advice is very simple:
only acquire the drawable


649
00:36:36,756 --> 00:36:38,136
when you actually need it.


650
00:36:38,866 --> 00:36:41,836
This is before the render pass
in which it's actually used.


651
00:36:42,826 --> 00:36:48,086
This will ensure that
you hide any long latency


652
00:36:48,086 --> 00:36:51,866
that would occur if there
weren't any drawables available.


653
00:36:52,016 --> 00:36:55,296
So your app can continue
to do useful work,


654
00:36:55,296 --> 00:36:58,106
and by the time it
actually needs a drawable,


655
00:36:58,236 --> 00:36:59,536
one is likely to be available.


656
00:37:01,996 --> 00:37:05,256
So at this point we are
doing pretty well so far.


657
00:37:05,256 --> 00:37:07,716
But there is still
room for improvement.


658
00:37:08,476 --> 00:37:11,076
So why don't we look
at the efficiency


659
00:37:11,076 --> 00:37:15,456
of the GPU side rather than
diving to a very low level, say,


660
00:37:15,456 --> 00:37:19,456
trying to optimize our shaders
or change texture formats,


661
00:37:19,616 --> 00:37:20,846
whatever, why don't we see


662
00:37:20,846 --> 00:37:22,796
if there is any general
advice we can apply.


663
00:37:23,916 --> 00:37:25,176
As it so happens, there is.


664
00:37:25,656 --> 00:37:28,776
That relates to how we use
Render Command Encoders.


665
00:37:29,486 --> 00:37:35,816
Now, a Render Command
Encoder is what is used


666
00:37:35,946 --> 00:37:40,306
to generate Draw commands
for a single rendering pass.


667
00:37:40,866 --> 00:37:45,306
And a single rendering pass
operates on a fixed set


668
00:37:45,416 --> 00:37:48,956
of color attachments, and
depth and stencil attachments.


669
00:37:49,336 --> 00:37:52,616
Once you begin the pass, you
cannot change these attachments.


670
00:37:53,066 --> 00:37:56,496
However, you can change
the actions acting on them,


671
00:37:56,756 --> 00:38:01,206
such as the depth stencil
state, color masking


672
00:38:01,206 --> 00:38:02,896
and blending, for instance.


673
00:38:02,896 --> 00:38:05,026
And this is valuable
to remember.


674
00:38:06,966 --> 00:38:12,026
Now, the way in which we use
our render encoders particularly


675
00:38:12,026 --> 00:38:17,776
important on the iOS device
GPUs due to the interesting way


676
00:38:17,776 --> 00:38:20,206
in which they are architected.


677
00:38:20,346 --> 00:38:22,486
They are tile-based
deferred renderers.


678
00:38:23,286 --> 00:38:28,796
So each Render Command Encoder
results in two GPU passes.


679
00:38:29,676 --> 00:38:34,546
First you have the vertex
phase, which transforms all


680
00:38:34,546 --> 00:38:41,236
of the geometry in your encoder,
and then performs clipping,


681
00:38:41,236 --> 00:38:47,826
coloring, and then bins
all of the geometry


682
00:38:47,826 --> 00:38:49,386
into screen space tiles.


683
00:38:50,456 --> 00:38:54,506
This is followed by the fragment
phase, which processes all


684
00:38:54,506 --> 00:38:58,836
of the objects tile
by tile to determine


685
00:38:58,836 --> 00:39:01,586
which objects are visible,


686
00:39:02,006 --> 00:39:05,766
and then only the visible
pixels are actually processed.


687
00:39:07,026 --> 00:39:10,086
And all of the fragment
processing occurs


688
00:39:10,086 --> 00:39:12,426
in these fast on-chip
tile buffers.


689
00:39:13,756 --> 00:39:17,276
Now, typically at the end
of a render you only need


690
00:39:17,276 --> 00:39:19,146
to store out the color buffer.


691
00:39:19,476 --> 00:39:21,346
You would just discard
the depth buffer.


692
00:39:21,906 --> 00:39:26,286
And even sometimes you may have,
say, multiple color attachments,


693
00:39:26,326 --> 00:39:28,746
but you only need to
store one of them.


694
00:39:28,746 --> 00:39:33,766
By not storing the
tile data in each pass,


695
00:39:33,826 --> 00:39:35,666
you are saving quite
a bit of bandwidth.


696
00:39:35,816 --> 00:39:38,076
You are avoiding writing
out entire frame buffers.


697
00:39:38,076 --> 00:39:42,446
This is important for
performance, as is not having


698
00:39:42,446 --> 00:39:44,646
to load in data each tile.


699
00:39:47,406 --> 00:39:50,606
So what can Xcode tell us?


700
00:39:50,706 --> 00:39:53,476
Can it give us -- or rather,


701
00:39:55,826 --> 00:40:01,096
I mentioned that each
encoder corresponds


702
00:40:01,226 --> 00:40:04,476
to a vertex pass
and a fragment pass.


703
00:40:05,076 --> 00:40:08,486
And this applies
even for MT encoders,


704
00:40:08,486 --> 00:40:09,816
and this is quite important.


705
00:40:10,766 --> 00:40:13,656
Here we have actually
two G-buffer encoders,


706
00:40:13,656 --> 00:40:16,626
and the first one doesn't
seem to be drawing anything.


707
00:40:17,356 --> 00:40:19,256
I guess that just slipped
in there by mistake,


708
00:40:19,986 --> 00:40:25,106
but this actually has quite an
impact on performance if we look


709
00:40:25,106 --> 00:40:26,626
at the system trace of the app.


710
00:40:27,966 --> 00:40:33,266
Just that empty encoder consumed
2.8 milliseconds on the GPU,


711
00:40:33,996 --> 00:40:38,856
and presumably it was
just writing a clear color


712
00:40:38,856 --> 00:40:42,886
out to however many
attachments we had, three color


713
00:40:42,886 --> 00:40:47,026
and two depth and stencil.


714
00:40:47,646 --> 00:40:50,606
And our total GPU
processing time


715
00:40:50,606 --> 00:40:52,886
for this particular
frame is 22 milliseconds.


716
00:40:53,486 --> 00:40:57,036
Now, if we remove
the MT encoder,


717
00:40:57,036 --> 00:40:59,466
which is done very easily
because it shouldn't be there


718
00:40:59,466 --> 00:41:05,386
in the first place, we go down
to 19, so that's a very nice win


719
00:41:05,386 --> 00:41:06,816
for doing very little at all.


720
00:41:07,176 --> 00:41:09,526
So watch out for
these MT encoders.


721
00:41:09,526 --> 00:41:11,286
If you are not going
to do any drawing


722
00:41:11,286 --> 00:41:14,236
in a pass, don't start encoding.


723
00:41:14,926 --> 00:41:19,656
So let's look a bit deeper now.


724
00:41:19,746 --> 00:41:22,786
Let's have a look at the render
passes in our example app


725
00:41:22,916 --> 00:41:23,906
and see what we have got.


726
00:41:25,496 --> 00:41:27,126
So we have got a shadow pass,


727
00:41:27,456 --> 00:41:30,076
which renders into
a depth buffer.


728
00:41:31,006 --> 00:41:32,696
We have a G-buffer
pass, which renders


729
00:41:32,696 --> 00:41:36,516
into three color attachments and
a depth and stencil attachment,


730
00:41:37,456 --> 00:41:40,186
and then we have these
three lighting passes,


731
00:41:40,236 --> 00:41:45,536
which use the render attachment
data from the G-buffer pass,


732
00:41:45,536 --> 00:41:48,086
either sampling through the
texture units or loading


733
00:41:49,046 --> 00:41:53,346
to the frame buffer content.


734
00:41:53,346 --> 00:41:55,976
And when the lighting
passes use this data,


735
00:41:55,976 --> 00:41:59,856
and they perform
lighting and outputs


736
00:42:00,146 --> 00:42:02,866
to a single accumulation target


737
00:42:02,866 --> 00:42:04,146
which is used several
times over.


738
00:42:04,866 --> 00:42:07,476
And finally you have
a user interface pass


739
00:42:07,476 --> 00:42:10,536
onto which user interface
elements are drawn


740
00:42:11,096 --> 00:42:12,496
and presented to the screen.


741
00:42:13,956 --> 00:42:18,086
So is this the most
efficient setup of encoders?


742
00:42:18,886 --> 00:42:22,956
Once again we summon
Xcode's frame debugger to see


743
00:42:22,956 --> 00:42:23,916
if it has anything to say.


744
00:42:23,916 --> 00:42:26,706
And once again, yes it does.


745
00:42:26,886 --> 00:42:29,526
It has taken issue with
our sunlight encoder.


746
00:42:30,456 --> 00:42:31,506
So let's take a closer look.


747
00:42:31,506 --> 00:42:35,536
We are inefficiently using
our command encoders.


748
00:42:36,856 --> 00:42:38,976
And Xcode is kind
enough to tell us


749
00:42:38,976 --> 00:42:41,866
which ones we could
actually combine.


750
00:42:43,576 --> 00:42:47,666
So let's go ahead and
merge a couple of passes.


751
00:42:48,166 --> 00:42:51,436
Rather than merge just two,
we can actually merge three,


752
00:42:51,436 --> 00:42:54,126
which all operate on the
same color attachment.


753
00:42:54,916 --> 00:42:56,506
So let's go ahead and do that.


754
00:42:56,906 --> 00:43:00,046
So we have six passes
here, and now we are going


755
00:43:00,046 --> 00:43:01,696
to merge them down to four.


756
00:43:02,966 --> 00:43:06,956
So what impact did that have
on performance, GPU side?


757
00:43:07,896 --> 00:43:11,426
Let's go back to the
GPU, the system trace.


758
00:43:12,456 --> 00:43:16,716
Here we can see we have
gone from 21 milliseconds,


759
00:43:16,916 --> 00:43:20,946
six passes, down to 18 by
not having to write out all


760
00:43:21,006 --> 00:43:23,786
of that load and store all
of that attachment data.


761
00:43:24,556 --> 00:43:25,846
So that's quite a nice win.


762
00:43:27,256 --> 00:43:28,756
But could we go any further?


763
00:43:28,756 --> 00:43:31,536
Let's return to our app.


764
00:43:32,756 --> 00:43:39,746
So we have four passes,
and is it actually possible


765
00:43:39,746 --> 00:43:44,736
to combine both the G-buffer and
the lighing pass to avoid having


766
00:43:44,736 --> 00:43:49,056
to store out five attachments
and keep everything on chip?


767
00:43:50,076 --> 00:43:52,676
Well, it in fact is.


768
00:43:52,676 --> 00:43:56,576
We can do that with clever
use of programmable blending.


769
00:43:57,636 --> 00:43:59,446
So I'm not going to go
into too much detail there,


770
00:43:59,446 --> 00:44:04,446
but what we did was we combined
these two encoders down to one.


771
00:44:04,696 --> 00:44:07,386
So now we are left with
three render encoders


772
00:44:08,056 --> 00:44:10,236
and we are having to
load and store far,


773
00:44:10,236 --> 00:44:13,946
far less attachment data,
and that's a massive win


774
00:44:13,996 --> 00:44:16,596
in terms of bandwidth.


775
00:44:16,676 --> 00:44:18,466
So let's see what
impact that had.


776
00:44:20,006 --> 00:44:21,776
Actually not a lot.


777
00:44:21,936 --> 00:44:23,416
That was very unexpected.


778
00:44:23,416 --> 00:44:26,556
We have only chopped
off about a millisecond.


779
00:44:26,936 --> 00:44:28,446
That's not great.


780
00:44:28,446 --> 00:44:31,036
I was hoping for more than that.


781
00:44:31,036 --> 00:44:33,756
So once again, can
Xcode save us?


782
00:44:34,676 --> 00:44:37,176
We turn to Xcode's
frame debugger.


783
00:44:38,256 --> 00:44:41,496
And we take a closer look at
the load and store bandwidth


784
00:44:42,016 --> 00:44:43,826
for the G-buffer encoder.


785
00:44:45,896 --> 00:44:48,266
Now, it turns out that we
are actually still loading


786
00:44:48,266 --> 00:44:52,566
and storing quite a lot
of data, and the reason


787
00:44:52,566 --> 00:44:53,706
for that is quite simple.


788
00:44:54,126 --> 00:44:57,566
It looks like here we have
mistakenly set our loads


789
00:44:58,026 --> 00:45:00,686
and store actions for each
attachment incorrectly.


790
00:45:01,526 --> 00:45:05,586
We only wanted to be storing
the first color attachment,


791
00:45:06,096 --> 00:45:08,976
and we want to discard the
remaining color attachments


792
00:45:08,976 --> 00:45:11,756
in addition to the depth
and stencil attachments,


793
00:45:12,556 --> 00:45:14,986
and we certainly don't
want to be loading them in.


794
00:45:16,406 --> 00:45:21,276
So if we make the very simple
change, we change our load


795
00:45:21,276 --> 00:45:24,116
and store actions to
something more appropriate,


796
00:45:24,826 --> 00:45:28,026
we have reduced our load
bandwidth down to zero


797
00:45:28,186 --> 00:45:31,706
and we have massively
reduced the amounts


798
00:45:31,836 --> 00:45:33,746
of attachment data
we're storing.


799
00:45:35,296 --> 00:45:38,246
So now, what impact
did that have?


800
00:45:39,266 --> 00:45:41,836
So before, with our
three passes,


801
00:45:41,836 --> 00:45:44,906
we are taking 17
milliseconds on the GPU.


802
00:45:45,806 --> 00:45:48,656
Now, we are down to 14.


803
00:45:48,656 --> 00:45:49,566
That's more like it.


804
00:45:51,766 --> 00:45:55,496
So to summarize, don't
waste your render encoders.


805
00:45:55,596 --> 00:45:58,166
Try to do as much useful
work as possible in them,


806
00:45:59,056 --> 00:46:01,756
and definitely do
not start encoding


807
00:46:01,756 --> 00:46:03,326
if you are not going
to draw anything.


808
00:46:05,276 --> 00:46:10,496
And if you can, and with the
help of Xcode, merge encoders


809
00:46:10,496 --> 00:46:12,596
which are rendering to
the same attachments.


810
00:46:13,136 --> 00:46:16,266
This will get you big wins.


811
00:46:17,116 --> 00:46:20,386
Now, we are doing pretty
well on the GPU side now.


812
00:46:20,496 --> 00:46:24,166
In fact, we are actually
within our frame budget.


813
00:46:25,496 --> 00:46:28,476
But is there anything we
can do on the CPU side?


814
00:46:29,676 --> 00:46:33,226
If you remember, I think we were
actually still slightly beyond


815
00:46:33,356 --> 00:46:34,396
our frame budget.


816
00:46:35,876 --> 00:46:36,956
What about multithreading?


817
00:46:37,386 --> 00:46:39,106
How could multithreading
help us?


818
00:46:40,246 --> 00:46:42,926
What does Metal allow us to
do in terms of multithreading?


819
00:46:44,496 --> 00:46:47,846
Fortunately for us, Metal was
designed with multithreading


820
00:46:47,846 --> 00:46:55,546
in mind and has a very efficient
threadsafe and scalable means


821
00:46:55,546 --> 00:46:57,366
of multithreading
your rendering.


822
00:46:57,366 --> 00:47:01,756
It allows you to encode multiple
command buffers simultaneously


823
00:47:02,086 --> 00:47:06,766
on different threads, and your
app has control over the order


824
00:47:06,766 --> 00:47:07,896
in which these are executed.


825
00:47:09,386 --> 00:47:12,256
Let's take a look at
a possible scenario


826
00:47:12,256 --> 00:47:14,036
where we might attempt
some multithreading.


827
00:47:14,956 --> 00:47:17,346
But before that, I
would like to stress


828
00:47:17,346 --> 00:47:20,436
that before you even
go ahead and try


829
00:47:20,436 --> 00:47:21,806
to multithread your rendering,


830
00:47:21,806 --> 00:47:25,276
you should actively
pursue the best possible


831
00:47:25,276 --> 00:47:26,686
single-threaded performance.


832
00:47:27,206 --> 00:47:30,096
So make sure there is
nothing terribly inefficient


833
00:47:30,096 --> 00:47:34,106
in there before you start
trying to multithread things.


834
00:47:34,286 --> 00:47:38,346
Okay. So we have an example here
where we have two render passes,


835
00:47:39,336 --> 00:47:45,996
and we are actually taking so
long to encode these two passes


836
00:47:45,996 --> 00:47:51,636
on the CPU that we are actually
missing our frame deadline.


837
00:47:53,016 --> 00:47:54,746
So how can we improve this?


838
00:47:55,386 --> 00:47:59,286
Well, we can go ahead and
we can encode the two passes


839
00:47:59,286 --> 00:47:59,916
in parallel.


840
00:48:00,866 --> 00:48:06,176
And not only have we managed to
reduce the CPU time per frame,


841
00:48:07,286 --> 00:48:11,046
the side effect is that the
first render pass can be


842
00:48:11,046 --> 00:48:13,496
submitted to the GPU quicker.


843
00:48:13,646 --> 00:48:19,716
So how would this look in
terms of Metal objects?


844
00:48:20,926 --> 00:48:21,866
How does it come together?


845
00:48:22,826 --> 00:48:25,626
Where we start with our Metal
device in the command queue


846
00:48:25,626 --> 00:48:29,656
as usual, and now for
this example we are going


847
00:48:29,656 --> 00:48:30,906
to have three threads.


848
00:48:30,906 --> 00:48:36,226
And for each thread, you
need a command buffer.


849
00:48:36,416 --> 00:48:41,756
Now, for the two threads, each
has a Render Command Encoder


850
00:48:41,806 --> 00:48:44,296
which is operating
on separate passes,


851
00:48:45,336 --> 00:48:50,426
and on our third thread we
might have multiple encoders


852
00:48:51,296 --> 00:48:52,416
executing serially.


853
00:48:53,046 --> 00:48:55,116
So it goes to show
the approaches


854
00:48:55,116 --> 00:48:57,376
to multithreading can
be quite flexible,


855
00:48:58,306 --> 00:49:00,706
and once they have all
finished their encoding,


856
00:49:00,706 --> 00:49:03,406
the command buffers are
submitted to the command queue.


857
00:49:04,976 --> 00:49:07,186
So how would you set this up?


858
00:49:08,556 --> 00:49:09,446
It's quite simple.


859
00:49:10,656 --> 00:49:15,856
You create one command buffer
per thread and you go ahead


860
00:49:15,856 --> 00:49:18,926
and initialize render
passes as usual,


861
00:49:19,586 --> 00:49:23,206
and now the important
point here is the order


862
00:49:23,206 --> 00:49:26,936
in which the command buffers
will be submitted to the GPU.


863
00:49:27,846 --> 00:49:29,936
Chances are this is
important to you.


864
00:49:30,256 --> 00:49:33,866
So you enforce it by
calling the Enqueue method


865
00:49:34,296 --> 00:49:39,086
on the command buffers,
and that reserves a place


866
00:49:39,086 --> 00:49:43,026
in the command queue so when
the buffers are eventually


867
00:49:43,026 --> 00:49:46,336
committed, they will be
executed in the order


868
00:49:46,336 --> 00:49:47,216
that they were enqueued.


869
00:49:47,216 --> 00:49:49,366
This is an important
point to remember.


870
00:49:50,486 --> 00:49:54,966
Because then we create the
render encoders for each thread,


871
00:49:55,766 --> 00:50:00,146
and we go ahead and encode our
draws on the separate threads


872
00:50:00,146 --> 00:50:02,106
and then commit the
command buffers.


873
00:50:02,746 --> 00:50:04,206
It's really very simple to do.


874
00:50:06,846 --> 00:50:08,756
Now, what about another scenario


875
00:50:08,846 --> 00:50:11,236
which could potentially
benefit from multithreading?


876
00:50:13,086 --> 00:50:15,236
So here again we
have two passes,


877
00:50:15,776 --> 00:50:18,006
but one of them is significantly
longer than the other.


878
00:50:18,816 --> 00:50:20,346
Could we split that up somehow?


879
00:50:21,086 --> 00:50:21,816
Yes, we can.


880
00:50:22,506 --> 00:50:25,586
Here, we will break it up
into two separate passes.


881
00:50:26,046 --> 00:50:27,246
We have three threads here.


882
00:50:27,906 --> 00:50:29,646
One is working on the
first render pass,


883
00:50:29,896 --> 00:50:33,206
and we have two dedicated to
working on chunks of the second.


884
00:50:34,226 --> 00:50:37,626
And, again, here by employing
multithreading we are


885
00:50:37,626 --> 00:50:41,286
within our frame deadline,
and we have got a bit of time


886
00:50:41,286 --> 00:50:42,836
to spare on the CPU as well


887
00:50:42,836 --> 00:50:45,326
for doing whatever
else we fancy doing.


888
00:50:45,326 --> 00:50:47,636
It need not necessarily
be more Metal work.


889
00:50:49,636 --> 00:50:52,946
So how would we, or rather
what would this look like?


890
00:50:54,516 --> 00:50:58,366
So once again, we have the
device and the command queue.


891
00:50:58,456 --> 00:51:02,306
And for this example, we are
going to be using three threads.


892
00:51:03,866 --> 00:51:08,866
But here we only want
one command buffer.


893
00:51:09,056 --> 00:51:13,096
Next, we have the special form
of the Render Command Encoder,


894
00:51:13,346 --> 00:51:15,456
the Parallel Render
Command Encoder.


895
00:51:16,176 --> 00:51:21,246
Now, this allows you to split
work for a single encoder


896
00:51:21,826 --> 00:51:25,196
over multiple threads, and this
is particularly important to use


897
00:51:25,196 --> 00:51:27,456
on iOS because it ensures


898
00:51:27,566 --> 00:51:32,266
that the threaded
workloads are later combined


899
00:51:32,266 --> 00:51:35,796
into a single pass on the GPU.


900
00:51:35,796 --> 00:51:38,696
So there is no loading and
storing between passes.


901
00:51:38,826 --> 00:51:41,406
This is very important that
you use this if you are going


902
00:51:41,406 --> 00:51:43,986
to split up a single pass
across multiple threads.


903
00:51:45,516 --> 00:51:47,806
So from the Parallel
Render Command Encoder,


904
00:51:47,996 --> 00:51:52,026
we create our three
subordinate command encoders,


905
00:51:53,206 --> 00:51:57,396
and each will encode to
the command buffer now,


906
00:51:57,396 --> 00:52:00,346
because we are multithreading
they may finish encoding


907
00:52:00,646 --> 00:52:03,266
at indeterminate times,


908
00:52:03,266 --> 00:52:05,696
not necessarily any
particular order.


909
00:52:06,866 --> 00:52:09,526
Then the command buffer
submitted to the queue.


910
00:52:10,596 --> 00:52:12,656
Now, it's entirely feasible


911
00:52:12,726 --> 00:52:16,276
that you could even have
parallel Parallel Render


912
00:52:16,276 --> 00:52:17,216
Command Encoders.


913
00:52:18,526 --> 00:52:22,796
The multithreading possibilities
are not quite endless,


914
00:52:22,846 --> 00:52:23,726
but very flexible.


915
00:52:24,456 --> 00:52:26,856
Or you could have
like we saw earlier,


916
00:52:26,856 --> 00:52:28,366
you could have a fourth thread


917
00:52:28,936 --> 00:52:31,996
which is executing
encoder serially.


918
00:52:32,726 --> 00:52:37,826
So how do we set this up?


919
00:52:38,336 --> 00:52:42,256
Well, we begin by creating one
command buffer per Parallel


920
00:52:42,826 --> 00:52:43,556
Render Command Encoder.


921
00:52:43,556 --> 00:52:46,016
So no matter how many
threads you are using,


922
00:52:46,296 --> 00:52:47,696
you only want one
command buffer.


923
00:52:48,296 --> 00:52:54,206
We then proceed to initialize
the render pass as usual,


924
00:52:54,206 --> 00:52:58,516
and then we create our
actual parallel encoder.


925
00:52:58,516 --> 00:53:01,026
Now, here is the important bit.


926
00:53:02,516 --> 00:53:05,436
When we create our
subordinate encoders,


927
00:53:06,036 --> 00:53:09,866
the order in which they are
created determines the order


928
00:53:09,866 --> 00:53:12,736
in which they will be
submitted to the GPU.


929
00:53:12,736 --> 00:53:15,526
This is something to bear
in mind when you split


930
00:53:15,526 --> 00:53:18,446
up your workload for encoding
over multiple threads.


931
00:53:20,436 --> 00:53:24,596
Then we go ahead and we encode
our draws and separate threads,


932
00:53:25,206 --> 00:53:28,706
and then finish encoding for
each subordinate encoder.


933
00:53:29,966 --> 00:53:32,296
Now, the second important
point is all


934
00:53:32,296 --> 00:53:36,996
of the subordinate encoders must
have finished encoding before we


935
00:53:36,996 --> 00:53:39,236
end encoding on the
parallel encoder.


936
00:53:40,216 --> 00:53:41,926
And how you implement
this is up to you.


937
00:53:42,916 --> 00:53:46,076
Then finally, the command buffer
is committed to the queue.


938
00:53:48,306 --> 00:53:52,646
So we went ahead and we
decided to multithread our app.


939
00:53:53,606 --> 00:53:54,616
Look what turned up.


940
00:53:56,106 --> 00:54:00,656
So previously, we had
serial encoding or passes.


941
00:54:01,856 --> 00:54:06,486
This was taking 25
milliseconds of CPU time.


942
00:54:08,166 --> 00:54:16,176
Now, we pursued an approach
where we encode the shadow pass


943
00:54:16,176 --> 00:54:20,656
on one thread, and the G-buffer
pass and UI pass on another,


944
00:54:21,656 --> 00:54:24,266
and now we are down
to 15 milliseconds.


945
00:54:25,286 --> 00:54:27,746
That's quite a nifty
improvement,


946
00:54:27,906 --> 00:54:33,976
and we have got a bit of time
left over on the CPU as well.


947
00:54:34,176 --> 00:54:36,826
So as far as multithreading
goes,


948
00:54:36,886 --> 00:54:40,766
if you find that you are still
CPU bound and you have done all


949
00:54:40,766 --> 00:54:42,546
of the investigations you can,


950
00:54:42,726 --> 00:54:45,756
and determining you haven't
got anything silly going


951
00:54:45,756 --> 00:54:48,556
on in your app, and that
you could actually benefit


952
00:54:48,556 --> 00:54:51,896
from multithreading, you
can encode render passes


953
00:54:51,896 --> 00:54:53,786
simultaneously on
multiple threads.


954
00:54:54,776 --> 00:54:57,846
But should you decide to
split up a single pass


955
00:54:58,286 --> 00:54:59,486
across multiple threads,


956
00:54:59,966 --> 00:55:03,066
you want to use the Parallel
Render Command Encoder to do so.


957
00:55:03,066 --> 00:55:09,426
Now, what did we
learn in this session?


958
00:55:10,936 --> 00:55:13,386
Well, we introduced the
Metal System Trace tool,


959
00:55:13,386 --> 00:55:14,296
and it was great.


960
00:55:14,296 --> 00:55:17,826
It offers new insight into
your app's Metal performance.


961
00:55:18,606 --> 00:55:21,406
And you want to use this
in conjunction with Xcode


962
00:55:21,526 --> 00:55:23,366
to profile early and often.


963
00:55:23,366 --> 00:55:27,516
And as we have seen,
you should also try


964
00:55:27,516 --> 00:55:30,036
to follow the best
practices set out,


965
00:55:30,616 --> 00:55:34,266
so you want to create the
expensive state up front


966
00:55:34,296 --> 00:55:35,846
and reuse it as often
as possible.


967
00:55:36,976 --> 00:55:39,956
We want to buffer
dynamic resources


968
00:55:40,436 --> 00:55:44,156
so we can efficiently
modify them between frames


969
00:55:44,156 --> 00:55:45,216
without causing stalls.


970
00:55:46,746 --> 00:55:50,166
We want to make sure we
are acquiring our drawable


971
00:55:50,166 --> 00:55:52,216
at the correct point in time.


972
00:55:52,736 --> 00:55:54,626
Usually at the last
possible moment.


973
00:55:56,086 --> 00:55:59,326
We want to make sure we are
efficiently using our Render


974
00:55:59,326 --> 00:56:00,326
Command Encoders.


975
00:56:00,816 --> 00:56:03,216
We don't have any
empty encoders,


976
00:56:03,216 --> 00:56:06,866
and we have coalesced any
encoders which are writing


977
00:56:06,866 --> 00:56:08,546
to the same attachment
down to one.


978
00:56:09,136 --> 00:56:14,196
And then if we find we are
still CPU bound as we were


979
00:56:14,196 --> 00:56:18,606
in this case, we might consider
the approaches Metal offers


980
00:56:18,606 --> 00:56:20,046
for multithreading
our rendering.


981
00:56:22,046 --> 00:56:25,176
So how did we do?


982
00:56:25,686 --> 00:56:27,876
Well, now look at our app!


983
00:56:28,336 --> 00:56:30,776
We don't have any runtime
shader compilation.


984
00:56:31,696 --> 00:56:36,456
Furthermore, our GPU workload
is within the frame deadline.


985
00:56:36,666 --> 00:56:37,146
It's great.


986
00:56:38,196 --> 00:56:40,266
As is the CPU workload.


987
00:56:41,376 --> 00:56:45,356
And there are no gaps between
processing of frames on the CPU.


988
00:56:46,016 --> 00:56:51,656
And we even got quite fancy and
decided to do multithreading.


989
00:56:51,656 --> 00:56:56,366
We have a lot of time left
over there to do other things.


990
00:56:56,556 --> 00:56:59,006
And we managed to
meet our target,


991
00:56:59,006 --> 00:57:01,016
which in this case was
60 frames per second.


992
00:57:01,146 --> 00:57:03,766
So well done us!


993
00:57:05,216 --> 00:57:08,566
So now, the talk is
over, and if you would


994
00:57:08,566 --> 00:57:11,356
like any more information
on anything mentioned


995
00:57:11,356 --> 00:57:14,526
in this session, you can
visit our developer portal,


996
00:57:14,916 --> 00:57:18,006
you can also sign up for
the developer forums,


997
00:57:18,896 --> 00:57:22,606
and should you have any detailed
questions or general inquiries,


998
00:57:22,606 --> 00:57:26,156
you can direct them to Allan
Schaffer, who is our Graphics


999
00:57:26,156 --> 00:57:27,896
and Games Technologies
Evangelist.


1000
00:57:29,476 --> 00:57:32,316
So thank you very much
for attending this talk.


1001
00:57:32,376 --> 00:57:34,676
And we hope you found
it interesting,


1002
00:57:34,846 --> 00:57:37,886
and enjoy the rest of WWDC!


1003
00:57:38,276 --> 00:57:38,876
Thank you very much!


1004
00:57:39,676 --> 00:57:52,520
[ Applause ]

