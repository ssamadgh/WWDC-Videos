1
00:00:24,516 --> 00:00:27,036
[Applause]


2
00:00:27,536 --> 00:00:31,316
>> ANTHONY CHIVETTA:
Good morning and welcome


3
00:00:31,316 --> 00:00:34,046
to building responsive and
efficient apps with GCD.


4
00:00:34,306 --> 00:00:37,276
We're so excited to see so
many of you here interested


5
00:00:37,276 --> 00:00:40,416
in learning about how Grand
Central Dispatch can help you


6
00:00:40,886 --> 00:00:43,256
adapt your application
to all of our platforms.


7
00:00:43,646 --> 00:00:46,826
I'm Anthony and my teammate
Daniel will be presenting this


8
00:00:46,826 --> 00:00:47,336
talk with me.


9
00:00:48,526 --> 00:00:52,176
Grand Central Dispatch or GCD is
a technology that was introduced


10
00:00:52,176 --> 00:00:53,336
with OS X Snow Leopard.


11
00:00:53,696 --> 00:00:57,626
At that time our brand new
Mac was the MacBook Pro


12
00:00:57,896 --> 00:00:59,286
with the Core II Duo.


13
00:00:59,656 --> 00:01:02,646
One of the selling points
of GCD at the time was


14
00:01:02,646 --> 00:01:05,126
that it would allow you to
take advantage of both cores,


15
00:01:05,126 --> 00:01:07,236
running different parts of
your application concurrently,


16
00:01:07,536 --> 00:01:09,866
and make threading
really, really easy.


17
00:01:10,356 --> 00:01:13,746
We think that use of GCD has
really stood the test of time.


18
00:01:14,656 --> 00:01:19,036
Today our top-of-the-line Mac
Pro has many, many more Cores


19
00:01:19,606 --> 00:01:22,446
and GCD is still a great
way to take advantage of all


20
00:01:22,446 --> 00:01:23,626
of those computing resources.


21
00:01:24,346 --> 00:01:28,056
But just as GCD is a great
way to use all the resources


22
00:01:28,056 --> 00:01:30,886
on the high end it can
help your application adapt


23
00:01:30,976 --> 00:01:32,596
to smaller environments.


24
00:01:34,176 --> 00:01:36,136
For example, the new MacBook


25
00:01:36,136 --> 00:01:38,686
that we recently released is
the first paneless design.


26
00:01:39,316 --> 00:01:44,846
While this is an advantage in
terms of size of the machine,


27
00:01:44,846 --> 00:01:47,336
it also presents unique
challenges in terms


28
00:01:47,336 --> 00:01:49,366
of how we manage the
thermal properties.


29
00:01:49,446 --> 00:01:52,986
I'll talk a little bit later
about how your app can use GCD


30
00:01:53,176 --> 00:01:54,946
to run more efficiently
in this environment.


31
00:01:55,696 --> 00:01:59,536
We also have iOS 9 with
new multitasking features.


32
00:01:59,946 --> 00:02:02,836
This is the first time your
app had to run side-by-side,


33
00:02:02,976 --> 00:02:06,896
quite literally, with other
applications on the system.


34
00:02:06,896 --> 00:02:09,836
GCD can inform the system
what kind of work you're doing


35
00:02:09,985 --> 00:02:13,406
and better share
resources between your app


36
00:02:13,476 --> 00:02:15,046
and the other apps
present on the screen.


37
00:02:15,536 --> 00:02:21,656
Of course, Watch OS brings your
code to our smallest platform.


38
00:02:22,516 --> 00:02:26,346
GCD is a way that you can help
the system know which parts


39
00:02:26,346 --> 00:02:28,916
of your code you should
run in order to be able


40
00:02:28,916 --> 00:02:34,056
to have a responsive application
on a device this size.


41
00:02:38,976 --> 00:02:41,176
So a brief outline of what we
are going to go through today.


42
00:02:41,686 --> 00:02:42,556
I'm going to start


43
00:02:42,556 --> 00:02:45,066
by introducing something called
Quality of Service classes.


44
00:02:45,646 --> 00:02:49,496
This is an API that we released
with iOS 8 and OS X Yosemite.


45
00:02:50,826 --> 00:02:53,276
Daniel's going to come up and
go through some design patterns


46
00:02:53,276 --> 00:02:54,706
for using GCD, and how


47
00:02:54,706 --> 00:02:56,576
to integrate QLS
with these patterns.


48
00:02:57,676 --> 00:03:00,296
I'll then go through some
details about threads, queues,


49
00:03:00,336 --> 00:03:03,126
and run loops that can
make using GCD easier.


50
00:03:03,706 --> 00:03:06,686
And finally, we'll conclude
with a brief section on how


51
00:03:06,686 --> 00:03:08,816
to understand crash reports
when you're using GCD.


52
00:03:09,596 --> 00:03:13,486
But first a little
bit of background.


53
00:03:14,336 --> 00:03:17,386
So we have your awesome app.


54
00:03:17,386 --> 00:03:20,266
And you start executing the
app, the user taps the icon,


55
00:03:20,266 --> 00:03:21,206
loads it from a finder.


56
00:03:21,976 --> 00:03:24,156
We will begin executing
your code in main


57
00:03:24,576 --> 00:03:26,366
and you'll have your
initial main thread


58
00:03:26,366 --> 00:03:27,336
that every app starts with.


59
00:03:28,326 --> 00:03:31,666
You call UI application
main, or NSApplication main,


60
00:03:31,666 --> 00:03:34,026
and that's going to bring
up a run loop on the thread


61
00:03:34,146 --> 00:03:35,216
and the Framework code.


62
00:03:35,776 --> 00:03:39,686
And then that thread is going
to sit there waiting for events.


63
00:03:40,306 --> 00:03:42,776
At some point something
is going to happen.


64
00:03:42,776 --> 00:03:44,206
Maybe you'll get a
delegate method call


65
00:03:44,206 --> 00:03:45,846
out to your UI application
delegate.


66
00:03:45,846 --> 00:03:48,556
At this point, your code
begins to run and needs


67
00:03:48,556 --> 00:03:51,206
to do something; let's say it
wants to read from a database.


68
00:03:52,146 --> 00:03:54,296
You go out and, you'll
access that file on disk.


69
00:03:55,256 --> 00:03:56,656
That data will come back.


70
00:03:58,366 --> 00:03:59,976
You'll update the
user interface.


71
00:04:02,436 --> 00:04:05,666
And then finally return
control back to the Frameworks


72
00:04:05,666 --> 00:04:07,246
and continue waiting for
events on the thread.


73
00:04:08,356 --> 00:04:10,196
This works great until that read


74
00:04:10,196 --> 00:04:13,626
from the database takes
a little bit of time.


75
00:04:13,766 --> 00:04:18,446
At that point on OS X you might
see a spinning wait cursor.


76
00:04:18,846 --> 00:04:21,676
On iOS the app would hang and
might even get terminated.


77
00:04:22,416 --> 00:04:25,806
This is a poor and
unresponsive user experience.


78
00:04:26,266 --> 00:04:30,106
And this is where
GCD can come in


79
00:04:30,106 --> 00:04:32,296
and help make things
a little bit easier.


80
00:04:32,296 --> 00:04:33,836
You'll get your delegate
method of call out.


81
00:04:33,836 --> 00:04:38,946
But instead of doing the work
immediately you can create a GCD


82
00:04:39,616 --> 00:04:42,576
queue, use dispatch async to
move the work on to the cue.


83
00:04:43,636 --> 00:04:45,756
Your code executes
asynchronously


84
00:04:45,756 --> 00:04:47,016
with respect to the main thread.


85
00:04:48,166 --> 00:04:50,246
When you have the
data available,


86
00:04:50,246 --> 00:04:53,346
you can dispatch async back to
the main thread, update the UI.


87
00:04:53,346 --> 00:04:57,356
Now, the advantage here is that
while your work is happening


88
00:04:57,356 --> 00:05:00,596
on that GCD queue, the main
thread can continue waiting


89
00:05:00,596 --> 00:05:01,256
for events.


90
00:05:01,436 --> 00:05:02,536
It stays responsive.


91
00:05:02,576 --> 00:05:04,546
The user continues to
get a great experience,


92
00:05:05,346 --> 00:05:08,056
and everyone is happy.


93
00:05:08,296 --> 00:05:09,436
Now, I'm hoping this
is a pattern


94
00:05:09,436 --> 00:05:10,486
that is familiar to all of you.


95
00:05:10,486 --> 00:05:12,266
We are not going to
go through the details


96
00:05:12,266 --> 00:05:13,526
of how to accomplish this.


97
00:05:14,016 --> 00:05:16,576
If this is not familiar, I
highly encourage you to head


98
00:05:16,576 --> 00:05:19,906
up to Presidio after this
and check out the talk there


99
00:05:19,906 --> 00:05:23,056
which will go through
the pattern in detail.


100
00:05:23,766 --> 00:05:25,846
One thing you might have
not thought about before,


101
00:05:25,846 --> 00:05:28,936
is we now have two threads
that both want to execute code.


102
00:05:29,346 --> 00:05:31,016
Your main thread wants
to handle new events


103
00:05:31,146 --> 00:05:32,536
and the GCD queue wants


104
00:05:32,536 --> 00:05:34,286
to execute the block
you dispatched to it.


105
00:05:34,286 --> 00:05:37,376
And maybe we're only on
a single core device.


106
00:05:38,046 --> 00:05:40,366
In this case, which
thread do we execute?


107
00:05:45,286 --> 00:05:47,676
This is where Quality of
Service classes come into play.


108
00:05:48,436 --> 00:05:53,156
As I mentioned this is a new
API in iOS 8 and 10 Yosemite


109
00:05:53,156 --> 00:05:54,546
that we released last year.


110
00:05:55,306 --> 00:05:58,806
We have four Quality of Service
classes: user interactive,


111
00:05:59,036 --> 00:06:01,616
user initiated, utility
and background.


112
00:06:02,806 --> 00:06:04,776
These are ways you tell
the system what kind


113
00:06:04,776 --> 00:06:07,896
of work you're doing, and in
turn, it allows the system


114
00:06:07,896 --> 00:06:10,246
to provide a variety
of resource controls


115
00:06:10,716 --> 00:06:12,526
to most effectively
execute your code.


116
00:06:12,526 --> 00:06:16,376
When I say resource controls,
what am I talking about?


117
00:06:16,946 --> 00:06:19,946
Our system has support for
CPU scheduling priority,


118
00:06:20,426 --> 00:06:22,286
which threads do we
run, in what order?


119
00:06:22,286 --> 00:06:26,146
I/O priority, how do we
execute I/O with deference


120
00:06:26,146 --> 00:06:27,326
to other I/O in the system.


121
00:06:28,216 --> 00:06:30,666
Timer coalescing, which
is a power-saving feature.


122
00:06:31,316 --> 00:06:33,836
And whether we run
the CPU in through-put


123
00:06:33,836 --> 00:06:35,356
or in efficiency-oriented mode.


124
00:06:35,566 --> 00:06:37,426
Do we want to get the most
performance, or do we want


125
00:06:37,426 --> 00:06:41,656
to execute the code in the
most energy-efficient manner?


126
00:06:41,806 --> 00:06:45,086
In an ideal world we tune each
of these configuration values


127
00:06:45,386 --> 00:06:48,306
for each platform or device and
piece of code that's running,


128
00:06:49,006 --> 00:06:51,166
but obviously this would
get out of hand quickly.


129
00:06:51,456 --> 00:06:54,526
There's a lot of values hard
to tune correctly and a lot


130
00:06:54,526 --> 00:06:58,176
of platforms where
your code can run.


131
00:06:58,176 --> 00:07:00,306
Quality of Service
Classes are designed


132
00:07:00,306 --> 00:07:03,206
to be a single abstract
parameter that you can use


133
00:07:03,236 --> 00:07:06,336
to communicate the intent and
classification of your work.


134
00:07:06,336 --> 00:07:08,566
Rather than trying to tune all


135
00:07:08,566 --> 00:07:11,566
of these specific configuration
values you simply say


136
00:07:11,716 --> 00:07:13,096
"I'm doing user initiated work"


137
00:07:13,526 --> 00:07:15,676
and the system will
automatically pick the right


138
00:07:15,676 --> 00:07:17,556
values for that platform
and device.


139
00:07:18,096 --> 00:07:22,776
So I mentioned we have four
Quality of Service classes.


140
00:07:22,856 --> 00:07:25,276
Let me talk through them briefly
and what they are used for.


141
00:07:26,126 --> 00:07:27,466
The first is user interactive.


142
00:07:28,086 --> 00:07:29,576
This is the main thread.


143
00:07:30,146 --> 00:07:33,426
Imagine you have an iOS app,
the user has their finger


144
00:07:33,426 --> 00:07:34,506
on the screen and is dragging.


145
00:07:35,086 --> 00:07:37,946
The main thread needs to
be responsive in order


146
00:07:37,946 --> 00:07:39,776
to deliver the next
frame of animation


147
00:07:39,776 --> 00:07:40,736
as the user is dragging.


148
00:07:41,166 --> 00:07:45,506
The main user interactive code
is specifically the code needed


149
00:07:45,856 --> 00:07:48,366
in order to keep that 60
frames per second animation


150
00:07:48,366 --> 00:07:49,156
running smoothly.


151
00:07:51,326 --> 00:07:55,096
So you want to ask yourself:
Is this work actively involved


152
00:07:55,096 --> 00:07:55,886
in updating the UI


153
00:07:56,436 --> 00:07:57,846
when considering
whether something should


154
00:07:57,846 --> 00:07:58,926
be user-interactive.


155
00:07:59,826 --> 00:08:04,386
This isn't loading the content
potentially of that scroll view.


156
00:08:04,976 --> 00:08:07,926
It is just drawing
the new animation.


157
00:08:08,576 --> 00:08:11,866
We talk about user initiated
as being loading the results


158
00:08:11,866 --> 00:08:13,856
of an action done by the user.


159
00:08:14,316 --> 00:08:15,726
So this might be
as I'm scrolling


160
00:08:15,726 --> 00:08:18,546
through scroll view loading
the data for the next cells


161
00:08:19,156 --> 00:08:22,596
or if I'm in a photo or mail
application and tap an email


162
00:08:22,596 --> 00:08:26,176
or photo, loading the
full size photo or e-mail,


163
00:08:26,666 --> 00:08:29,226
those kinds of actions are what
we talk about as user initiated.


164
00:08:30,236 --> 00:08:33,206
The question is, is
this work required


165
00:08:33,206 --> 00:08:34,716
to continue user interaction?


166
00:08:35,096 --> 00:08:36,775
It's helpful not to any about it


167
00:08:36,775 --> 00:08:38,726
as user initiated
but user blocking.


168
00:08:38,726 --> 00:08:41,816
If the user can't continue
to make meaningful progress


169
00:08:41,816 --> 00:08:44,596
with your application, user
initiated is the correct class.


170
00:08:46,236 --> 00:08:48,866
Utility is for those things
that the user may have started,


171
00:08:49,596 --> 00:08:50,896
or may have started
automatically,


172
00:08:51,156 --> 00:08:54,176
but are longer running tasks
that don't prevent the user


173
00:08:54,176 --> 00:08:55,536
from continuing to use your app.


174
00:08:57,176 --> 00:08:59,126
You want to ask yourself,
is the user aware


175
00:08:59,126 --> 00:09:01,356
of the progress of this work?


176
00:09:01,356 --> 00:09:03,896
If you were a magazine app
downloading a new issue,


177
00:09:04,336 --> 00:09:06,586
is something that
the user can continue


178
00:09:06,586 --> 00:09:07,616
to use the app while
it's happening.


179
00:09:07,616 --> 00:09:09,976
They can read old
issues or browse around.


180
00:09:10,496 --> 00:09:12,136
You may have a progress bar


181
00:09:12,416 --> 00:09:13,986
and the user is aware
of the progress.


182
00:09:14,506 --> 00:09:16,746
This is a great thing
to classify as utility.


183
00:09:18,836 --> 00:09:21,256
Finally, background is
for everything else.


184
00:09:21,466 --> 00:09:23,216
The user is not actively
watching.


185
00:09:23,216 --> 00:09:25,216
Any kind of maintenance
task, cleanup work,


186
00:09:26,776 --> 00:09:29,486
database vacuuming
would all be background.


187
00:09:30,316 --> 00:09:32,776
And the question is basically,


188
00:09:32,816 --> 00:09:34,286
is the user unaware
of this work?


189
00:09:34,956 --> 00:09:37,256
Now background work is
interesting because you want


190
00:09:37,256 --> 00:09:39,436
to think about when
you're doing it.


191
00:09:39,436 --> 00:09:41,746
I encourage you to take a look


192
00:09:41,746 --> 00:09:44,666
at the writing energy efficient
code sessions from last year


193
00:09:44,776 --> 00:09:47,406
that talk about how to do
background work effectively


194
00:09:47,516 --> 00:09:55,276
if your app has significant
work in this class.


195
00:09:56,666 --> 00:09:57,816
So I mentioned our new MacBook.


196
00:09:58,836 --> 00:10:02,546
As I said, this is
the first fanless Mac.


197
00:10:02,546 --> 00:10:05,676
In previous MacBooks
that had a fan,


198
00:10:05,676 --> 00:10:08,896
as the machine is doing more and
more work and generating more


199
00:10:08,896 --> 00:10:11,766
and more energy and
therefore heat we can bring


200
00:10:11,766 --> 00:10:14,436
up the fan speed to help
dissipate the heat faster.


201
00:10:15,256 --> 00:10:17,836
The new MacBook is
incredibly energy efficient.


202
00:10:18,246 --> 00:10:22,446
We don't need a fan to dissipate
heat in most circumstances,


203
00:10:23,426 --> 00:10:26,896
but running this machine at
full speed is still going


204
00:10:26,896 --> 00:10:29,346
to generate some energy
we need to dissipate.


205
00:10:30,266 --> 00:10:32,426
But our ability to dissipate
heat is at a constant rate.


206
00:10:33,356 --> 00:10:37,806
We have other techniques to make
sure we can keep the enclosure


207
00:10:37,806 --> 00:10:40,006
of the machine at an appropriate
temperature for the user.


208
00:10:40,846 --> 00:10:44,226
Imagine you have an app using
and you have work happening


209
00:10:44,226 --> 00:10:46,026
at all four Quality
of Service classes.


210
00:10:46,856 --> 00:10:49,886
You are driving the machine
hard, using a lot of energy


211
00:10:50,176 --> 00:10:52,906
and we need to help control
that amount of energy in order


212
00:10:52,906 --> 00:10:54,976
to keep the machine at a
reasonable temperature.


213
00:10:55,616 --> 00:10:58,986
Well, what we can do is we can
start to squeeze the amount


214
00:10:58,986 --> 00:11:00,126
of work we are going to do


215
00:11:00,476 --> 00:11:02,646
at the less important
Quality of Service classes.


216
00:11:03,136 --> 00:11:06,586
This allows us to manage
the system's use of energy,


217
00:11:07,896 --> 00:11:10,406
keep the machine
responsive, and make sure


218
00:11:10,406 --> 00:11:13,726
that there's no responsiveness
issues visible to the user.


219
00:11:14,666 --> 00:11:16,096
This way it's very important


220
00:11:16,096 --> 00:11:17,806
that you have your work
correctly classified


221
00:11:17,866 --> 00:11:21,516
when running on a
machine like this.


222
00:11:21,926 --> 00:11:24,846
I also mentioned iOS and the
new multitasking features.


223
00:11:25,556 --> 00:11:28,436
You can imagine in the old
world we might have your app


224
00:11:28,436 --> 00:11:31,776
with its main thread and maybe
it has additional dispatch


225
00:11:31,816 --> 00:11:35,346
thread running but now
I bring up another app.


226
00:11:35,836 --> 00:11:40,066
And that app also is going
to have a main thread.


227
00:11:41,246 --> 00:11:42,916
And then I also have
a Picture in Picture.


228
00:11:43,646 --> 00:11:45,206
That has a thread
decoding the video.


229
00:11:46,026 --> 00:11:48,966
Okay, but I've only
got two CPUs.


230
00:11:49,896 --> 00:11:52,256
So if I have to use one
to decode the video,


231
00:11:52,536 --> 00:11:53,576
what do I do with the next one?


232
00:11:54,286 --> 00:11:55,676
This is another place
for Quality


233
00:11:55,676 --> 00:11:57,356
of Service classes can
really help you out.


234
00:11:57,856 --> 00:12:01,716
Indicating to the operating
system the Quality of Service


235
00:12:01,716 --> 00:12:04,026
of each thread we
can correctly decide


236
00:12:04,026 --> 00:12:05,966
where to marshall those
available resources.


237
00:12:07,426 --> 00:12:10,196
So with that I'll hand things
off to Daniel who will go


238
00:12:10,196 --> 00:12:13,096
through specific design patterns
and how to apply Quality


239
00:12:13,096 --> 00:12:13,976
of Service to those patterns.


240
00:12:14,516 --> 00:12:20,806
[Applause]


241
00:12:21,306 --> 00:12:21,796
>> DANIEL STEFFEN: Good morning.


242
00:12:21,796 --> 00:12:22,396
Thanks, Anthony.


243
00:12:23,136 --> 00:12:25,016
So in this section
we are going to look


244
00:12:25,016 --> 00:12:29,606
at a couple specific examples
GCD design and how QoS applies.


245
00:12:30,606 --> 00:12:34,236
The fundamentals we are
going to look at for GCD


246
00:12:34,236 --> 00:12:38,326
and QoS are how QoS
can be specified


247
00:12:38,396 --> 00:12:41,866
at the individual block level
as well as on QoS has a whole


248
00:12:42,446 --> 00:12:44,446
and how dispatch async


249
00:12:44,446 --> 00:12:47,746
and related APIs
propagate QoS automatically


250
00:12:47,746 --> 00:12:49,056
from the submitting thread


251
00:12:49,096 --> 00:12:50,836
to the asynchronously
running block,


252
00:12:51,516 --> 00:12:54,656
and then how the system can
resolve some priority inversions


253
00:12:54,656 --> 00:12:55,766
for you automatically.


254
00:12:56,196 --> 00:13:00,236
We won't have time to go into
depth on the specific API calls.


255
00:13:00,796 --> 00:13:05,526
If you want more details
I encourage you to look


256
00:13:05,526 --> 00:13:07,536
at the session from last
year, "Power, performance


257
00:13:07,536 --> 00:13:09,456
and diagnostics: What's
New in GCD and XPC",


258
00:13:09,456 --> 00:13:13,356
that you can see this on the
developer website where we went


259
00:13:13,356 --> 00:13:17,286
into much more specific
detail on how to use the APIs


260
00:13:17,286 --> 00:13:18,676
that were new last year.


261
00:13:19,876 --> 00:13:22,956
So first example is the
example that Anthony had earlier


262
00:13:23,206 --> 00:13:25,376
where we performed
some asynchronous work


263
00:13:26,156 --> 00:13:30,866
and do some I/O on the GCD
cue off of the main thread.


264
00:13:32,266 --> 00:13:37,316
How does this example
fit in with QoS,


265
00:13:37,316 --> 00:13:39,046
what are the appropriate Quality


266
00:13:39,046 --> 00:13:40,476
of Service classes
to apply here?


267
00:13:40,476 --> 00:13:44,606
On the left-hand side we have
the main thread, of course.


268
00:13:44,606 --> 00:13:47,466
As Anthony mentioned, this is
where the UI rendering happens,


269
00:13:47,516 --> 00:13:48,846
this is where the
event handling happens,


270
00:13:49,386 --> 00:13:51,876
the appropriate caller service
call here is user interactive.


271
00:13:52,566 --> 00:13:54,106
Nothing you have
to do to get this.


272
00:13:54,216 --> 00:13:55,986
The main thread of
the application comes


273
00:13:55,986 --> 00:13:57,266
up at this Quality
of Service class.


274
00:13:57,266 --> 00:14:00,786
On the right-hand
side of the screen,


275
00:14:00,786 --> 00:14:03,236
that's the asynchronous work not
happening on the main thread.


276
00:14:03,766 --> 00:14:06,866
Obviously, we shouldn't be
running user interactive.


277
00:14:07,136 --> 00:14:08,766
We're not doing the
UI rendering here.


278
00:14:09,186 --> 00:14:12,216
But, say the user tapped on the
document icon and is waiting


279
00:14:12,486 --> 00:14:16,196
for his document to open.


280
00:14:16,196 --> 00:14:18,776
The user is blocked in
his progress with the app.


281
00:14:18,906 --> 00:14:21,866
He can still interact with the
UI but can't do what he wants,


282
00:14:21,866 --> 00:14:24,856
which is edit the document
or view the document.


283
00:14:24,856 --> 00:14:26,756
User initiated is the
appropriate Quality


284
00:14:26,756 --> 00:14:27,556
of Service Class here.


285
00:14:30,286 --> 00:14:32,916
So how do we achieve
that with the GCD API.


286
00:14:33,596 --> 00:14:37,696
It turns out you don't
have to do anything,


287
00:14:37,696 --> 00:14:39,226
it will work automatically.


288
00:14:39,616 --> 00:14:41,646
But it's important to
understand why that is.


289
00:14:41,646 --> 00:14:44,916
Let's look at that in detail.


290
00:14:44,916 --> 00:14:47,386
Everything starts with
this initial dispatch async


291
00:14:47,456 --> 00:14:50,036
that works off the asynchronous
work from the main thread.


292
00:14:50,756 --> 00:14:53,596
As I mentioned in
the previous slide,


293
00:14:53,676 --> 00:14:56,036
dispatch async does automatic
propagation of Quality


294
00:14:56,036 --> 00:14:59,206
of Service from the
submitting thread to the queue


295
00:14:59,646 --> 00:15:02,696
where you submit the
block to execute.


296
00:15:02,696 --> 00:15:07,226
Now, in this case there's
a special rule that applies


297
00:15:07,226 --> 00:15:09,426
which is that we
automatically translate Quality


298
00:15:09,426 --> 00:15:12,756
of Service Class user
interactive to user initiated.


299
00:15:13,286 --> 00:15:16,086
We do this so we don't
accidentaly over-propagate the


300
00:15:16,086 --> 00:15:18,216
Quality of Service Class
that should be restricted


301
00:15:18,216 --> 00:15:19,976
to the main thread
and UI rendering.


302
00:15:19,976 --> 00:15:22,286
We can take advantage
of that here,


303
00:15:22,436 --> 00:15:23,796
because that is exactly
what we want.


304
00:15:24,346 --> 00:15:25,966
That is typically the case


305
00:15:26,536 --> 00:15:30,036
by having the automatic
propagation run the block


306
00:15:30,456 --> 00:15:33,956
on the queue at Quality of
Service Class user initiated.


307
00:15:34,726 --> 00:15:36,996
Of course when you go back to
the main thread to update the UI


308
00:15:36,996 --> 00:15:40,276
with the results this automatic
propagation will also try


309
00:15:40,686 --> 00:15:41,446
to take place.


310
00:15:42,086 --> 00:15:45,666
Because the user main
thread is Quality


311
00:15:45,666 --> 00:15:47,066
of Service Class
user interactive,


312
00:15:47,576 --> 00:15:48,576
that will take priority.


313
00:15:48,716 --> 00:15:51,286
It will not lower if
you go to a thread


314
00:15:51,506 --> 00:15:52,866
that has some assigned Quality


315
00:15:52,866 --> 00:15:54,246
of Service Class
like the main thread.


316
00:15:54,866 --> 00:15:56,896
Here we will ignore
this propagated value


317
00:15:57,336 --> 00:16:01,386
and run the UI update block
at the bottom at Quality


318
00:16:01,386 --> 00:16:02,636
of Service Class
user interactive.


319
00:16:03,286 --> 00:16:08,756
So we call this QoS propagation
property inferred QoS.


320
00:16:09,516 --> 00:16:13,216
And this is QoS captured at the
time the block gets submitted


321
00:16:13,216 --> 00:16:15,626
to a queue and with
the special rule


322
00:16:15,626 --> 00:16:17,206
that we translate
user interactive


323
00:16:17,296 --> 00:16:19,076
to user initiated as mentioned.


324
00:16:20,406 --> 00:16:22,706
This propagated Quality
of Service is used


325
00:16:22,786 --> 00:16:24,826
if the destination where
the block is submitted


326
00:16:24,826 --> 00:16:27,156
to does not have its own
quality of service specified


327
00:16:28,286 --> 00:16:31,566
and does not lower QoS if
you go to the main thread


328
00:16:31,566 --> 00:16:34,626
that has its own high
Quality of Service assigned.


329
00:16:36,756 --> 00:16:42,636
So next example is something
that doesn't open automatically,


330
00:16:42,636 --> 00:16:44,666
long running job, say a
long running calculation


331
00:16:45,096 --> 00:16:48,486
that dispatch asyncs it off
the main thread so as not


332
00:16:48,486 --> 00:16:53,136
to interfere with the UI and it
operates on a queue concurrently


333
00:16:53,136 --> 00:16:58,906
with the main thread and maybe
updates the UI with the progress


334
00:16:58,996 --> 00:17:00,446
by asyncing back a block


335
00:17:00,546 --> 00:17:02,596
that updates some
progress UI element.


336
00:17:05,816 --> 00:17:08,356
What are the appropriate
Quality of Service classes here?


337
00:17:08,715 --> 00:17:11,425
On the left-hand side you
have user interactive,


338
00:17:11,915 --> 00:17:14,965
and the right-hand side as
Anthony has described earlier,


339
00:17:14,965 --> 00:17:17,026
this is something where Quality


340
00:17:17,026 --> 00:17:18,925
of Service utility
is appropriate.


341
00:17:19,336 --> 00:17:20,506
It's something long running.


342
00:17:20,816 --> 00:17:22,205
The user can continue
to use the UI.


343
00:17:22,496 --> 00:17:24,376
He's not waiting for
the results immediately


344
00:17:24,376 --> 00:17:28,036
and he can see the progress,
and he probably initiated it


345
00:17:28,036 --> 00:17:32,106
in some fashion but it is not
blocking his immediate progress.


346
00:17:33,696 --> 00:17:37,746
So how do we make this
happen with the GCD API?


347
00:17:38,256 --> 00:17:40,476
The simplest solution
is to focus on the point


348
00:17:40,476 --> 00:17:42,526
where the work is
generated, initiated.


349
00:17:43,266 --> 00:17:44,876
This is initial dispatch async.


350
00:17:45,586 --> 00:17:47,986
We can tag the block
that we submit


351
00:17:48,676 --> 00:17:50,606
with the appropriate
Quality of Service Class


352
00:17:50,606 --> 00:17:53,656
by using the dispatch block
create with QoS class API,


353
00:17:54,456 --> 00:17:57,376
we pass in the block that
we want to execute as well


354
00:17:57,486 --> 00:17:58,586
as the Quality of Service Class


355
00:17:58,666 --> 00:18:00,346
that we would like,
utility here.


356
00:18:00,766 --> 00:18:02,616
The resulting block
object is what we pass


357
00:18:02,686 --> 00:18:06,656
through dispatch async and when
that gets executed that will run


358
00:18:06,836 --> 00:18:08,366
at Quality of Service
Class utility


359
00:18:09,226 --> 00:18:12,756
and by finding this
initial generation point


360
00:18:12,756 --> 00:18:14,526
where the Quality of
Service Class changes,


361
00:18:15,076 --> 00:18:17,716
the automatic propagation
further downstream,


362
00:18:17,946 --> 00:18:21,326
if any from that block, will
then be able to take advantage


363
00:18:21,326 --> 00:18:22,566
of the automatic propagation.


364
00:18:22,926 --> 00:18:25,396
So that anything that gets
generated asynchronously


365
00:18:25,396 --> 00:18:27,526
from that work will
happen automatically


366
00:18:27,526 --> 00:18:30,346
at the correct Quality
of Service class,


367
00:18:30,346 --> 00:18:32,616
continue to be a utility without
you having to do anything.


368
00:18:33,246 --> 00:18:39,476
So this block QoS is
created like we saw


369
00:18:39,476 --> 00:18:42,426
in the previous slide by adding
an explicit QoS attribute


370
00:18:42,426 --> 00:18:45,306
to the wrapped up block object
to the block you provide


371
00:18:45,806 --> 00:18:49,176
at the appropriate time to use
this is at the point when work


372
00:18:49,176 --> 00:18:50,536
of a different class
is generated.


373
00:18:51,396 --> 00:18:54,146
Another use case for
QoS in a block object is


374
00:18:54,656 --> 00:18:58,716
if you have needs to capture
the Quality of Service class


375
00:18:58,716 --> 00:19:00,406
in a block that you
are provided,


376
00:19:00,856 --> 00:19:05,106
say in a callback block scenario
where you are writing an API


377
00:19:05,296 --> 00:19:08,036
where somebody provides you with
a callback block and you want


378
00:19:08,036 --> 00:19:11,016
to store that block and submit
it later from a different thread


379
00:19:11,396 --> 00:19:13,366
or queue, but you really want


380
00:19:13,366 --> 00:19:16,106
to get this propagation right
the same way dispatch async


381
00:19:16,106 --> 00:19:17,786
propagates the Quality
of Service.


382
00:19:18,276 --> 00:19:21,476
You can do this by using the
dispatch block assign current


383
00:19:22,106 --> 00:19:24,136
flag, pass that through
dispatch block create,


384
00:19:24,136 --> 00:19:27,126
and that will capture the
current QoS and execution state,


385
00:19:27,516 --> 00:19:30,576
store it in a rapid block and
when you submit that block later


386
00:19:30,576 --> 00:19:33,496
on to a queue it will run
with that assigned value.


387
00:19:34,756 --> 00:19:39,896
To look at another example,
we have an application


388
00:19:40,346 --> 00:19:42,036
that performs a UI action.


389
00:19:42,036 --> 00:19:43,056
And during the performance


390
00:19:43,056 --> 00:19:45,336
of that action it notices
some maintenance condition,


391
00:19:45,336 --> 00:19:46,876
some cleanup condition
that should happen.


392
00:19:47,316 --> 00:19:49,566
Say you have a database, it
has too many loose objects,


393
00:19:49,566 --> 00:19:53,036
has to do some compaction,
some clean up task,


394
00:19:53,936 --> 00:20:00,996
typical example again
of the use of GCD


395
00:20:01,246 --> 00:20:04,106
where you would execute
dispatch async to run


396
00:20:04,106 --> 00:20:07,306
that maintenance task
on a background queue


397
00:20:07,306 --> 00:20:09,676
and the left-hand
side, of course,


398
00:20:10,086 --> 00:20:13,606
being the user initiated
-- user interactive again.


399
00:20:13,606 --> 00:20:16,836
The appropriate Quality of
Service class here would be


400
00:20:17,166 --> 00:20:19,076
to use Quality of
Service background.


401
00:20:19,806 --> 00:20:22,056
Currently given by the
title of the slide,


402
00:20:22,256 --> 00:20:24,326
this is a maintenance
operation that is unrelated


403
00:20:24,326 --> 00:20:25,466
to what the user is doing.


404
00:20:25,466 --> 00:20:27,986
You notice this condition
while you were going along


405
00:20:28,586 --> 00:20:31,296
and the user is unaware
that this is occurring.


406
00:20:31,446 --> 00:20:34,036
You are kind of doing
work, the app does work


407
00:20:34,036 --> 00:20:35,166
on its own behalf here.


408
00:20:35,486 --> 00:20:39,556
How do we achieve running
Quality of Service background?


409
00:20:39,956 --> 00:20:43,426
One thing we can do is to use
the block API we saw earlier


410
00:20:43,426 --> 00:20:47,666
and have the initial async
to this queue be the Quality


411
00:20:47,846 --> 00:20:49,176
of Service background.


412
00:20:49,616 --> 00:20:52,206
Maybe this is a case where there
is multiple places in the app


413
00:20:52,266 --> 00:20:53,876
that generate this
type of clean up work


414
00:20:53,876 --> 00:20:57,196
and there's multiple ways
that you need to operate


415
00:20:57,196 --> 00:20:58,526
on the database in this mode.


416
00:20:58,526 --> 00:21:02,366
It might be appropriate to have
a queue specifically dedicated


417
00:21:02,406 --> 00:21:05,046
to this task so you
can also create queues


418
00:21:05,226 --> 00:21:07,786
with assigned Quality
of Service.


419
00:21:07,786 --> 00:21:11,386
You use dispatch queue
attr make with QoS class,


420
00:21:11,386 --> 00:21:13,296
passing in background
in this example.


421
00:21:13,756 --> 00:21:16,286
The resulting attribute can be
passed to dispatch queue create


422
00:21:16,796 --> 00:21:19,136
to create a clean up queue
in this example here.


423
00:21:20,556 --> 00:21:23,046
By having Quality of Service
class assigned to the queue,


424
00:21:23,616 --> 00:21:26,496
you get the automatic
propagation for dispatch async,


425
00:21:27,706 --> 00:21:31,576
again user initiated
from the main thread we


426
00:21:31,976 --> 00:21:34,876
in fact ignore this propagated
value because you are submitting


427
00:21:34,876 --> 00:21:36,826
to a queue that has its
own assigned Quality


428
00:21:36,826 --> 00:21:39,516
of Service Class and use
what the queue says instead.


429
00:21:40,006 --> 00:21:43,026
So the block that you submitted
will run at background instead


430
00:21:43,366 --> 00:21:44,466
of what it would have otherwise


431
00:21:44,696 --> 00:21:46,466
if it had the automatic
propagation.


432
00:21:47,636 --> 00:21:50,936
For a case like this where there
is a maintenance task unrelated


433
00:21:50,936 --> 00:21:54,736
to the execution flow,
it may be appropriate


434
00:21:55,316 --> 00:21:59,936
to consider whether the dispatch
block detached flag is of use.


435
00:22:00,626 --> 00:22:04,476
This is a way to tell the
operating system that the work


436
00:22:04,476 --> 00:22:06,266
that you are doing in this
block has nothing to do


437
00:22:06,266 --> 00:22:07,706
with the flow of execution.


438
00:22:08,106 --> 00:22:11,526
And it will in particular
opt out of propagation of QoS


439
00:22:11,666 --> 00:22:15,196
but also opt out of capturing
things like the activity ID


440
00:22:15,196 --> 00:22:18,346
if you are using that for
the activity tracing feature


441
00:22:18,346 --> 00:22:20,606
that we introduced at
the conference last year.


442
00:22:22,146 --> 00:22:25,566
And other properties of
the execution context.


443
00:22:26,436 --> 00:22:30,436
Now, of course, even if you have
work that should always kind


444
00:22:30,436 --> 00:22:32,676
of be at Quality of Service
background that is clean


445
00:22:32,676 --> 00:22:34,206
up work, there may
be exceptions.


446
00:22:34,676 --> 00:22:38,896
Maybe there is some kind of log
out feature where the user logs


447
00:22:38,896 --> 00:22:41,506
out of his account and you
have to delete the database


448
00:22:42,066 --> 00:22:44,056
and delete the user's
private data.


449
00:22:44,486 --> 00:22:46,816
That's something that the
user want to see complete.


450
00:22:46,866 --> 00:22:48,496
This is not a background task.


451
00:22:49,066 --> 00:22:54,616
You may have a need to override
or opt out of this queue


452
00:22:54,616 --> 00:22:56,996
or this runs at background
property


453
00:22:56,996 --> 00:22:58,196
that you have set up here.


454
00:22:58,976 --> 00:23:01,646
If you just use the automatic
propagation feature here,


455
00:23:01,646 --> 00:23:05,416
as before we would ignore
the user initiated Quality


456
00:23:05,506 --> 00:23:07,336
of Service except
here, of course,


457
00:23:07,336 --> 00:23:09,376
that's the right Quality
of Service to use.


458
00:23:09,666 --> 00:23:10,896
That's what we really
want to happen.


459
00:23:10,896 --> 00:23:12,626
The user is waiting for
this log out to complete.


460
00:23:13,316 --> 00:23:14,526
How to achieve that?


461
00:23:14,526 --> 00:23:19,276
Use the dispatch block
enforce QoS class flag,


462
00:23:19,396 --> 00:23:21,776
block create along with the
block you want to execute.


463
00:23:22,156 --> 00:23:23,506
That indicates to the system


464
00:23:23,816 --> 00:23:26,856
that you really want the value
that's in the block as opposed


465
00:23:26,856 --> 00:23:27,986
to the one that's in the queue.


466
00:23:27,986 --> 00:23:30,896
So you can override the
queue's value display.


467
00:23:32,196 --> 00:23:36,986
If you do that, the block
will get executed at Quality


468
00:23:36,986 --> 00:23:39,236
of Service class user
initiated in this example.


469
00:23:40,616 --> 00:23:42,086
But of course, here


470
00:23:42,086 --> 00:23:44,116
in the picture you can
see now we have a case


471
00:23:44,116 --> 00:23:47,106
where you have several queue
with potentially two blocks


472
00:23:47,106 --> 00:23:49,486
in queue at the same time at
different priority levels.


473
00:23:50,256 --> 00:23:53,156
That's the case of
asynchronous priority inversion.


474
00:23:53,546 --> 00:23:56,196
A High QoS block may be
submitted to a serial queue,


475
00:23:56,196 --> 00:23:58,236
but there is already
work in queue or running


476
00:23:58,606 --> 00:24:00,026
at a lower Quality of Service


477
00:24:00,276 --> 00:24:01,966
and you have a priority
inversion.


478
00:24:03,166 --> 00:24:05,436
GCD helps you with that
if you use a serial queue


479
00:24:05,726 --> 00:24:08,936
by raising the work that
is already there, running


480
00:24:08,936 --> 00:24:11,776
or enqueued until you reach the
high Quality of Service block.


481
00:24:12,986 --> 00:24:15,226
This is something that
happens behind the scenes


482
00:24:15,356 --> 00:24:17,036
with QoS override.


483
00:24:17,036 --> 00:24:20,306
It is not something that the
over-written blocks can see


484
00:24:20,306 --> 00:24:22,896
themselves or if they
propagate work further along


485
00:24:23,286 --> 00:24:26,406
asynchronously they will
propagate at the original QoS


486
00:24:26,406 --> 00:24:29,766
that they were as, but they
will actually be running


487
00:24:29,766 --> 00:24:32,496
at a higher priority to
resolve the inversion.


488
00:24:34,316 --> 00:24:38,616
So to recap, queue QoS is
mostly appropriate for queues


489
00:24:38,666 --> 00:24:42,746
that are single purpose in the
app or take inputs from all


490
00:24:42,746 --> 00:24:44,876
over the place where you
don't want the priority


491
00:24:44,876 --> 00:24:46,926
of the submitted to be
important, but the priority


492
00:24:47,316 --> 00:24:50,516
of that purpose and it
may also be appropriate


493
00:24:50,896 --> 00:24:54,966
to use the detached block API
for such types of workload,


494
00:24:54,966 --> 00:24:56,966
especially if they are
maintenance or background.


495
00:24:58,946 --> 00:25:03,586
And using QoS on the queue
causes us to ignore the QoS


496
00:25:03,586 --> 00:25:06,856
in the asynchronous
blocks exempt in the case


497
00:25:06,856 --> 00:25:08,756
where you also use
that enforce flag.


498
00:25:09,616 --> 00:25:15,976
Last example is use of
serial queues as locks.


499
00:25:16,536 --> 00:25:18,236
This is a very common use of GCD


500
00:25:18,296 --> 00:25:21,716
where you have some shared
data structure in the app


501
00:25:22,106 --> 00:25:24,656
where you want locked access
to that data structure


502
00:25:25,176 --> 00:25:29,936
and you can use GCD by
creating a serial queue


503
00:25:30,046 --> 00:25:33,926
with a dispatch queue serial
flag at the data structure


504
00:25:33,986 --> 00:25:38,956
and then use dispatch sync to
execute a critical section block


505
00:25:39,406 --> 00:25:42,266
on that queue where that
block has exclusive access


506
00:25:42,266 --> 00:25:43,006
to the data structure.


507
00:25:43,826 --> 00:25:47,576
How does QoS fit into this?


508
00:25:47,576 --> 00:25:49,896
It is important to note
that dispatch sync,


509
00:25:50,136 --> 00:25:56,136
it executes the block when that
lock is obtained on the thread


510
00:25:56,136 --> 00:25:59,396
that calls dispatch sync
and releases the thread


511
00:25:59,396 --> 00:26:01,606
with the block returns.


512
00:26:01,776 --> 00:26:03,846
In this case we don't need any
additional [inaudible] threads,


513
00:26:03,846 --> 00:26:07,906
we have a thread called dispatch
sync and we will execute


514
00:26:07,906 --> 00:26:10,656
that block at the Quality of
Service of the calling thread,


515
00:26:11,026 --> 00:26:12,166
user interactive here.


516
00:26:13,426 --> 00:26:15,156
Of course you have
synchronization


517
00:26:15,156 --> 00:26:16,246
because you have other queues


518
00:26:16,316 --> 00:26:18,026
or threads accessing
this data structure.


519
00:26:18,446 --> 00:26:19,726
Maybe you have a Quality


520
00:26:19,726 --> 00:26:22,446
of Service utility thread
also calling dispatch sync


521
00:26:22,446 --> 00:26:25,316
on this queue to get
the exclusive access


522
00:26:25,346 --> 00:26:26,116
to the data structure.


523
00:26:26,626 --> 00:26:28,906
Again, the same thing
will happen if he comes


524
00:26:28,906 --> 00:26:32,496
in later he will block waiting
to get the exclusive access.


525
00:26:33,016 --> 00:26:36,236
Then execute that block on
his own thread at Quality


526
00:26:36,236 --> 00:26:37,206
of Service utility


527
00:26:37,456 --> 00:26:40,306
at the calling threads
Quality of Service.


528
00:26:41,426 --> 00:26:44,776
Now, of course in this,
if this acquisition


529
00:26:44,776 --> 00:26:46,386
of this exclusive
access happened


530
00:26:46,386 --> 00:26:48,646
in the other order we
would again have a case


531
00:26:48,646 --> 00:26:50,106
of priority inversion.


532
00:26:50,106 --> 00:26:52,956
If the utility guy comes in
first and takes the lock,


533
00:26:52,956 --> 00:26:55,606
you have the main thread
waiting on a utility thread.


534
00:26:56,456 --> 00:26:58,516
And that's obviously
undesirable.


535
00:26:59,086 --> 00:27:02,126
So Quality of Service
inheritance,


536
00:27:02,316 --> 00:27:04,346
synchronous priority inversion
will help you with that.


537
00:27:04,766 --> 00:27:06,356
A high priority service
thread waiting


538
00:27:06,356 --> 00:27:09,246
for the lower course
work, we'll resolve


539
00:27:09,316 --> 00:27:12,536
that by raising the Quality
of Service of waited on work


540
00:27:13,166 --> 00:27:16,046
for the duration of the
waiter and this happens


541
00:27:16,046 --> 00:27:18,716
if you use a serial queue
with the dispatch sync


542
00:27:18,716 --> 00:27:20,266
or the dispatch block wait APIs.


543
00:27:20,916 --> 00:27:22,906
It also happens if you
use pthread mutex lock


544
00:27:23,106 --> 00:27:26,426
or any APIs built on top
of it such as NSLock.


545
00:27:26,916 --> 00:27:32,346
It is important to note, there
are APIs that do not do this.


546
00:27:32,346 --> 00:27:35,306
Dispatch semaphores do not
admit a concept of ownership


547
00:27:35,306 --> 00:27:36,826
so the system cannot determine


548
00:27:36,826 --> 00:27:38,986
who will eventually
signal the semaphore.


549
00:27:39,086 --> 00:27:40,646
There cannot be any resolution


550
00:27:40,646 --> 00:27:42,616
of priority inversion
in that case.


551
00:27:42,616 --> 00:27:44,596
If you have priority inversions


552
00:27:45,026 --> 00:27:47,436
where you find high
priority waiter


553
00:27:47,436 --> 00:27:49,526
in a dispatch semaphore wait,


554
00:27:50,086 --> 00:27:54,636
where a low priority worker
is performing some work,


555
00:27:54,636 --> 00:27:57,436
you may have to switch
to dispatch block wait,


556
00:27:57,436 --> 00:27:58,006
where you can wait


557
00:27:58,006 --> 00:28:00,246
on an explicit entity
that we can raise.


558
00:28:00,246 --> 00:28:05,416
With that I hand it back to
Anthony to talk about queues,


559
00:28:05,416 --> 00:28:06,076
threads and run loops.


560
00:28:07,516 --> 00:28:12,326
[Applause]


561
00:28:12,826 --> 00:28:13,306
>> ANTHONY CHIVETTA:
Thanks, Daniel.


562
00:28:14,686 --> 00:28:17,506
Hopefully that whet your
appetite for Quality of Service


563
00:28:17,656 --> 00:28:20,036
and you'll go back and take
a look at the applications


564
00:28:20,036 --> 00:28:22,026
and how you can adopt
Quality of Service.


565
00:28:22,306 --> 00:28:25,976
I want to go through now other
topics around queues, threads


566
00:28:25,976 --> 00:28:30,896
and run loops in the hopes that
it might make a greater adoption


567
00:28:30,896 --> 00:28:33,466
of GCD easier for you and
help provide a little context


568
00:28:33,466 --> 00:28:34,796
as you debug your application.


569
00:28:35,376 --> 00:28:39,956
To remind ourselves we
have our application


570
00:28:40,276 --> 00:28:41,376
with our main thread.


571
00:28:41,846 --> 00:28:43,746
There's a GCD thread pool


572
00:28:44,126 --> 00:28:47,426
that services all blocks
you might put on GCD queues


573
00:28:47,696 --> 00:28:49,666
and you have some set of
queues in your application.


574
00:28:50,946 --> 00:28:53,806
Imagine on the main thread
you execute this code.


575
00:28:54,106 --> 00:28:56,256
You dispatch async
on to some queue.


576
00:28:57,396 --> 00:29:01,876
A block, and we will bring
up a thread for that block.


577
00:29:02,786 --> 00:29:04,206
Start executing your code.


578
00:29:04,466 --> 00:29:07,316
We'll execute performSelector
withObject afterDelay,


579
00:29:07,366 --> 00:29:10,006
and that will put a timer source


580
00:29:10,326 --> 00:29:11,546
on the current thread's
run loop.


581
00:29:11,546 --> 00:29:16,156
Now what do we think
happens a second later?


582
00:29:16,666 --> 00:29:17,736
Well, it turns out when


583
00:29:17,736 --> 00:29:20,786
that block completes the
thread might just go away.


584
00:29:20,966 --> 00:29:23,576
These are threads from
our ephemeral thread pool.


585
00:29:23,886 --> 00:29:26,056
They don't have any
guaranteed lifetime.


586
00:29:26,056 --> 00:29:27,656
We may destroy the thread.


587
00:29:28,326 --> 00:29:30,116
Of course even if
the thread stays


588
00:29:30,116 --> 00:29:32,976
around no one is actually
running that run loop.


589
00:29:33,296 --> 00:29:35,256
That timer is never
going to be able to fire.


590
00:29:36,036 --> 00:29:38,806
This is sort of an interesting
interaction that can happen


591
00:29:38,806 --> 00:29:43,556
as you mix run loop based and
dispatch queue based APIs.


592
00:29:43,846 --> 00:29:48,576
So kind of -- to kind of briefly
summarize the differences


593
00:29:48,576 --> 00:29:52,626
between run loops and serial
queues, run loops are bound


594
00:29:52,626 --> 00:29:53,516
to a particular thread.


595
00:29:54,306 --> 00:29:58,036
As an API you generally see them
get delegate method callbacks.


596
00:29:59,186 --> 00:30:02,506
They have an auto release pool
that pops after each iteration


597
00:30:02,506 --> 00:30:03,746
through all the run loop sources


598
00:30:04,256 --> 00:30:07,036
and run loop can be used
reentrantly, it's possible


599
00:30:07,036 --> 00:30:10,026
to respin the run loop from
the call out on that run loop.


600
00:30:10,026 --> 00:30:13,126
On the other hand, serial queues


601
00:30:13,446 --> 00:30:17,426
or dispatch queues use
ephemeral threads that come


602
00:30:17,426 --> 00:30:19,376
from our Grand Central
Dispatch thread pool.


603
00:30:20,056 --> 00:30:22,316
They generally take
blocks as their callbacks,


604
00:30:22,976 --> 00:30:25,466
or APIs that use them generally
take blocks as callbacks.


605
00:30:26,646 --> 00:30:29,146
The autorelease pool on a
serial queue will only pop


606
00:30:29,186 --> 00:30:30,976
when a thread goes
completely idle.


607
00:30:31,716 --> 00:30:34,846
This could never happen if your
application is constantly busy.


608
00:30:35,606 --> 00:30:38,996
So it's important to not rely on
the autorelease pool that comes


609
00:30:38,996 --> 00:30:40,816
for free when you use dispatch.


610
00:30:41,206 --> 00:30:43,296
If you are going to be auto
releasing a lot of objects,


611
00:30:43,296 --> 00:30:45,406
make sure you have your
auto release pools in place.


612
00:30:45,856 --> 00:30:49,636
Finally, serial queues
are not a reentrant


613
00:30:50,086 --> 00:30:51,946
or recursive locking structure.


614
00:30:52,326 --> 00:30:55,236
You want to make sure as you're
designing your application's use


615
00:30:55,236 --> 00:30:57,226
of queues, you don't run
into a case where you need


616
00:30:57,226 --> 00:30:58,316
to use them reentrantly.


617
00:30:59,256 --> 00:31:01,966
These rules are bound
together in the sense


618
00:31:01,966 --> 00:31:05,166
that main thread's run loop is
also exposed as the main queue.


619
00:31:05,626 --> 00:31:09,276
It is easy with respect to
the main thread to jump back


620
00:31:09,276 --> 00:31:10,596
and forth between these worlds.


621
00:31:11,166 --> 00:31:13,986
So if you go back to
the timer example,


622
00:31:13,986 --> 00:31:16,216
we kind of compare the APIs.


623
00:31:16,326 --> 00:31:17,416
For run loops we have things


624
00:31:17,416 --> 00:31:20,556
like NSObjects performSelector
withObject afterDelay.


625
00:31:21,266 --> 00:31:23,586
Or NSTimer
scheduledTimerWithTimeInterval


626
00:31:23,586 --> 00:31:25,966
that installs a timer
on the current run loop.


627
00:31:26,756 --> 00:31:29,116
In the dispatch world, we have
things like dispatch after


628
00:31:29,626 --> 00:31:32,536
and dispatch sources with
dispatch source set timer,


629
00:31:32,536 --> 00:31:36,006
which can create a
timer that will fire


630
00:31:36,006 --> 00:31:40,006
by putting a block on a queue.


631
00:31:40,516 --> 00:31:44,426
Now, I mentioned that Grand
Central Dispatch uses ephemeral


632
00:31:44,496 --> 00:31:47,606
threads, now let me talk
you through how that works.


633
00:31:48,436 --> 00:31:51,886
Imagine I'm executing and I do a
whole bunch of dispatch asyncs.


634
00:31:53,336 --> 00:31:55,746
I put those on the
global queues.


635
00:31:57,056 --> 00:32:00,446
The system is going to take
a thread from the thread pool


636
00:32:00,446 --> 00:32:01,726
and give it to the first block.


637
00:32:02,316 --> 00:32:03,356
Send it running on its way.


638
00:32:04,106 --> 00:32:05,876
Take another thread, give
it to the second block


639
00:32:05,876 --> 00:32:07,356
and send it running on its way.


640
00:32:07,896 --> 00:32:09,576
Say we're a two core device,


641
00:32:10,006 --> 00:32:11,916
these threads are both
running, actively executing.


642
00:32:12,356 --> 00:32:13,296
We stop here.


643
00:32:13,616 --> 00:32:16,726
We have one thread per
core which is ideal.


644
00:32:17,786 --> 00:32:20,316
Now, when that first block
finishes executing we'll take


645
00:32:20,346 --> 00:32:23,456
the thread, give it to
the next one, and so on.


646
00:32:24,096 --> 00:32:25,566
And this works really well.


647
00:32:25,956 --> 00:32:29,796
Until one of our blocks
needs access to a resource


648
00:32:29,796 --> 00:32:30,786
that isn't yet available.


649
00:32:32,346 --> 00:32:33,406
We call this waiting.


650
00:32:33,746 --> 00:32:37,026
A thread will wait
and suspend execution


651
00:32:37,096 --> 00:32:40,426
when it needs a resource
such as I/O or a lock.


652
00:32:41,186 --> 00:32:43,336
Now, you might also hear
this referred to as blocking.


653
00:32:43,756 --> 00:32:45,176
I will call it waiting today.


654
00:32:45,176 --> 00:32:46,786
So if I talk about
blocks blocking


655
00:32:46,786 --> 00:32:49,066
for the next five minutes
you'll get confused


656
00:32:49,476 --> 00:32:52,436
but you'll hear it called
blocking in many other contexts.


657
00:32:54,006 --> 00:32:56,836
What is interesting from this
from the GCD perspective,


658
00:32:56,836 --> 00:33:01,606
we want one block or one thread
executing actively per core


659
00:33:01,606 --> 00:33:02,206
on the device.


660
00:33:03,076 --> 00:33:06,486
So when a thread waits, we are
going to bring up another thread


661
00:33:06,486 --> 00:33:08,806
in our thread pool
up until some limit


662
00:33:09,616 --> 00:33:11,766
so that we can have one
thread executing per core.


663
00:33:13,306 --> 00:33:15,646
So let's imagine we
have these four blocks,


664
00:33:15,906 --> 00:33:18,356
we're executing the first
two on two different threads


665
00:33:19,156 --> 00:33:22,326
and the first guy goes
hey, I need to do some I/O.


666
00:33:22,966 --> 00:33:24,876
We go great, we'll issue
the I/O to the disk.


667
00:33:25,276 --> 00:33:29,916
But we are going to have you
wait for that I/O to come back.


668
00:33:30,166 --> 00:33:31,856
Then we are going to
bring up another thread,


669
00:33:31,856 --> 00:33:35,876
execute the next block and so
on as threads wait we'll bring


670
00:33:35,876 --> 00:33:37,256
up another thread to
execute the next block


671
00:33:37,256 --> 00:33:38,956
on that queue while there's
still work to be done.


672
00:33:39,256 --> 00:33:43,936
The problem here, if I only have
four blocks, that works great.


673
00:33:44,266 --> 00:33:47,906
If I have lots of blocks
and they all want to wait,


674
00:33:47,906 --> 00:33:50,126
we can get what we
call thread explosion.


675
00:33:51,596 --> 00:33:53,586
This is, of course,
a little inefficient.


676
00:33:53,706 --> 00:33:56,646
There are lots of threads
all using resources.


677
00:33:57,346 --> 00:33:59,176
If they all stop
waiting at the same time,


678
00:33:59,176 --> 00:34:00,496
we have lots of contention.


679
00:34:01,306 --> 00:34:03,576
So this isn't great
for performance.


680
00:34:03,816 --> 00:34:06,046
But it is also a
little dangerous


681
00:34:06,046 --> 00:34:07,166
in that there is a
limit to the number


682
00:34:07,166 --> 00:34:08,126
of threads we can bring up.


683
00:34:08,596 --> 00:34:11,926
When you exhaust the limit we
have a problem of what do we do


684
00:34:11,926 --> 00:34:13,016
with new work that comes in?


685
00:34:13,746 --> 00:34:14,876
This brings in deadlock.


686
00:34:14,876 --> 00:34:19,846
I want to talk about an example
of deadlock we saw in one


687
00:34:19,846 --> 00:34:21,186
of our applications internally.


688
00:34:21,466 --> 00:34:25,466
I hope I can talk
you through this.


689
00:34:25,466 --> 00:34:28,085
This is a great example
of how different parts


690
00:34:28,085 --> 00:34:30,656
of your application
interact in unexpected ways.


691
00:34:31,206 --> 00:34:36,216
We have the main thread and
the main thread has a bunch


692
00:34:36,216 --> 00:34:38,065
of work it wants to do.


693
00:34:38,065 --> 00:34:41,065
It will dispatch async
a whole butch of blocks


694
00:34:41,065 --> 00:34:42,045
onto a concurrent queue.


695
00:34:42,716 --> 00:34:45,246
We start bringing up
threads for those blocks,


696
00:34:45,596 --> 00:34:47,416
and those blocks
immediately turn around


697
00:34:47,416 --> 00:34:49,436
and dispatch sync back
on to the main thread.


698
00:34:50,356 --> 00:34:52,136
At this point we've brought


699
00:34:52,136 --> 00:34:53,396
up all the threads
we are willing to.


700
00:34:53,485 --> 00:34:55,226
In the simple example
here, it's four.


701
00:34:55,295 --> 00:34:57,005
We hit the thread limit.


702
00:34:57,005 --> 00:34:58,646
We are not going to bring


703
00:34:58,646 --> 00:35:00,576
up any additional threads
for the thread pool.


704
00:35:03,436 --> 00:35:03,996
Okay, fine.


705
00:35:03,996 --> 00:35:07,156
We need the main thread
to become available again


706
00:35:07,156 --> 00:35:08,706
so that those blocks
can acquire it,


707
00:35:09,256 --> 00:35:11,146
do their work and then complete.


708
00:35:11,736 --> 00:35:13,206
Now it put us back
under our limit.


709
00:35:14,646 --> 00:35:17,126
That might happen some some
situations, but let's imagine


710
00:35:17,716 --> 00:35:19,676
that our main thread then goes


711
00:35:19,676 --> 00:35:21,516
into the dispatch
async to a serial cue.


712
00:35:22,216 --> 00:35:23,656
So far so good.


713
00:35:24,086 --> 00:35:25,526
That block will not execute


714
00:35:25,526 --> 00:35:28,266
yet because there's no
additional threads available


715
00:35:28,266 --> 00:35:29,436
to execute that block.


716
00:35:29,746 --> 00:35:33,016
It will sit there waiting for
one of the threads to return


717
00:35:33,016 --> 00:35:33,926
so we can use it again.


718
00:35:35,116 --> 00:35:38,336
But then our main thread
decides to dispatch sync


719
00:35:38,486 --> 00:35:39,726
to that same serial queue.


720
00:35:41,216 --> 00:35:43,486
The problem is that there
are no threads available


721
00:35:43,486 --> 00:35:44,256
for that serial queue.


722
00:35:44,746 --> 00:35:48,016
The main call is going
to block forever.


723
00:35:48,546 --> 00:35:50,586
This is the classic
deadlock situation.


724
00:35:51,166 --> 00:35:53,036
Our main thread is
waiting on a resource.


725
00:35:53,686 --> 00:35:55,326
In this case a thread
from our thread pool.


726
00:35:55,326 --> 00:35:57,796
Where all the threads from
the thread pool are waiting


727
00:35:57,796 --> 00:35:59,086
on a resource, the main thread.


728
00:35:59,516 --> 00:36:01,386
They're both waiting on each
other and neither is going


729
00:36:01,386 --> 00:36:03,866
to give up that resource
so we have a deadlock.


730
00:36:05,146 --> 00:36:07,346
This may seem bizarre
and contrived.


731
00:36:07,346 --> 00:36:09,016
But when you have lots
of different parts


732
00:36:09,016 --> 00:36:10,626
of your appliation,
different modules,


733
00:36:10,666 --> 00:36:12,716
frameworks all doing
things at the same time,


734
00:36:13,236 --> 00:36:15,086
it's easier to hit
than you might imagine


735
00:36:15,816 --> 00:36:18,226
and may be more complicated
in practice.


736
00:36:18,846 --> 00:36:21,096
So it's something you
want to keep in mind


737
00:36:21,096 --> 00:36:22,436
as you are working with GCD.


738
00:36:22,476 --> 00:36:24,696
To make sure you can
avoid the situation.


739
00:36:25,086 --> 00:36:25,956
It is easy.


740
00:36:26,076 --> 00:36:29,176
I'll talk through some ways that
we can architect our application


741
00:36:29,176 --> 00:36:30,666
to be resilient against
this problem.


742
00:36:31,156 --> 00:36:33,836
First some basic things.


743
00:36:34,376 --> 00:36:35,336
Always good advice


744
00:36:35,336 --> 00:36:37,216
to use asynchronous
APIs whenever possible,


745
00:36:37,376 --> 00:36:38,516
especially for I/Os.


746
00:36:39,286 --> 00:36:42,496
If you do that, you can
avoid having blocks wait


747
00:36:42,496 --> 00:36:45,346
and as a result you won't
have to bring up more threads.


748
00:36:45,346 --> 00:36:46,356
Gain some efficiency.


749
00:36:47,426 --> 00:36:50,326
You can also use serial queues
for something like this.


750
00:36:50,526 --> 00:36:52,236
If we dispatched all that work


751
00:36:52,236 --> 00:36:56,366
on a serial queue we wouldn't
have had thread explosion.


752
00:36:56,366 --> 00:36:59,106
We would have only executed
one block at a time.


753
00:36:59,106 --> 00:37:01,956
I'm not telling you to serialize
your entire application,


754
00:37:02,616 --> 00:37:05,526
but as you are building
your application


755
00:37:05,526 --> 00:37:08,486
and creating different queues,
service different modules


756
00:37:08,486 --> 00:37:11,706
in your application, unless you
know that you need to run things


757
00:37:11,706 --> 00:37:13,796
in parallel for that
particular module,


758
00:37:14,046 --> 00:37:16,026
in order to meet your
performance goals,


759
00:37:16,396 --> 00:37:18,526
consider starting out with
a serial queue instead.


760
00:37:19,246 --> 00:37:21,536
There's a lot of performance
to be gained from running parts


761
00:37:21,536 --> 00:37:24,746
of your application
concurrently on serial queues.


762
00:37:25,116 --> 00:37:29,136
Then you can profile
your application,


763
00:37:29,366 --> 00:37:31,366
see what needs the additional
performance of running work


764
00:37:31,366 --> 00:37:34,576
in parallel and specifically
design those pieces of work


765
00:37:34,896 --> 00:37:37,526
in ways that are well managed
to avoid thread explosion.


766
00:37:38,446 --> 00:37:41,526
Now, of course, you can
also use NSOperation queues


767
00:37:41,526 --> 00:37:42,856
which have a concurrency limit.


768
00:37:44,056 --> 00:37:47,406
And finally don't
generate unlimited work.


769
00:37:47,706 --> 00:37:50,176
If you can design your work
to be well bounded in terms


770
00:37:50,176 --> 00:37:51,426
of the number of
blocks you need,


771
00:37:51,756 --> 00:37:52,886
that can avoid thread explosion.


772
00:37:53,906 --> 00:37:56,866
Let's look through more
specific code examples


773
00:37:57,476 --> 00:37:58,526
of things that went wrong here.


774
00:38:00,056 --> 00:38:03,326
The first is that we
mixed sync and async


775
00:38:04,546 --> 00:38:08,566
so if I just do a dispatch sync
to a queue, it's really fast.


776
00:38:08,786 --> 00:38:10,816
It is basically taking a lock.


777
00:38:11,886 --> 00:38:14,766
If I do a dispatch
async, it's really fast,


778
00:38:14,826 --> 00:38:16,216
it's an atomic enqueue.


779
00:38:17,046 --> 00:38:19,756
If I have a queue and
I only do one of these,


780
00:38:19,756 --> 00:38:23,506
the performance will be
similar to those primitives.


781
00:38:24,786 --> 00:38:29,006
If I mix these and async to to
a queue and do a dispatch sync,


782
00:38:29,626 --> 00:38:32,356
that dispatch sync has wait
for a thread to be created


783
00:38:32,456 --> 00:38:35,166
and then execute that block, and
then for the block to complete.


784
00:38:36,036 --> 00:38:38,446
Now we have the thread
creation time coming


785
00:38:38,446 --> 00:38:40,156
in to what really would
have been just a lock.


786
00:38:40,156 --> 00:38:44,056
Now, it's absolutely safe to
mix these primitives, but,


787
00:38:44,246 --> 00:38:46,956
as you design the application,
think about whether you need to.


788
00:38:47,556 --> 00:38:48,606
Be especially careful


789
00:38:48,606 --> 00:38:52,666
when mixing them
from the main thread.


790
00:38:53,406 --> 00:38:56,696
Now, of course, the next problem
is that we try to dispatch a lot


791
00:38:56,696 --> 00:38:58,936
of blocks on to a
concurrent queue all at once.


792
00:39:00,016 --> 00:39:05,186
If you do this, and in our
case we are just going to try


793
00:39:05,186 --> 00:39:06,866
to continue executing
off the main thread,


794
00:39:07,336 --> 00:39:09,686
but imagine you do something
similar where you async


795
00:39:09,686 --> 00:39:10,796
and then do a barrier sync.


796
00:39:11,486 --> 00:39:15,606
Either one is dangerous because
it could cause thread explosion


797
00:39:15,646 --> 00:39:16,386
and deadlocks.


798
00:39:17,266 --> 00:39:19,506
But we have a primitive
called dispatch apply,


799
00:39:19,976 --> 00:39:23,346
and these two pieces of code
here are basically exactly the


800
00:39:23,346 --> 00:39:25,726
same from the perspective
of the semantics for you.


801
00:39:26,306 --> 00:39:28,576
By switching to dispatch
apply, you allow GCD


802
00:39:28,576 --> 00:39:32,026
to manage the parallelism and
avoid the thread explosion.


803
00:39:33,536 --> 00:39:38,376
Of course, you can also
use dispatch semaphores.


804
00:39:38,376 --> 00:39:41,336
Many of you are familiar with
the use of semaphores as locks.


805
00:39:42,126 --> 00:39:43,326
We are going to use
the semaphore


806
00:39:43,406 --> 00:39:44,846
as a counting semaphore instead.


807
00:39:45,436 --> 00:39:47,866
We start out by initializing
it with the number


808
00:39:47,866 --> 00:39:50,296
of concurrent tasks
we want to execute.


809
00:39:50,296 --> 00:39:51,986
Say we want four running.


810
00:39:53,376 --> 00:39:57,476
Every time our block completes,
it signals the semaphore.


811
00:39:58,166 --> 00:40:01,016
Every time we submit, we
wait on the semaphore.


812
00:40:01,926 --> 00:40:05,686
As a result our submitter
thread will do four submissions


813
00:40:05,766 --> 00:40:08,596
and then block on that
semaphore wait until one


814
00:40:08,596 --> 00:40:10,516
of them can complete and
signal the semaphore.


815
00:40:11,436 --> 00:40:13,376
This pattern is nice if
you might be submitting


816
00:40:13,376 --> 00:40:15,026
from multiple places
in your application.


817
00:40:15,176 --> 00:40:17,956
Something like dispatch
apply isn't appropriate.


818
00:40:22,696 --> 00:40:25,276
So hopefully that's helped
you understand a little bit


819
00:40:25,276 --> 00:40:28,206
about thread explosion
and how to avoid it.


820
00:40:28,206 --> 00:40:30,416
I also want to talk
briefly about crash reports.


821
00:40:31,966 --> 00:40:33,876
Unfortunately most of
you probably had to deal


822
00:40:33,876 --> 00:40:35,086
with a crash report
at some point.


823
00:40:35,456 --> 00:40:36,876
There's a lot of
information here.


824
00:40:37,436 --> 00:40:39,496
This is especially true
if you are using GCD.


825
00:40:39,496 --> 00:40:46,226
As you have more threads,
there's more things to parse


826
00:40:46,596 --> 00:40:47,876
and to understand
what's going on.


827
00:40:49,386 --> 00:40:51,316
So I want to talk you
through a couple stacks


828
00:40:51,636 --> 00:40:55,846
that can help you understand
what the different threads


829
00:40:55,846 --> 00:40:56,806
in your application are doing.


830
00:40:57,216 --> 00:40:58,926
So the first one is
the manager thread.


831
00:40:59,836 --> 00:41:02,146
So the manager thread is
something that you are going


832
00:41:02,146 --> 00:41:04,486
to see in almost all
GCD using applications.


833
00:41:04,856 --> 00:41:06,776
It's there to help
process dispatch sources.


834
00:41:07,176 --> 00:41:10,076
You notice dispatch manager
thread is the root frame.


835
00:41:10,736 --> 00:41:12,506
You can generally ignore it.


836
00:41:13,056 --> 00:41:15,366
We have idle GCD threads.


837
00:41:16,006 --> 00:41:17,556
These are idle threads
in the thread pool.


838
00:41:17,866 --> 00:41:19,356
You can see start
work queue thread


839
00:41:19,356 --> 00:41:20,266
at the bottom of the stack.


840
00:41:20,666 --> 00:41:22,216
There's an indication
it's a GCD thread.


841
00:41:22,676 --> 00:41:24,776
Work queue current return
indicates it's sitting


842
00:41:24,776 --> 00:41:25,196
there idle.


843
00:41:25,676 --> 00:41:30,586
An active GCD thread, on the
other hand, will still begin


844
00:41:30,586 --> 00:41:33,016
with start work queue thread
but you'll see something


845
00:41:33,016 --> 00:41:35,746
like dispatch client call
out and dispatch call block


846
00:41:35,746 --> 00:41:37,696
and release, followed
by your code.


847
00:41:38,206 --> 00:41:40,536
You'll also see the dispatch
queue name that you passed


848
00:41:40,536 --> 00:41:41,426
when you created the queue.


849
00:41:41,796 --> 00:41:43,956
It's important to give
descriptive queue names.


850
00:41:44,536 --> 00:41:49,366
The main thread when
idle you'll see sitting


851
00:41:49,366 --> 00:41:53,806
in mock message trap, CF run
loop port and CF run loop run


852
00:41:54,536 --> 00:41:57,346
and you'll see com.apple.main
thread.


853
00:41:57,346 --> 00:42:01,586
On the other hand, if
your main queue is active,


854
00:42:02,126 --> 00:42:05,246
you might see CF run loop is
servicing the main dispatch


855
00:42:05,326 --> 00:42:09,186
queue if it was active because
of the main queue GCD queue.


856
00:42:09,186 --> 00:42:12,506
And in this case which
have NSBlock operation


857
00:42:12,506 --> 00:42:13,256
that we're calling out.


858
00:42:13,256 --> 00:42:17,226
Now, of course, you shouldn't
rely on things not changing.


859
00:42:17,226 --> 00:42:19,756
There are internal details and
I'm walking through this today


860
00:42:19,756 --> 00:42:23,076
to give you a guide
through your crash reports.


861
00:42:23,506 --> 00:42:25,596
Hopefully it will provide
some useful context.


862
00:42:27,006 --> 00:42:31,376
So with that to wrap things
up, remember that an efficient


863
00:42:31,376 --> 00:42:33,626
and responsive application
must be able to adopt


864
00:42:33,626 --> 00:42:36,436
to diverse environments, whether
it's the Watch or Mac Pro.


865
00:42:36,886 --> 00:42:40,146
These different platforms have a
variety of resources available.


866
00:42:40,606 --> 00:42:43,156
GCD is a great way to help
you manage them appropriately.


867
00:42:43,716 --> 00:42:47,016
QoS classes allow
the operating system


868
00:42:47,016 --> 00:42:49,886
to marshall your resources
in the most efficient way.


869
00:42:51,516 --> 00:42:54,086
So you should go home and think
about how you integrate Quality


870
00:42:54,086 --> 00:42:55,936
of Service classes
into your application


871
00:42:55,936 --> 00:42:58,956
and the existing uses of GCD.


872
00:42:59,486 --> 00:43:02,216
Finally, consider how
your apps use GCD and try


873
00:43:02,216 --> 00:43:03,316
to avoid thread explosion.


874
00:43:04,826 --> 00:43:05,966
For more information, check


875
00:43:05,966 --> 00:43:07,466
out the concurrency
programming guide


876
00:43:07,896 --> 00:43:10,716
or the energy efficiency
guides for Mac and iOS apps.


877
00:43:10,756 --> 00:43:13,036
The iOS app one is
new this week.


878
00:43:13,576 --> 00:43:14,006
Check it out.


879
00:43:14,006 --> 00:43:14,366
It's great.


880
00:43:14,366 --> 00:43:19,146
We have the developer forums
and Paul, our evangelist.


881
00:43:19,416 --> 00:43:21,396
A couple related sessions:


882
00:43:21,766 --> 00:43:26,546
Achieving all day battery life
provides more context behind the


883
00:43:26,546 --> 00:43:27,736
energy topics I mentioned.


884
00:43:28,426 --> 00:43:31,506
Optimizing your app
for multitasking iOS 9,


885
00:43:32,916 --> 00:43:36,846
advanced NSOperations, and
performans on iOS and Watch OS,


886
00:43:37,196 --> 00:43:38,926
just after this in Presidio.


887
00:43:38,926 --> 00:43:42,186
If those are new to
you, I highly recommend


888
00:43:42,186 --> 00:43:44,406
that you check those out.

