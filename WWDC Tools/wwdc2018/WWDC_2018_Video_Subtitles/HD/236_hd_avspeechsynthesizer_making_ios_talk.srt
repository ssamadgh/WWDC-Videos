1
00:00:06,516 --> 00:00:14,500
[ Music ]


2
00:00:18,286 --> 00:00:19,366
>> Hello. My name is Chris


3
00:00:19,366 --> 00:00:20,976
Fleizach and let's talk about


4
00:00:20,976 --> 00:00:22,846
making iOS talk using


5
00:00:22,846 --> 00:00:23,856
AVSpeechSynthesis.


6
00:00:25,536 --> 00:00:26,646
So our agenda for today.


7
00:00:26,826 --> 00:00:28,126
What and why is


8
00:00:28,126 --> 00:00:29,316
AVSpeechSynthesis?


9
00:00:30,066 --> 00:00:31,296
Let's talk about some of the


10
00:00:31,296 --> 00:00:31,876
basics.


11
00:00:32,456 --> 00:00:33,416
We'll talk about choosing the


12
00:00:33,416 --> 00:00:35,566
right voice, some properties


13
00:00:35,566 --> 00:00:36,886
that are available like rate,


14
00:00:36,886 --> 00:00:38,416
pitch, and volume, and finally


15
00:00:38,416 --> 00:00:39,376
attributed strings.


16
00:00:41,256 --> 00:00:44,126
AVSpeechSynthesis is an API for


17
00:00:44,126 --> 00:00:45,836
generating computer synthesized


18
00:00:45,836 --> 00:00:47,776
speech on your iOS devices.


19
00:00:48,216 --> 00:00:49,156
It has many uses.


20
00:00:49,866 --> 00:00:51,446
For example, you might want to


21
00:00:51,446 --> 00:00:52,556
post announcements within your


22
00:00:52,556 --> 00:00:52,786
app.


23
00:00:53,696 --> 00:00:54,566
You might be creating an


24
00:00:54,566 --> 00:00:56,266
interface that's not meant to be


25
00:00:56,266 --> 00:00:56,826
looked at.


26
00:00:57,466 --> 00:00:58,886
Or you might be creating an


27
00:00:58,886 --> 00:01:00,306
education app where having


28
00:01:00,306 --> 00:01:02,246
synthesized speech provides a


29
00:01:02,246 --> 00:01:03,596
good reinforcement for learning


30
00:01:03,596 --> 00:01:04,215
materials.


31
00:01:05,546 --> 00:01:07,236
One example, providing audio


32
00:01:07,236 --> 00:01:08,866
updates during a workout can be


33
00:01:08,866 --> 00:01:10,596
communicated effectively using


34
00:01:10,596 --> 00:01:11,496
synthesized speech.


35
00:01:12,846 --> 00:01:15,996
A note about synthesis and


36
00:01:16,086 --> 00:01:17,026
accessibility.


37
00:01:17,666 --> 00:01:19,286
So speech synthesis is a


38
00:01:19,286 --> 00:01:20,816
powerful tool for helping many


39
00:01:20,816 --> 00:01:22,586
users with many disabilities.


40
00:01:22,586 --> 00:01:23,956
For example, cognitive users can


41
00:01:23,956 --> 00:01:25,806
get reinforcement about the


42
00:01:25,806 --> 00:01:27,336
output that they are


43
00:01:27,336 --> 00:01:28,046
experiencing.


44
00:01:28,556 --> 00:01:29,776
Users who have trouble


45
00:01:29,776 --> 00:01:31,386
vocalizing speech can use


46
00:01:31,386 --> 00:01:33,046
synthesis to generate speech for


47
00:01:33,046 --> 00:01:33,336
them.


48
00:01:33,906 --> 00:01:36,206
Non-sighted users use speech


49
00:01:36,206 --> 00:01:37,566
synthesis to consume their


50
00:01:37,566 --> 00:01:38,336
interfaces.


51
00:01:39,666 --> 00:01:41,076
However, it's important to note


52
00:01:41,076 --> 00:01:42,376
that it is not a replacement for


53
00:01:42,376 --> 00:01:43,946
VoiceOver or other screen reader


54
00:01:43,946 --> 00:01:44,736
technologies.


55
00:01:44,946 --> 00:01:46,656
For example, speech can overlap


56
00:01:46,656 --> 00:01:47,796
with what VoiceOver is speaking


57
00:01:47,796 --> 00:01:48,576
at the same time.


58
00:01:49,446 --> 00:01:50,846
And most of the speech won't be


59
00:01:50,846 --> 00:01:52,626
available to any devices that


60
00:01:52,626 --> 00:01:53,926
are connected such as a Braille


61
00:01:53,926 --> 00:01:54,366
device.


62
00:01:55,886 --> 00:01:56,816
Instead, you should make your


63
00:01:56,816 --> 00:01:58,026
app accessible using the


64
00:01:58,026 --> 00:02:01,876
UIAccessibility API.


65
00:02:02,076 --> 00:02:03,206
Okay. So let's get to the


66
00:02:03,206 --> 00:02:03,736
basics.


67
00:02:04,066 --> 00:02:05,216
First step, create an


68
00:02:05,216 --> 00:02:06,426
AVSpeechSynthesizer.


69
00:02:06,816 --> 00:02:07,926
You can use that with this code


70
00:02:07,926 --> 00:02:08,306
snippet.


71
00:02:08,735 --> 00:02:10,356
One thing to note is that you


72
00:02:10,356 --> 00:02:11,276
want to make sure that it's


73
00:02:11,276 --> 00:02:12,876
retained until speech is done.


74
00:02:13,486 --> 00:02:14,836
If the synthesizer goes out of


75
00:02:14,836 --> 00:02:16,786
scope, any synthesis in-flight


76
00:02:16,786 --> 00:02:17,456
will be canceled.


77
00:02:18,116 --> 00:02:20,296
Now that we've created a


78
00:02:20,296 --> 00:02:21,606
synthesis, the next job is to


79
00:02:21,606 --> 00:02:22,576
create an utterance.


80
00:02:23,296 --> 00:02:24,566
We can then dispatch that to the


81
00:02:24,566 --> 00:02:25,236
synthesizer.


82
00:02:26,416 --> 00:02:28,016
So, in this example, we create


83
00:02:28,016 --> 00:02:28,926
an utterance with the string


84
00:02:28,926 --> 00:02:30,816
hello and then we dispatch it


85
00:02:31,406 --> 00:02:32,406
using the speak method.


86
00:02:35,186 --> 00:02:36,486
A note about audio sessions.


87
00:02:36,956 --> 00:02:39,416
So when AVSpeechSynthesis is


88
00:02:39,416 --> 00:02:41,496
activated using speak, the audio


89
00:02:41,496 --> 00:02:43,106
session will automatically set


90
00:02:43,106 --> 00:02:43,546
to active.


91
00:02:44,526 --> 00:02:45,706
If you want to mix with other


92
00:02:45,706 --> 00:02:47,256
audio, you can use the


93
00:02:47,256 --> 00:02:48,966
setCategory with options on your


94
00:02:48,966 --> 00:02:50,976
shared AVAudioSession mixed with


95
00:02:50,976 --> 00:02:51,356
others.


96
00:02:52,086 --> 00:02:53,266
If you wanted to duck other


97
00:02:53,266 --> 00:02:55,816
audio so that your speech is


98
00:02:55,936 --> 00:02:57,576
primary but then other audio


99
00:02:57,576 --> 00:02:59,276
becomes lower in volume, you can


100
00:02:59,276 --> 00:03:01,086
use the duckOthers option.


101
00:03:02,506 --> 00:03:04,436
Another note is that the audio


102
00:03:04,436 --> 00:03:05,706
session will not be set to


103
00:03:05,706 --> 00:03:07,436
inactive after speech is done.


104
00:03:07,926 --> 00:03:10,146
That's because it's a shared


105
00:03:10,146 --> 00:03:12,026
session only so that if there is


106
00:03:12,026 --> 00:03:13,436
any other audio playing at the


107
00:03:13,436 --> 00:03:14,756
same time, we would not want to


108
00:03:14,756 --> 00:03:15,336
stop that.


109
00:03:15,726 --> 00:03:17,576
So if you want to set the audio


110
00:03:17,576 --> 00:03:18,826
session to inactive, you would


111
00:03:18,826 --> 00:03:19,566
do that yourself.


112
00:03:20,766 --> 00:03:23,386
There are some callback methods


113
00:03:23,386 --> 00:03:24,736
available in AVSpeechSynthesis


114
00:03:24,736 --> 00:03:26,386
that will help inform about the


115
00:03:26,386 --> 00:03:27,716
life cycle of an utterance.


116
00:03:28,566 --> 00:03:30,036
These are optional methods in


117
00:03:30,036 --> 00:03:31,016
the synthesizer delegate


118
00:03:31,016 --> 00:03:31,516
protocol.


119
00:03:32,116 --> 00:03:33,656
For example, you can know when


120
00:03:33,656 --> 00:03:36,116
speech starts, speech finishes,


121
00:03:36,606 --> 00:03:37,946
even the character ranges that


122
00:03:37,946 --> 00:03:38,746
will be spoken.


123
00:03:39,406 --> 00:03:40,506
You can also know when speech is


124
00:03:40,506 --> 00:03:41,676
paused or continued.


125
00:03:43,146 --> 00:03:45,426
So an example of this in code


126
00:03:45,426 --> 00:03:47,226
snippet form, you can set your


127
00:03:47,226 --> 00:03:49,036
synthesizer delegate to an


128
00:03:49,036 --> 00:03:50,586
object and then implement these


129
00:03:50,586 --> 00:03:51,926
methods, for example the


130
00:03:51,926 --> 00:03:53,506
didStart in which case you'll


131
00:03:53,506 --> 00:03:55,886
get the utterance back, the


132
00:03:55,886 --> 00:03:58,586
didFinish which will do the


133
00:03:58,586 --> 00:03:59,976
appropriate thing, and then the


134
00:03:59,976 --> 00:04:01,736
willSpeakRangeOfSpeechString


135
00:04:02,166 --> 00:04:03,186
which will give you back an


136
00:04:03,226 --> 00:04:04,636
NSRange which then you can


137
00:04:04,636 --> 00:04:06,966
convert into a string range to


138
00:04:06,966 --> 00:04:08,306
use that in your string.


139
00:04:11,436 --> 00:04:12,606
Now a little demo.


140
00:04:15,166 --> 00:04:17,046
>> Hello, my friends.


141
00:04:17,426 --> 00:04:18,976
I'm inside the iPhone.


142
00:04:22,906 --> 00:04:24,116
>> Great. Those are the basics


143
00:04:24,116 --> 00:04:26,226
of AVSpeechSynthesis and, as you


144
00:04:26,226 --> 00:04:27,796
can see, it's very simple to get


145
00:04:27,796 --> 00:04:28,386
off the ground.


146
00:04:29,246 --> 00:04:30,766
The next topic is how do you


147
00:04:30,766 --> 00:04:31,746
choose a right voice?


148
00:04:31,986 --> 00:04:33,236
There are many built-in voices,


149
00:04:33,236 --> 00:04:34,716
one for each supported language.


150
00:04:36,096 --> 00:04:37,516
Something to note is Siri voices


151
00:04:37,516 --> 00:04:39,146
are not available through this


152
00:04:39,146 --> 00:04:39,446
API.


153
00:04:40,726 --> 00:04:42,356
Users can, however, download


154
00:04:42,356 --> 00:04:43,766
higher-quality voices.


155
00:04:43,766 --> 00:04:44,716
And when those are downloaded,


156
00:04:44,716 --> 00:04:46,286
they will appear in the list of


157
00:04:46,286 --> 00:04:46,856
voices.


158
00:04:48,466 --> 00:04:50,846
So you can select a voice using


159
00:04:50,956 --> 00:04:52,176
either an identifier or a


160
00:04:52,176 --> 00:04:52,706
language.


161
00:04:53,246 --> 00:04:54,386
If you select a voice by


162
00:04:54,386 --> 00:04:55,486
language, it will select the


163
00:04:55,486 --> 00:04:56,606
user's default voice.


164
00:04:57,776 --> 00:04:58,736
So how do we do that?


165
00:04:59,166 --> 00:05:00,356
First you make your utterance


166
00:05:00,356 --> 00:05:01,406
and then you set the voice


167
00:05:01,406 --> 00:05:02,506
property using


168
00:05:02,506 --> 00:05:03,886
AVSpeechSynthesisVoice.


169
00:05:04,236 --> 00:05:07,286
As an example of using the


170
00:05:07,286 --> 00:05:09,296
identifier initializer, you


171
00:05:09,296 --> 00:05:10,896
could get all the speech voices


172
00:05:11,536 --> 00:05:13,266
which is an array of speech


173
00:05:13,266 --> 00:05:15,116
voice objects and then choose


174
00:05:15,116 --> 00:05:16,546
the first one, for example, and


175
00:05:16,546 --> 00:05:17,626
then pass in the identifier


176
00:05:17,626 --> 00:05:18,126
property.


177
00:05:19,996 --> 00:05:22,136
Here are some of the languages


178
00:05:22,256 --> 00:05:24,166
that are supported on iOS by


179
00:05:24,166 --> 00:05:24,476
default.


180
00:05:29,266 --> 00:05:30,136
Now let's talk about some of the


181
00:05:30,136 --> 00:05:31,096
properties that you can use on


182
00:05:31,096 --> 00:05:32,116
AVSpeechSynthesizer.


183
00:05:32,686 --> 00:05:34,096
Speech rate can be controlled


184
00:05:34,526 --> 00:05:36,336
using the rate property, and it


185
00:05:36,336 --> 00:05:37,406
goes from 0 to 1.


186
00:05:38,226 --> 00:05:40,856
Now this will scale speech to go


187
00:05:40,856 --> 00:05:42,496
slower or faster.


188
00:05:43,166 --> 00:05:44,626
Speech will be scaled from about


189
00:05:44,626 --> 00:05:47,686
0 to 1 with values from 0 to .5.


190
00:05:48,326 --> 00:05:50,206
So that means if you pass in .5,


191
00:05:50,516 --> 00:05:51,776
you will get the default normal


192
00:05:51,776 --> 00:05:52,396
speaking rate.


193
00:05:53,736 --> 00:05:55,606
If you want to go faster, you


194
00:05:55,606 --> 00:05:58,066
can pass in values from .5 to 1


195
00:05:58,066 --> 00:05:59,806
and that will scale speech from


196
00:05:59,806 --> 00:06:01,296
normal speaking rates at 1x all


197
00:06:01,296 --> 00:06:02,216
the way up to 4x.


198
00:06:03,096 --> 00:06:04,666
To do that, you can create a


199
00:06:04,666 --> 00:06:05,926
speech utterance and then set


200
00:06:05,926 --> 00:06:09,056
the rate to a float value or you


201
00:06:09,056 --> 00:06:10,366
can use some of these constants


202
00:06:10,666 --> 00:06:12,956
which are default rate maximum


203
00:06:12,956 --> 00:06:13,526
or minimum.


204
00:06:15,546 --> 00:06:16,496
Let's talk about pitch and


205
00:06:16,496 --> 00:06:16,836
volume.


206
00:06:17,396 --> 00:06:18,316
These are also properties you


207
00:06:18,316 --> 00:06:19,446
set on the speech utterance.


208
00:06:19,926 --> 00:06:21,386
Pitch controls how high the


209
00:06:21,386 --> 00:06:23,076
voice is or how low.


210
00:06:23,166 --> 00:06:25,046
Volume controls the volume of


211
00:06:25,046 --> 00:06:25,986
the voice itself.


212
00:06:27,166 --> 00:06:28,496
So, for example, we can set


213
00:06:28,496 --> 00:06:30,146
pitch to a very high pitch voice


214
00:06:30,666 --> 00:06:31,786
using a one value.


215
00:06:32,396 --> 00:06:33,706
We can set volume to a lower


216
00:06:33,706 --> 00:06:35,286
volume using .25.


217
00:06:35,986 --> 00:06:37,116
Note that lowering the speech


218
00:06:37,116 --> 00:06:38,086
volume does not affect the


219
00:06:38,086 --> 00:06:38,996
system volume.


220
00:06:42,176 --> 00:06:43,466
Finally, let's talk about


221
00:06:43,466 --> 00:06:44,616
attributed strings.


222
00:06:45,666 --> 00:06:46,936
Attributed strings allow us to


223
00:06:46,936 --> 00:06:48,716
customize how speech sounds


224
00:06:48,816 --> 00:06:49,866
using different attributes.


225
00:06:50,446 --> 00:06:52,136
One available attribute that I'd


226
00:06:52,136 --> 00:06:53,896
like to discuss is IPA notation.


227
00:06:54,296 --> 00:06:55,636
IPA stands for International


228
00:06:55,636 --> 00:06:58,256
Phonetic Alphabet, and it allows


229
00:06:58,256 --> 00:07:00,796
us to customize how specialized


230
00:07:00,796 --> 00:07:02,606
names, nouns, and other things


231
00:07:02,606 --> 00:07:03,266
are pronounced.


232
00:07:04,966 --> 00:07:06,116
It's available in these


233
00:07:06,116 --> 00:07:06,766
languages.


234
00:07:09,516 --> 00:07:10,886
And here is an example of what


235
00:07:10,886 --> 00:07:11,566
it might look like.


236
00:07:11,766 --> 00:07:13,676
To pronounce the iPhone in the


237
00:07:13,676 --> 00:07:15,286
way that we are used to, you


238
00:07:15,286 --> 00:07:16,836
would use this IPA notation.


239
00:07:18,176 --> 00:07:19,756
Now the obvious question is how


240
00:07:19,756 --> 00:07:20,806
do you generate this IPA


241
00:07:20,806 --> 00:07:21,406
notation?


242
00:07:21,406 --> 00:07:22,886
It is not easy to type with a


243
00:07:22,886 --> 00:07:23,346
keyboard.


244
00:07:24,076 --> 00:07:26,306
One way to do that is to use the


245
00:07:26,446 --> 00:07:28,126
pronunciation editor in


246
00:07:28,126 --> 00:07:29,306
accessibility settings.


247
00:07:29,816 --> 00:07:30,886
So when you go to the settings


248
00:07:30,886 --> 00:07:33,046
app, go into accessibility and


249
00:07:33,046 --> 00:07:33,836
speech, you will find


250
00:07:33,836 --> 00:07:35,376
pronunciations and find a screen


251
00:07:35,556 --> 00:07:36,056
like this.


252
00:07:36,746 --> 00:07:37,946
You can enter in the phrase that


253
00:07:37,946 --> 00:07:39,536
you want to find the correct


254
00:07:39,536 --> 00:07:41,066
pronunciation for, tap the


255
00:07:41,066 --> 00:07:42,666
microphone button, and then


256
00:07:42,666 --> 00:07:43,136
speak it.


257
00:07:44,246 --> 00:07:45,796
After you're done, you'll be


258
00:07:45,796 --> 00:07:47,516
presented with options on


259
00:07:47,516 --> 00:07:48,686
possible variations.


260
00:07:48,686 --> 00:07:50,346
As you tap those, it will say


261
00:07:50,346 --> 00:07:51,036
those out loud.


262
00:07:51,316 --> 00:07:52,106
You can choose the one that


263
00:07:52,106 --> 00:07:53,656
sounds correct and then copy


264
00:07:53,656 --> 00:07:55,876
this value that you get into


265
00:07:55,876 --> 00:07:56,366
your code.


266
00:07:57,006 --> 00:07:58,136
So let's see how that's done.


267
00:07:58,636 --> 00:08:00,966
First, we make an attributed


268
00:08:00,966 --> 00:08:03,836
string then we can add the


269
00:08:03,836 --> 00:08:05,026
attribute for the speech IPA


270
00:08:05,026 --> 00:08:07,236
notation using the value that we


271
00:08:07,236 --> 00:08:09,256
got from the settings.


272
00:08:10,996 --> 00:08:12,686
Finally, we can create a speech


273
00:08:12,686 --> 00:08:14,656
utterance with the attributed


274
00:08:16,886 --> 00:08:17,116
string.


275
00:08:17,246 --> 00:08:20,116
So in summary, AVSpeechSynthesis


276
00:08:20,116 --> 00:08:21,446
is a great way to augment your


277
00:08:21,446 --> 00:08:23,336
app experience if you add speech


278
00:08:23,336 --> 00:08:24,266
at the right time.


279
00:08:24,766 --> 00:08:26,476
Multiple languages and voices


280
00:08:26,476 --> 00:08:28,046
are available and can be


281
00:08:28,046 --> 00:08:29,126
dynamic.


282
00:08:29,936 --> 00:08:31,336
Finally, you can customize


283
00:08:31,336 --> 00:08:33,056
pronunciation for the way words


284
00:08:33,056 --> 00:08:34,696
sound using the IPA notation


285
00:08:34,696 --> 00:08:35,106
attribute.


286
00:08:38,356 --> 00:08:40,226
For more information, visit the


287
00:08:40,226 --> 00:08:43,046
session URL and thanks for


288
00:08:43,046 --> 00:08:43,366
watching.

