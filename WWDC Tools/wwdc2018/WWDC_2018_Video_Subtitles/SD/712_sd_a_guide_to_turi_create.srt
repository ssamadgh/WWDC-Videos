1
00:00:06,516 --> 00:00:15,500
[ Music ]


2
00:00:21,836 --> 00:00:23,076
>> [Applause] Hey, everyone.


3
00:00:25,266 --> 00:00:25,736
[Applause] Thank you.


4
00:00:25,736 --> 00:00:27,126
Good afternoon, and welcome to


5
00:00:27,126 --> 00:00:28,726
our session on Turi Create.


6
00:00:30,286 --> 00:00:31,676
This session builds upon


7
00:00:31,676 --> 00:00:33,236
yesterday's session on Create


8
00:00:33,236 --> 00:00:33,586
ML.


9
00:00:34,076 --> 00:00:35,316
That session covered many of the


10
00:00:35,316 --> 00:00:36,826
foundations of machine learning


11
00:00:36,826 --> 00:00:37,336
in Swift.


12
00:00:37,336 --> 00:00:38,596
So if you didn't catch that


13
00:00:38,596 --> 00:00:40,006
session I do recommend you add


14
00:00:40,006 --> 00:00:40,916
it to your watch list.


15
00:00:42,486 --> 00:00:44,396
The goal of Turi Create is to


16
00:00:44,396 --> 00:00:46,236
help you add intelligent user


17
00:00:46,236 --> 00:00:48,866
experiences to your apps.


18
00:00:49,516 --> 00:00:51,516
For example, you might want to


19
00:00:51,516 --> 00:00:52,606
be able to take a picture of


20
00:00:52,606 --> 00:00:53,266
your breakfast.


21
00:00:53,526 --> 00:00:54,916
And tap on the different food


22
00:00:54,916 --> 00:00:56,726
items to see how many calories


23
00:00:56,726 --> 00:00:57,386
you're consuming.


24
00:00:59,076 --> 00:01:01,136
Or maybe you want to control a


25
00:01:01,136 --> 00:01:03,496
lightbulb using your iPhone and


26
00:01:03,496 --> 00:01:04,486
simple gestures.


27
00:01:07,356 --> 00:01:08,736
Maybe you want to track an


28
00:01:08,736 --> 00:01:11,096
object in real time like a dog


29
00:01:11,156 --> 00:01:12,866
or a picture of a dog if you


30
00:01:12,866 --> 00:01:13,976
don't have dogs in the office.


31
00:01:14,516 --> 00:01:17,266
[ Laughter ]


32
00:01:17,766 --> 00:01:20,116
Maybe you have custom avatars in


33
00:01:20,116 --> 00:01:21,566
your game, and you want to


34
00:01:21,696 --> 00:01:22,516
provide personalized


35
00:01:22,516 --> 00:01:24,136
recommendations like hairstyles


36
00:01:24,496 --> 00:01:26,186
based on the beard that the user


37
00:01:26,186 --> 00:01:26,826
has selected.


38
00:01:28,216 --> 00:01:29,676
Or maybe you want to let your


39
00:01:29,676 --> 00:01:31,846
users apply artistic styles or


40
00:01:31,846 --> 00:01:33,756
filters to their own photos.


41
00:01:35,096 --> 00:01:37,056
These are very different user


42
00:01:37,056 --> 00:01:37,806
experiences.


43
00:01:38,256 --> 00:01:39,756
But they have several things in


44
00:01:39,756 --> 00:01:40,136
common.


45
00:01:41,046 --> 00:01:42,836
First and foremost, they use


46
00:01:42,836 --> 00:01:43,536
machine learning.


47
00:01:44,846 --> 00:01:46,556
These experiences all require


48
00:01:46,556 --> 00:01:49,906
very little data to create.


49
00:01:50,036 --> 00:01:51,516
All these models were made with


50
00:01:51,516 --> 00:01:53,646
Turi Create and deployed with


51
00:01:53,646 --> 00:01:54,186
Core ML.


52
00:01:55,656 --> 00:01:57,176
They all follow the five, the


53
00:01:57,176 --> 00:01:59,096
same five-step recipe that we'll


54
00:01:59,096 --> 00:02:00,226
go over today.


55
00:02:01,776 --> 00:02:02,906
And all these demo apps will


56
00:02:02,906 --> 00:02:04,366
also be available in our labs.


57
00:02:04,366 --> 00:02:06,056
So please join us today or


58
00:02:06,056 --> 00:02:08,326
Friday for the ML labs to get


59
00:02:08,326 --> 00:02:09,376
hands-on experience.


60
00:02:11,696 --> 00:02:14,026
Turi Create is a Python package


61
00:02:14,436 --> 00:02:15,846
that helps you create Core ML


62
00:02:15,846 --> 00:02:16,186
models.


63
00:02:17,436 --> 00:02:19,446
It's easy to use, so you don't


64
00:02:19,446 --> 00:02:20,816
need to be an ML expert or even


65
00:02:20,816 --> 00:02:22,066
have a background in machine


66
00:02:22,066 --> 00:02:23,326
learning to create these


67
00:02:23,326 --> 00:02:24,676
exciting user experiences.


68
00:02:25,626 --> 00:02:27,366
We make it easy to use by


69
00:02:27,366 --> 00:02:29,646
focusing on tasks first and


70
00:02:29,646 --> 00:02:30,206
foremost.


71
00:02:30,206 --> 00:02:31,576
What we do is we abstract away


72
00:02:31,576 --> 00:02:32,906
the complicated machine-learning


73
00:02:32,906 --> 00:02:34,776
algorithms so you can just focus


74
00:02:34,776 --> 00:02:35,866
on the user experience that


75
00:02:35,866 --> 00:02:36,746
you're trying to create.


76
00:02:38,056 --> 00:02:39,796
Turi Create is cross platform so


77
00:02:39,796 --> 00:02:41,836
you can use it both on Mac and


78
00:02:41,836 --> 00:02:42,226
Linux.


79
00:02:43,066 --> 00:02:44,436
And it's also open source.


80
00:02:45,726 --> 00:02:47,446
We have a repo on GitHub and we


81
00:02:47,446 --> 00:02:48,056
hope you'll visit.


82
00:02:48,056 --> 00:02:49,406
There's a lot of great resources


83
00:02:49,406 --> 00:02:50,186
to get started.


84
00:02:51,456 --> 00:02:52,786
And we look forward to working


85
00:02:52,786 --> 00:02:54,156
with you and the rest of the


86
00:02:54,156 --> 00:02:55,716
developer community to make Turi


87
00:02:55,716 --> 00:02:57,856
Create even better over time.


88
00:02:58,676 --> 00:03:00,276
Today we're excited to announce


89
00:03:00,276 --> 00:03:01,886
that the beta release of Turi


90
00:03:01,886 --> 00:03:04,216
Create 5.0 is now available.


91
00:03:04,986 --> 00:03:06,026
This has some powerful new


92
00:03:06,026 --> 00:03:06,576
features.


93
00:03:06,896 --> 00:03:08,336
Like GPU acceleration.


94
00:03:08,556 --> 00:03:09,846
And we'll go into these features


95
00:03:09,846 --> 00:03:11,396
in detail later on today.


96
00:03:12,776 --> 00:03:14,756
The main focus today is going to


97
00:03:14,756 --> 00:03:17,086
be the five-step recipe for


98
00:03:17,086 --> 00:03:18,366
creating Core ML models.


99
00:03:18,746 --> 00:03:20,306
I'm going to start by going over


100
00:03:20,306 --> 00:03:21,676
these steps at a high level.


101
00:03:22,086 --> 00:03:23,196
And then we'll dive into some


102
00:03:23,196 --> 00:03:24,486
demos and code.


103
00:03:25,026 --> 00:03:28,746
So the first step you need is to


104
00:03:28,746 --> 00:03:30,166
understand the task you're


105
00:03:30,166 --> 00:03:31,126
trying to accomplish.


106
00:03:31,566 --> 00:03:33,276
And how we refer to that task in


107
00:03:33,276 --> 00:03:34,316
machine learning terms.


108
00:03:35,686 --> 00:03:37,536
Second, you need to understand


109
00:03:37,866 --> 00:03:39,656
the type of data you need for


110
00:03:39,656 --> 00:03:40,616
this task.


111
00:03:41,026 --> 00:03:42,526
And how much of it.


112
00:03:43,696 --> 00:03:45,876
Third, you need to create your


113
00:03:45,876 --> 00:03:46,156
model.


114
00:03:48,056 --> 00:03:50,096
Fourth, you need to evaluate


115
00:03:50,096 --> 00:03:50,626
that model.


116
00:03:50,766 --> 00:03:52,066
That means understanding the


117
00:03:52,066 --> 00:03:53,536
quality of the model and wheth--


118
00:03:53,536 --> 00:03:54,416
whether it's ready for


119
00:03:54,416 --> 00:03:54,926
production.


120
00:03:56,106 --> 00:03:57,946
And finally, when your model's


121
00:03:57,946 --> 00:03:59,566
ready to deploy, it's really


122
00:03:59,566 --> 00:04:00,856
easy using Core ML.


123
00:04:02,356 --> 00:04:04,066
Let's dig a bit deeper into each


124
00:04:04,066 --> 00:04:04,786
of these steps.


125
00:04:06,076 --> 00:04:07,656
Turi Create lets you accomplish


126
00:04:07,656 --> 00:04:09,816
a wide variety of common machine


127
00:04:09,816 --> 00:04:10,566
learning tasks.


128
00:04:10,836 --> 00:04:11,976
And you can work with many


129
00:04:11,976 --> 00:04:13,306
different types of data.


130
00:04:13,926 --> 00:04:16,296
For example, if you have images,


131
00:04:16,616 --> 00:04:17,796
you might be interested in image


132
00:04:17,796 --> 00:04:18,646
classification.


133
00:04:18,805 --> 00:04:19,815
Or object detection.


134
00:04:20,856 --> 00:04:21,805
You might want to provide


135
00:04:21,805 --> 00:04:23,216
personalized recommendations for


136
00:04:23,216 --> 00:04:23,796
your users.


137
00:04:24,976 --> 00:04:25,876
You might want to be able to


138
00:04:25,876 --> 00:04:27,756
detect automatically activities


139
00:04:27,756 --> 00:04:30,226
like walking or jumping jacks.


140
00:04:30,416 --> 00:04:33,056
You might want to understand


141
00:04:33,056 --> 00:04:34,986
user sentiment given a block of


142
00:04:35,016 --> 00:04:35,426
text.


143
00:04:36,256 --> 00:04:37,606
Or you might be interested in


144
00:04:37,606 --> 00:04:39,006
more traditional machine


145
00:04:39,006 --> 00:04:40,306
learning algorithms like


146
00:04:40,306 --> 00:04:42,316
classification and regression.


147
00:04:44,636 --> 00:04:46,316
Now we know this can get really


148
00:04:46,316 --> 00:04:47,806
confusing to those of you who


149
00:04:47,806 --> 00:04:49,236
are new to machine learning.


150
00:04:49,696 --> 00:04:51,906
So we've taken a stab at making


151
00:04:51,906 --> 00:04:52,976
this really easy for you in our


152
00:04:52,976 --> 00:04:53,866
documentation.


153
00:04:54,266 --> 00:04:55,496
We begin by helping you


154
00:04:55,496 --> 00:04:56,986
understand the types of tasks


155
00:04:57,286 --> 00:04:59,156
that are possible and then how


156
00:04:59,156 --> 00:05:00,436
we reference them in machine


157
00:05:00,436 --> 00:05:01,176
learning terms.


158
00:05:01,716 --> 00:05:03,196
So what we can do now is revisit


159
00:05:03,196 --> 00:05:04,596
those intelligent experiences


160
00:05:04,596 --> 00:05:05,326
that we walked through at the


161
00:05:05,326 --> 00:05:06,606
beginning of this presentation


162
00:05:06,956 --> 00:05:08,176
and assign them to these machine


163
00:05:08,176 --> 00:05:09,026
learning tasks.


164
00:05:09,626 --> 00:05:10,856
For example, if you want to


165
00:05:10,856 --> 00:05:12,616
recognize different types of


166
00:05:12,616 --> 00:05:14,676
flowers in photos we call that


167
00:05:14,676 --> 00:05:15,826
image classification.


168
00:05:17,236 --> 00:05:19,136
If you want to take pictures of


169
00:05:19,406 --> 00:05:20,766
your breakfast and understand


170
00:05:20,766 --> 00:05:22,096
the different food objects


171
00:05:22,096 --> 00:05:24,066
within them, we call them, that


172
00:05:24,066 --> 00:05:24,876
object detection.


173
00:05:25,436 --> 00:05:27,986
If you want to apply artistic


174
00:05:27,986 --> 00:05:30,246
styles to your own photos, we


175
00:05:30,246 --> 00:05:31,546
call that style transfer.


176
00:05:33,606 --> 00:05:35,256
And if you want to recognize


177
00:05:35,356 --> 00:05:37,046
gestures or motions or different


178
00:05:37,046 --> 00:05:38,816
activities using sensors of


179
00:05:38,816 --> 00:05:40,556
different devices, we call that


180
00:05:40,556 --> 00:05:41,896
activity classification.


181
00:05:43,996 --> 00:05:45,616
Finally, if you want to make


182
00:05:45,656 --> 00:05:46,906
personalized recommendations to


183
00:05:46,906 --> 00:05:48,886
your users, we call this task


184
00:05:49,106 --> 00:05:50,086
recommender systems.


185
00:05:50,766 --> 00:05:53,936
Now the great thing is that the


186
00:05:53,936 --> 00:05:55,756
same five-step recipe we just


187
00:05:55,756 --> 00:05:57,596
walked through also applies to


188
00:05:57,596 --> 00:05:58,106
your code.


189
00:05:59,156 --> 00:06:00,786
We begin by importing Turi


190
00:06:00,786 --> 00:06:01,236
Create.


191
00:06:02,526 --> 00:06:04,796
We proceed to load our data into


192
00:06:04,796 --> 00:06:06,046
a data structure called an


193
00:06:06,046 --> 00:06:06,466
SFrame.


194
00:06:06,816 --> 00:06:07,796
And we'll go into a bit more


195
00:06:07,796 --> 00:06:09,156
detail on the SFrame data


196
00:06:09,156 --> 00:06:10,006
structure shortly.


197
00:06:10,486 --> 00:06:13,106
We'll proceed to create our


198
00:06:13,106 --> 00:06:14,736
model with a simple function,


199
00:06:14,816 --> 00:06:15,446
.create.


200
00:06:15,966 --> 00:06:18,116
This, this function extracts


201
00:06:18,116 --> 00:06:19,336
away the complicated machine


202
00:06:19,336 --> 00:06:22,066
learning behind the scenes.


203
00:06:22,956 --> 00:06:24,966
We proceed to evaluate our model


204
00:06:24,966 --> 00:06:25,956
with the simple function


205
00:06:26,176 --> 00:06:26,916
.evaluate.


206
00:06:27,476 --> 00:06:30,266
And finally we can export the


207
00:06:30,266 --> 00:06:32,586
resulting model to Core ML's


208
00:06:32,626 --> 00:06:34,396
ML-model format to be easily


209
00:06:34,396 --> 00:06:36,686
dragged and dropped into Xcode.


210
00:06:37,356 --> 00:06:39,226
Now I mentioned that this same


211
00:06:39,226 --> 00:06:41,166
five-step template applies to


212
00:06:41,166 --> 00:06:42,866
all the different tasks within


213
00:06:42,866 --> 00:06:43,506
Turi Create.


214
00:06:44,296 --> 00:06:45,146
So whether you're working on


215
00:06:45,146 --> 00:06:47,186
object detection, image


216
00:06:47,186 --> 00:06:49,716
classification or activity


217
00:06:49,716 --> 00:06:51,896
classification, the same code


218
00:06:51,896 --> 00:06:52,806
template applies.


219
00:06:52,806 --> 00:06:56,826
For our first demo today, we're


220
00:06:57,066 --> 00:06:58,016
going to walk through a


221
00:06:58,016 --> 00:06:59,846
calorie-counting app that uses


222
00:06:59,846 --> 00:07:01,196
an object detection model.


223
00:07:01,746 --> 00:07:02,866
So we'll want to recognize


224
00:07:03,186 --> 00:07:04,486
different foods within an image.


225
00:07:04,726 --> 00:07:05,636
And we'll need to know where


226
00:07:05,636 --> 00:07:07,046
those, where in the image those


227
00:07:07,046 --> 00:07:08,396
foods are so that we could tap


228
00:07:08,396 --> 00:07:09,346
on them to see the different


229
00:07:09,346 --> 00:07:10,000
calorie counts.


230
00:07:13,196 --> 00:07:14,636
So let's take a look at the type


231
00:07:14,636 --> 00:07:16,036
of data that we'll need to


232
00:07:16,036 --> 00:07:17,576
create this machine learning


233
00:07:17,576 --> 00:07:17,846
model.


234
00:07:18,436 --> 00:07:20,906
Of course we need images.


235
00:07:20,906 --> 00:07:21,866
And if we were just building a


236
00:07:21,866 --> 00:07:24,006
simple image classifier model,


237
00:07:24,306 --> 00:07:25,286
we would just need our set of


238
00:07:25,286 --> 00:07:27,316
images and labels that describe


239
00:07:27,316 --> 00:07:28,356
the images overall.


240
00:07:29,366 --> 00:07:30,506
But because we're performing


241
00:07:30,746 --> 00:07:32,506
object detection, we need a bit


242
00:07:32,506 --> 00:07:33,316
more information.


243
00:07:33,956 --> 00:07:35,416
We need to understand not just


244
00:07:35,416 --> 00:07:36,226
what's in the image.


245
00:07:36,496 --> 00:07:37,766
But where those objects are.


246
00:07:38,146 --> 00:07:40,126
Now if we zoom in a bit closer


247
00:07:40,126 --> 00:07:42,596
to one example, we see a red box


248
00:07:42,646 --> 00:07:43,756
around a cup of coffee.


249
00:07:44,616 --> 00:07:45,866
And a green box around a


250
00:07:45,866 --> 00:07:46,376
croissant.


251
00:07:47,336 --> 00:07:48,916
We call those boxes bounding


252
00:07:48,916 --> 00:07:50,996
boxes and we represent those in


253
00:07:50,996 --> 00:07:51,936
JSON format.


254
00:07:52,296 --> 00:07:53,806
With a label, and then with


255
00:07:53,806 --> 00:07:55,796
coordinates x, y, width and


256
00:07:55,796 --> 00:07:56,086
height.


257
00:07:56,656 --> 00:07:58,186
Where x and y refer to the


258
00:07:58,186 --> 00:07:59,926
center of that bounding box.


259
00:08:00,216 --> 00:08:01,426
So it's also worth noting that


260
00:08:01,426 --> 00:08:03,066
with object detection, you can


261
00:08:03,066 --> 00:08:05,196
reference or detect multiple


262
00:08:05,196 --> 00:08:07,486
images, multiple objects within


263
00:08:07,486 --> 00:08:07,996
each image.


264
00:08:07,996 --> 00:08:11,086
So I mentioned that we'd be


265
00:08:11,086 --> 00:08:12,816
loading our data into this


266
00:08:12,816 --> 00:08:14,246
tabular data structure called an


267
00:08:14,246 --> 00:08:14,686
SFrame.


268
00:08:15,406 --> 00:08:16,716
And in this example, we will end


269
00:08:16,716 --> 00:08:17,926
up with two columns.


270
00:08:18,136 --> 00:08:19,326
The first column will contain


271
00:08:19,326 --> 00:08:19,836
your images.


272
00:08:20,466 --> 00:08:22,086
The second column will contain


273
00:08:22,086 --> 00:08:24,000
your annotations in JSON format.


274
00:08:27,476 --> 00:08:29,306
Let's or by now you're probably


275
00:08:29,306 --> 00:08:30,886
wondering what is an SFrame?


276
00:08:30,886 --> 00:08:32,506
So let's take a step back and,


277
00:08:32,506 --> 00:08:34,706
and learn more about it.


278
00:08:34,706 --> 00:08:36,596
SFrame is a [inaudible] tabular


279
00:08:36,596 --> 00:08:37,376
data structure.


280
00:08:37,566 --> 00:08:39,006
And what this means is you can


281
00:08:39,395 --> 00:08:40,976
create machine learning models


282
00:08:40,976 --> 00:08:41,806
on your laptop.


283
00:08:41,966 --> 00:08:43,015
Even if you have enormous


284
00:08:43,015 --> 00:08:45,226
amounts of data.


285
00:08:45,366 --> 00:08:46,656
SFrame allows you to perform


286
00:08:46,656 --> 00:08:48,676
common data manipulation tasks.


287
00:08:49,026 --> 00:08:50,816
Like joining two SFrames or


288
00:08:50,816 --> 00:08:52,686
filtering to specific rows or


289
00:08:52,686 --> 00:08:53,476
columns of data.


290
00:08:55,296 --> 00:08:57,046
SFrames let you work with all


291
00:08:57,046 --> 00:08:57,976
different data types.


292
00:08:58,926 --> 00:08:59,986
And once you have your data


293
00:09:00,046 --> 00:09:02,486
loaded into an SFrame, it's easy


294
00:09:02,486 --> 00:09:04,446
to visually explore and inspect


295
00:09:04,446 --> 00:09:05,000
your data.


296
00:09:08,936 --> 00:09:10,426
Let's zoom in a bit more on


297
00:09:10,426 --> 00:09:11,796
what's possible with SFrame.


298
00:09:12,796 --> 00:09:13,946
With our object detector


299
00:09:13,946 --> 00:09:14,396
example.


300
00:09:15,446 --> 00:09:17,026
So after we import Turi Create,


301
00:09:17,426 --> 00:09:18,436
in the case of our object


302
00:09:18,436 --> 00:09:20,206
detector, we're actually going


303
00:09:20,276 --> 00:09:21,606
to load two different SFrames.


304
00:09:22,086 --> 00:09:23,406
The first containing our


305
00:09:23,406 --> 00:09:25,526
annotations, and the second


306
00:09:26,036 --> 00:09:27,166
containing our images.


307
00:09:27,896 --> 00:09:29,556
We have a simple function


308
00:09:29,556 --> 00:09:31,526
.explore that will allow you to


309
00:09:31,526 --> 00:09:32,806
visually inspect the data you've


310
00:09:32,806 --> 00:09:33,276
imported.


311
00:09:34,276 --> 00:09:35,876
We can do things like access


312
00:09:35,876 --> 00:09:36,896
specific rows.


313
00:09:37,386 --> 00:09:38,496
Or columns of our data.


314
00:09:39,866 --> 00:09:40,976
And of course we can do common


315
00:09:40,976 --> 00:09:43,266
operations like joining our two


316
00:09:43,266 --> 00:09:44,286
SFrames into one.


317
00:09:44,826 --> 00:09:46,546
And saving the resulting SFrame


318
00:09:46,986 --> 00:09:49,476
for later use or to share with a


319
00:09:51,176 --> 00:09:51,356
colleague.


320
00:09:51,486 --> 00:09:52,746
Next we create our model.


321
00:09:53,146 --> 00:09:54,306
So I mentioned we have this


322
00:09:54,396 --> 00:09:56,746
simple function .create that


323
00:09:56,746 --> 00:09:58,126
does all the heavy lifting for


324
00:09:58,126 --> 00:09:59,236
the creation of the actual


325
00:09:59,236 --> 00:09:59,576
model.


326
00:10:00,016 --> 00:10:01,486
And what we do behind the scenes


327
00:10:01,486 --> 00:10:03,026
is we ensure that the model we


328
00:10:03,026 --> 00:10:04,546
create for you is customized to


329
00:10:04,546 --> 00:10:06,076
the task and that it's state of


330
00:10:06,076 --> 00:10:06,496
the art.


331
00:10:06,496 --> 00:10:07,916
Meaning it's as high quality and


332
00:10:07,956 --> 00:10:10,016
high accuracy as we can get.


333
00:10:10,016 --> 00:10:11,206
And we're able to do this


334
00:10:11,206 --> 00:10:12,256
whether you have large amounts


335
00:10:12,256 --> 00:10:13,956
of data or small amounts of


336
00:10:13,956 --> 00:10:14,206
data.


337
00:10:14,516 --> 00:10:16,336
It's very important for us that


338
00:10:16,386 --> 00:10:17,926
all of our tasks work whether


339
00:10:17,926 --> 00:10:19,846
you have even a small amount of


340
00:10:19,846 --> 00:10:22,116
data as small as about 40 images


341
00:10:22,176 --> 00:10:23,266
per item that you're trying to


342
00:10:23,266 --> 00:10:24,676
detect in the class of object.


343
00:10:25,106 --> 00:10:26,276
In the case of object detection.


344
00:10:26,826 --> 00:10:30,866
Let's move on to evaluation.


345
00:10:31,236 --> 00:10:32,446
So I mentioned we have a simple


346
00:10:32,446 --> 00:10:34,936
function .evaluate that will


347
00:10:34,936 --> 00:10:36,566
give you an idea of the quality


348
00:10:36,566 --> 00:10:37,106
of your model.


349
00:10:38,216 --> 00:10:40,006
In the case of object detectors.


350
00:10:40,416 --> 00:10:42,086
We have two factors to consider.


351
00:10:42,406 --> 00:10:43,846
First, we want to know did we


352
00:10:43,846 --> 00:10:44,766
get the label right?


353
00:10:45,386 --> 00:10:46,966
But we also have to know if we


354
00:10:46,966 --> 00:10:48,306
got that bounding box right


355
00:10:48,666 --> 00:10:49,476
around the object.


356
00:10:50,616 --> 00:10:51,876
So we can establish a simple


357
00:10:51,876 --> 00:10:53,846
metric with these two factors


358
00:10:53,846 --> 00:10:55,906
and go through a test data set


359
00:10:55,906 --> 00:10:57,696
scoring predictions against


360
00:10:57,696 --> 00:10:59,996
known what we call ground-truth


361
00:11:00,316 --> 00:11:00,616
data.


362
00:11:01,446 --> 00:11:02,726
And so we want to make sure that


363
00:11:02,726 --> 00:11:04,026
we have correct labels.


364
00:11:04,506 --> 00:11:07,046
And then a standard metric is at


365
00:11:07,046 --> 00:11:08,906
least 50% overlap in the


366
00:11:08,906 --> 00:11:10,616
predicted bounding box when


367
00:11:10,616 --> 00:11:11,296
compared with to the


368
00:11:11,296 --> 00:11:12,756
ground-truth bounding box.


369
00:11:13,206 --> 00:11:14,676
Let's look at a few examples.


370
00:11:15,236 --> 00:11:18,296
In this prediction we see that


371
00:11:18,296 --> 00:11:19,806
the model got the label right


372
00:11:20,336 --> 00:11:21,316
with a cup of coffee.


373
00:11:21,906 --> 00:11:23,316
But that bounding box is not


374
00:11:23,316 --> 00:11:24,676
really covering the whole cup of


375
00:11:24,676 --> 00:11:25,016
coffee.


376
00:11:25,016 --> 00:11:26,066
It's only about ten percent


377
00:11:26,066 --> 00:11:27,286
overlapping the ground truth.


378
00:11:27,726 --> 00:11:29,256
So we're going to consider that


379
00:11:29,666 --> 00:11:31,676
a bad prediction.


380
00:11:31,676 --> 00:11:33,136
Here we see a highly accurate


381
00:11:33,136 --> 00:11:35,106
bounding box, but we got the


382
00:11:35,106 --> 00:11:35,816
label wrong.


383
00:11:35,896 --> 00:11:36,786
That's not a banana.


384
00:11:37,206 --> 00:11:38,706
So let's not consider that a


385
00:11:38,706 --> 00:11:39,896
successful prediction either.


386
00:11:41,006 --> 00:11:42,236
Now this middle example's what


387
00:11:42,236 --> 00:11:42,866
we want to see.


388
00:11:43,336 --> 00:11:44,906
We have 70% overlap of our


389
00:11:44,906 --> 00:11:46,836
bounding box, and the correct


390
00:11:46,836 --> 00:11:47,896
label, coffee.


391
00:11:48,796 --> 00:11:49,776
So what we can do is


392
00:11:49,776 --> 00:11:51,416
systematically go through all of


393
00:11:51,416 --> 00:11:52,806
our predictions with a test data


394
00:11:52,806 --> 00:11:53,066
set.


395
00:11:53,656 --> 00:11:55,026
And get an overall accuracy


396
00:11:55,026 --> 00:11:56,806
score for a new model.


397
00:11:57,356 --> 00:12:00,676
And finally, we move to


398
00:12:00,676 --> 00:12:01,196
deployment.


399
00:12:01,896 --> 00:12:03,146
We have an export to Core ML


400
00:12:03,146 --> 00:12:04,556
function that saves your model


401
00:12:04,626 --> 00:12:06,386
to Core ML's ML model format.


402
00:12:06,816 --> 00:12:08,056
So you can then drag and drop


403
00:12:08,056 --> 00:12:09,486
that model in to Xcode.


404
00:12:10,696 --> 00:12:12,046
This week we've actually some


405
00:12:12,046 --> 00:12:13,806
exciting new features related to


406
00:12:13,806 --> 00:12:15,296
object detection specifically.


407
00:12:15,856 --> 00:12:16,876
So I encourage you to attend


408
00:12:16,876 --> 00:12:18,716
tomorrow's Vision with Core ML


409
00:12:18,716 --> 00:12:20,506
session to learn more.


410
00:12:20,876 --> 00:12:21,886
In that session, the speaker


411
00:12:21,886 --> 00:12:23,076
will actually take the object


412
00:12:23,076 --> 00:12:24,036
detection model that we're


413
00:12:24,036 --> 00:12:26,146
building today and go into more


414
00:12:26,146 --> 00:12:27,706
detail about deployment options.


415
00:12:28,316 --> 00:12:30,996
And there you have it!


416
00:12:31,536 --> 00:12:33,486
The five-step recipe for Turi


417
00:12:33,486 --> 00:12:33,826
Create.


418
00:12:35,516 --> 00:12:38,946
[ Applause ]


419
00:12:39,446 --> 00:12:40,036
Thank you.


420
00:12:40,316 --> 00:12:41,256
So with that, I'm going to hand


421
00:12:41,256 --> 00:12:42,896
off to my colleague Zach Nation,


422
00:12:42,896 --> 00:12:43,426
for a demo.


423
00:12:45,516 --> 00:12:50,436
[ Applause ]


424
00:12:50,936 --> 00:12:51,536
>> Thanks, Aaron.


425
00:12:52,466 --> 00:12:54,126
I think let's just jump straight


426
00:12:54,126 --> 00:12:54,616
into code.


427
00:12:54,616 --> 00:12:55,616
Who wants to write some code


428
00:12:55,616 --> 00:12:56,516
live today?


429
00:12:56,946 --> 00:12:58,096
We're going to go ahead and


430
00:12:58,096 --> 00:12:59,496
build an object detector model


431
00:12:59,496 --> 00:13:00,000
right now.


432
00:13:10,046 --> 00:13:11,416
So I'm going to start out in


433
00:13:11,416 --> 00:13:11,956
Finder.


434
00:13:12,336 --> 00:13:14,216
Here I've got a folder of images


435
00:13:14,596 --> 00:13:15,906
that I want to use to train a


436
00:13:15,906 --> 00:13:16,266
model.


437
00:13:17,206 --> 00:13:18,546
We can see this folder's named


438
00:13:18,546 --> 00:13:21,476
Data, and it's full of images of


439
00:13:21,506 --> 00:13:22,296
breakfast foods.


440
00:13:22,786 --> 00:13:25,046
I've got a croissant, some eggs,


441
00:13:25,396 --> 00:13:25,936
and so on.


442
00:13:26,516 --> 00:13:29,006
This is, this is a good data set


443
00:13:29,006 --> 00:13:29,736
for breakfast food.


444
00:13:29,736 --> 00:13:31,086
I think let's go ahead and write


445
00:13:31,086 --> 00:13:31,746
some code with it.


446
00:13:33,016 --> 00:13:34,806
I'm going to switch over to an


447
00:13:34,806 --> 00:13:35,986
environment called Jupyter


448
00:13:35,986 --> 00:13:36,466
notebook.


449
00:13:37,096 --> 00:13:38,546
This is an interactive Python


450
00:13:38,546 --> 00:13:40,576
environment where you can run


451
00:13:40,576 --> 00:13:42,026
snippets of Python code and


452
00:13:42,026 --> 00:13:43,256
immediately see the output.


453
00:13:43,526 --> 00:13:45,126
So this is a great way to


454
00:13:45,126 --> 00:13:46,526
interactively work with a model.


455
00:13:46,776 --> 00:13:48,616
And it's very similar in concept


456
00:13:48,816 --> 00:13:50,066
to Xcode Playgrounds.


457
00:13:51,056 --> 00:13:52,116
The first thing we're going to


458
00:13:52,116 --> 00:13:55,996
do is import Turi Create as TC.


459
00:13:56,396 --> 00:14:00,376
And that we way we can refer to


460
00:14:00,376 --> 00:14:01,946
it as TC throughout the rest of


461
00:14:01,946 --> 00:14:02,416
the script.


462
00:14:03,576 --> 00:14:05,326
Now, the first task we want to


463
00:14:06,166 --> 00:14:07,336
do is load data.


464
00:14:07,916 --> 00:14:12,086
And we're going to load it up


465
00:14:12,086 --> 00:14:13,356
into SFrame format.


466
00:14:14,256 --> 00:14:15,846
So first we can say images


467
00:14:15,846 --> 00:14:18,046
equals TC.loadimages.


468
00:14:18,536 --> 00:14:19,386
And we're going to give it that


469
00:14:19,386 --> 00:14:21,216
folder day that I just showed in


470
00:14:21,216 --> 00:14:21,616
Finder.


471
00:14:22,166 --> 00:14:26,476
And Turi Create provides


472
00:14:26,476 --> 00:14:28,206
utilities to interactively


473
00:14:28,206 --> 00:14:29,766
explore and visualize our data.


474
00:14:30,006 --> 00:14:31,346
So let's make sure those images


475
00:14:31,346 --> 00:14:32,866
loaded correctly and we got the


476
00:14:32,866 --> 00:14:34,016
resulting SFrame that we


477
00:14:34,016 --> 00:14:34,496
expected.


478
00:14:35,216 --> 00:14:36,696
I'm just going to call .explore,


479
00:14:37,456 --> 00:14:38,826
and this is going to open up a


480
00:14:38,826 --> 00:14:40,346
visualization window where we


481
00:14:40,346 --> 00:14:41,976
can see that we have two columns


482
00:14:41,976 --> 00:14:42,696
in our SFrame.


483
00:14:43,166 --> 00:14:44,746
The first is called path, and


484
00:14:44,746 --> 00:14:46,256
it's the relative path to that


485
00:14:46,256 --> 00:14:47,106
image on disk.


486
00:14:47,536 --> 00:14:48,816
And the second column is called


487
00:14:48,816 --> 00:14:49,296
image.


488
00:14:49,566 --> 00:14:50,876
And that's actually the contents


489
00:14:50,876 --> 00:14:51,866
of the image itself.


490
00:14:52,096 --> 00:14:53,166
And we can see our breakfast


491
00:14:53,206 --> 00:14:53,906
foods right here.


492
00:14:54,676 --> 00:14:55,586
It looks like these loaded


493
00:14:55,586 --> 00:14:56,956
correctly, so I'm going to


494
00:14:56,956 --> 00:14:57,356
proceed.


495
00:14:57,906 --> 00:15:01,026
Back in Jupyter notebook.


496
00:15:01,416 --> 00:15:02,786
Now I'm also going to load up a


497
00:15:02,786 --> 00:15:04,196
second SFrame called


498
00:15:04,196 --> 00:15:04,996
annotations.


499
00:15:05,536 --> 00:15:09,416
And this I'm just going to call


500
00:15:09,416 --> 00:15:11,066
the SFrame instructor and


501
00:15:11,066 --> 00:15:12,346
provide a file name to


502
00:15:12,346 --> 00:15:13,896
annotations.csv.


503
00:15:14,326 --> 00:15:16,286
This is a CSV file containing


504
00:15:16,286 --> 00:15:17,776
the annotations that correspond


505
00:15:17,776 --> 00:15:18,546
to those images.


506
00:15:19,236 --> 00:15:23,256
And let's take a look at that.


507
00:15:23,876 --> 00:15:25,206
Right in Jupyter notebook, we


508
00:15:25,206 --> 00:15:26,296
can see that this SFrame


509
00:15:26,296 --> 00:15:28,146
contains a path column, again


510
00:15:28,146 --> 00:15:29,476
pointing to that relative path


511
00:15:29,476 --> 00:15:30,706
on disk of the image.


512
00:15:31,206 --> 00:15:32,926
And an annotation column


513
00:15:33,156 --> 00:15:34,606
containing a JSON object


514
00:15:34,806 --> 00:15:36,326
describing the bounding box and


515
00:15:36,326 --> 00:15:37,966
labels associated with that


516
00:15:37,966 --> 00:15:38,366
image.


517
00:15:39,806 --> 00:15:40,866
But now we have two different


518
00:15:40,866 --> 00:15:42,636
data sources and we need to


519
00:15:42,826 --> 00:15:44,286
provide one data source to train


520
00:15:44,286 --> 00:15:44,776
our model.


521
00:15:45,316 --> 00:15:46,406
Let's join them together.


522
00:15:47,096 --> 00:15:48,986
In Turi Create, this is as easy


523
00:15:48,986 --> 00:15:50,186
as calling the join method.


524
00:15:50,616 --> 00:15:52,626
I'm going to say data equals


525
00:15:52,956 --> 00:15:57,946
images.joinannotations and now


526
00:15:58,066 --> 00:15:59,916
we can see we have a single


527
00:16:00,036 --> 00:16:01,656
SFrame with three columns.


528
00:16:02,216 --> 00:16:03,766
It joined on that path column.


529
00:16:04,016 --> 00:16:05,956
So for each image with a path,


530
00:16:06,206 --> 00:16:07,766
it combined the annotations for


531
00:16:07,766 --> 00:16:08,246
that path.


532
00:16:09,006 --> 00:16:10,566
And so now for each image, we


533
00:16:10,566 --> 00:16:11,806
have annotations available.


534
00:16:12,656 --> 00:16:13,486
Now we're ready to train a


535
00:16:13,486 --> 00:16:13,786
model.


536
00:16:14,386 --> 00:16:17,936
So I'm going to create a new


537
00:16:17,936 --> 00:16:20,396
section here called train a


538
00:16:20,396 --> 00:16:20,716
model.


539
00:16:23,406 --> 00:16:26,006
And that's just one line of code


540
00:16:26,006 --> 00:16:26,276
here.


541
00:16:26,276 --> 00:16:28,096
I'm going to say model equals


542
00:16:28,426 --> 00:16:30,606
TC.objectdetector.create.


543
00:16:30,936 --> 00:16:31,896
And this is our simple


544
00:16:31,896 --> 00:16:33,636
task-focused API for object


545
00:16:33,636 --> 00:16:35,166
detection that expects data in


546
00:16:35,166 --> 00:16:35,696
this format.


547
00:16:36,476 --> 00:16:37,906
I'm going to pass in that data


548
00:16:37,906 --> 00:16:39,226
SFrame that I just created.


549
00:16:39,686 --> 00:16:41,126
And for the purposes of today's


550
00:16:41,126 --> 00:16:42,816
demo, I'm going to pass another


551
00:16:42,816 --> 00:16:44,686
parameter called max iterations


552
00:16:45,136 --> 00:16:46,706
and normally you wouldn't need


553
00:16:46,706 --> 00:16:48,046
to pass this parameter because


554
00:16:48,086 --> 00:16:49,366
Turi Create will pick the


555
00:16:49,366 --> 00:16:50,846
correct number of iterations for


556
00:16:50,846 --> 00:16:51,076
you.


557
00:16:51,226 --> 00:16:52,206
Based on the data that you


558
00:16:52,206 --> 00:16:52,676
provide.


559
00:16:53,456 --> 00:16:54,916
In this case, I'm going to say


560
00:16:54,916 --> 00:16:56,876
max iterations equals one just


561
00:16:56,876 --> 00:16:58,216
to give an example of what


562
00:16:58,216 --> 00:16:59,076
training would look like.


563
00:16:59,886 --> 00:17:01,216
And the reason this is going to


564
00:17:01,216 --> 00:17:02,556
take a minute is it actually


565
00:17:02,556 --> 00:17:03,856
goes through and resizes all of


566
00:17:03,856 --> 00:17:05,445
those images in order to get


567
00:17:05,445 --> 00:17:06,856
them ready to run through the


568
00:17:06,856 --> 00:17:07,435
neural network.


569
00:17:07,435 --> 00:17:08,836
That is under the hood of this


570
00:17:08,836 --> 00:17:09,665
object detector.


571
00:17:10,465 --> 00:17:12,036
And then it will perform just


572
00:17:12,036 --> 00:17:14,856
one iteration on this Mac GPO.


573
00:17:16,116 --> 00:17:17,965
But this is probably not the


574
00:17:17,965 --> 00:17:19,435
best model we could get because


575
00:17:19,435 --> 00:17:20,496
I just wanted to train it in a


576
00:17:20,496 --> 00:17:21,306
couple of seconds.


577
00:17:21,656 --> 00:17:22,906
So I'm going to go ahead and


578
00:17:22,906 --> 00:17:24,685
switch over to like cooking show


579
00:17:24,685 --> 00:17:25,016
mode.


580
00:17:25,056 --> 00:17:26,406
And I'm going to take one out of


581
00:17:26,406 --> 00:17:27,445
the oven that we've had in there


582
00:17:27,445 --> 00:17:28,036
for an hour [laughter].


583
00:17:28,726 --> 00:17:30,826
[Applause] So I'm going to say


584
00:17:30,826 --> 00:17:34,676
TC.loadmodel and it's called


585
00:17:34,796 --> 00:17:36,696
breakfastmodel.model.


586
00:17:36,696 --> 00:17:39,546
And this is one that I've had an


587
00:17:39,546 --> 00:17:40,896
opportunity to train for a bit


588
00:17:40,896 --> 00:17:41,316
longer.


589
00:17:41,806 --> 00:17:43,466
So let's inspect that right here


590
00:17:43,466 --> 00:17:44,026
in the notebook.


591
00:17:44,266 --> 00:17:45,396
And we can see that it's an


592
00:17:45,396 --> 00:17:46,576
object detector model.


593
00:17:47,226 --> 00:17:48,356
It's been trained on six


594
00:17:48,386 --> 00:17:50,336
classes, and we trained it for


595
00:17:50,336 --> 00:17:51,486
55 minutes.


596
00:17:52,026 --> 00:17:53,006
This is means, this means you


597
00:17:53,006 --> 00:17:54,296
can train a useful


598
00:17:54,296 --> 00:17:55,966
object-detector model in under


599
00:17:55,966 --> 00:17:58,000
an hour on your Mac.


600
00:18:01,096 --> 00:18:02,866
Next, let's test the predictions


601
00:18:02,866 --> 00:18:04,336
of this model and see if it's


602
00:18:04,336 --> 00:18:05,000
any good.


603
00:18:11,046 --> 00:18:11,876
So I'm going to make a new


604
00:18:11,876 --> 00:18:13,096
section here called inspect


605
00:18:13,166 --> 00:18:13,676
predictions.


606
00:18:14,056 --> 00:18:15,506
And we're going to go ahead and


607
00:18:15,716 --> 00:18:17,436
load up a test data set.


608
00:18:18,026 --> 00:18:19,496
And here I've already prepared


609
00:18:19,496 --> 00:18:20,676
one in SFrame format.


610
00:18:20,676 --> 00:18:21,716
So I'm just going to load it,


611
00:18:22,436 --> 00:18:23,266
and I called it


612
00:18:23,266 --> 00:18:25,046
testbreakfastdata.sframe.


613
00:18:25,666 --> 00:18:26,606
There are two important


614
00:18:26,606 --> 00:18:28,756
properties of this test SFrame.


615
00:18:29,146 --> 00:18:31,126
One is that it contains the same


616
00:18:31,126 --> 00:18:33,256
types of images that the model


617
00:18:33,366 --> 00:18:34,316
would have trained on.


618
00:18:34,656 --> 00:18:36,216
But the second important


619
00:18:36,216 --> 00:18:37,756
property is the model has never


620
00:18:37,756 --> 00:18:39,266
seen these images before.


621
00:18:39,556 --> 00:18:41,136
So this is a good test for


622
00:18:41,136 --> 00:18:42,126
whether that model can


623
00:18:42,126 --> 00:18:44,176
generalize to users' real data.


624
00:18:44,756 --> 00:18:48,466
I'm going to make predictions


625
00:18:48,566 --> 00:18:50,176
from that whole test set by


626
00:18:50,176 --> 00:18:52,016
calling model.predict and


627
00:18:52,016 --> 00:18:54,196
providing that test SFrame.


628
00:18:54,396 --> 00:18:55,626
And we'll get a batch prediction


629
00:18:55,626 --> 00:18:56,546
for the whole SFrame.


630
00:18:57,096 --> 00:19:00,656
And that'll just take a few


631
00:19:00,656 --> 00:19:01,136
seconds.


632
00:19:01,996 --> 00:19:04,306
And then we're going to inspect.


633
00:19:04,516 --> 00:19:05,556
I'm just going to pick a random


634
00:19:05,556 --> 00:19:06,346
prediction here.


635
00:19:06,626 --> 00:19:08,856
Let's say index two.


636
00:19:09,606 --> 00:19:11,676
Here we can see the JSON object


637
00:19:11,676 --> 00:19:13,346
that was predicted in just the


638
00:19:13,346 --> 00:19:14,966
same format that the training


639
00:19:14,966 --> 00:19:16,106
data is provided in.


640
00:19:16,446 --> 00:19:18,316
So here we have coordinates,


641
00:19:18,486 --> 00:19:19,776
height, width, x and y.


642
00:19:20,056 --> 00:19:21,196
And a label, banana.


643
00:19:21,796 --> 00:19:23,116
And we get a confidence score


644
00:19:23,116 --> 00:19:23,816
from the model.


645
00:19:23,966 --> 00:19:25,876
In this case about .87.


646
00:19:26,886 --> 00:19:28,466
This is a little bit hard for me


647
00:19:28,466 --> 00:19:29,976
as a human to interpret though.


648
00:19:30,436 --> 00:19:32,516
I can't really tell if this


649
00:19:32,516 --> 00:19:33,786
image is really supposed to be a


650
00:19:33,786 --> 00:19:35,446
banana or whether these


651
00:19:35,446 --> 00:19:36,866
coordinates are where the banana


652
00:19:36,866 --> 00:19:38,526
would appear in that image.


653
00:19:39,686 --> 00:19:41,526
Turi Create produces a function


654
00:19:41,706 --> 00:19:42,996
to take the predicted bounding


655
00:19:42,996 --> 00:19:44,476
boxes or the ground-truth


656
00:19:44,476 --> 00:19:46,036
bounding boxes and draw them


657
00:19:46,066 --> 00:19:47,096
right onto the images.


658
00:19:47,576 --> 00:19:48,836
So let's go and do that.


659
00:19:49,516 --> 00:19:50,976
I'm going to create a new column


660
00:19:51,046 --> 00:19:52,846
in my test SFrame called


661
00:19:52,906 --> 00:19:53,856
predicted image.


662
00:19:54,936 --> 00:19:56,926
And I'm going to assign it the


663
00:19:56,926 --> 00:19:58,906
output of the object detector


664
00:19:58,906 --> 00:20:00,406
utility called draw bounding


665
00:20:00,406 --> 00:20:00,896
boxes.


666
00:20:01,756 --> 00:20:03,736
And I'm going to pass into draw


667
00:20:03,736 --> 00:20:06,536
bounding boxes that test image


668
00:20:06,536 --> 00:20:06,946
column.


669
00:20:07,016 --> 00:20:09,176
So that's the image itself and


670
00:20:09,176 --> 00:20:11,616
then I'm also going to pass the


671
00:20:11,616 --> 00:20:13,226
predictions that I just got from


672
00:20:13,226 --> 00:20:13,626
the model.


673
00:20:13,766 --> 00:20:15,616
That's going to draw those


674
00:20:15,656 --> 00:20:17,316
predicted bounding boxes onto


675
00:20:17,316 --> 00:20:18,126
each image.


676
00:20:18,656 --> 00:20:19,996
Now let's take a look at that


677
00:20:19,996 --> 00:20:21,286
number two prediction again.


678
00:20:21,566 --> 00:20:23,096
This time in image form.


679
00:20:24,676 --> 00:20:25,586
So I can say


680
00:20:25,586 --> 00:20:28,396
testpredictedimage2.show.


681
00:20:28,836 --> 00:20:30,296
And it will render right here in


682
00:20:30,296 --> 00:20:30,786
the notebook.


683
00:20:31,516 --> 00:20:38,016
[ Applause ]


684
00:20:38,516 --> 00:20:39,946
And this is great as a spot


685
00:20:39,946 --> 00:20:41,596
check because at least for one


686
00:20:41,596 --> 00:20:42,396
picture, we know that the


687
00:20:42,396 --> 00:20:43,146
model's working.


688
00:20:43,616 --> 00:20:44,706
But this doesn't tell us if


689
00:20:44,706 --> 00:20:45,996
it'll work for say the next


690
00:20:45,996 --> 00:20:47,786
50,000 images that we pass in.


691
00:20:48,636 --> 00:20:49,986
So for that, we're going to


692
00:20:49,986 --> 00:20:50,916
evaluate the model


693
00:20:50,976 --> 00:20:51,846
quantitatively.


694
00:20:52,446 --> 00:20:53,966
And I'm going to start a new


695
00:20:53,966 --> 00:20:55,106
section here in the notebook


696
00:20:55,106 --> 00:20:56,326
called evaluate the model.


697
00:20:56,426 --> 00:20:58,286
And what we're going to do is


698
00:20:58,286 --> 00:21:01,226
call model.evaluate and once


699
00:21:01,226 --> 00:21:02,436
again, I'm going to pass in just


700
00:21:02,436 --> 00:21:04,186
that whole test data set.


701
00:21:05,936 --> 00:21:08,096
Here the evaluation function is


702
00:21:08,096 --> 00:21:09,436
going to run the metric that


703
00:21:09,436 --> 00:21:11,526
Aaron described, testing whether


704
00:21:11,526 --> 00:21:12,546
the bounding boxes are


705
00:21:12,546 --> 00:21:14,556
overlapping at least 50% and


706
00:21:14,556 --> 00:21:15,586
have a correct label.


707
00:21:15,586 --> 00:21:17,226
And it's going to give us that


708
00:21:17,226 --> 00:21:18,756
result across each of the six


709
00:21:18,756 --> 00:21:19,926
classes that we trained on.


710
00:21:20,516 --> 00:21:22,036
So here we can see that our


711
00:21:22,356 --> 00:21:24,096
overlapping bounding boxes with


712
00:21:24,096 --> 00:21:25,636
the correct label are happening


713
00:21:25,736 --> 00:21:27,696
about 80% of the time for bagel.


714
00:21:28,106 --> 00:21:29,946
About 67% of the time for


715
00:21:29,946 --> 00:21:30,416
banana.


716
00:21:30,706 --> 00:21:31,276
And so on.


717
00:21:32,456 --> 00:21:34,016
That's pretty good, so I think


718
00:21:34,096 --> 00:21:35,616
let's, let's see if this model's


719
00:21:35,616 --> 00:21:36,966
actually going to work in a real


720
00:21:36,966 --> 00:21:37,226
app.


721
00:21:37,866 --> 00:21:39,526
I'm going to go ahead and call


722
00:21:39,806 --> 00:21:42,366
exportcoreml to create a Core ML


723
00:21:42,366 --> 00:21:43,806
model from the model we just


724
00:21:43,806 --> 00:21:44,076
trained.


725
00:21:44,226 --> 00:21:45,666
And I'm going to call it


726
00:21:45,666 --> 00:21:47,536
breakfastmodel.mlmodel.


727
00:21:47,826 --> 00:21:49,036
And then as soon as that's done


728
00:21:49,036 --> 00:21:50,546
training, I'm going to go ahead


729
00:21:50,546 --> 00:21:51,656
and open it in finder.


730
00:21:52,236 --> 00:21:55,206
Or sorry. As soon as that's done


731
00:21:55,206 --> 00:21:56,000
exporting.


732
00:22:00,046 --> 00:22:01,686
So here in finder, I've got my


733
00:22:01,686 --> 00:22:03,316
breakfastmodel.mlmodel.


734
00:22:03,316 --> 00:22:05,636
And when I open it in Xcode, I


735
00:22:05,636 --> 00:22:07,106
can see that it looks just like


736
00:22:07,106 --> 00:22:08,306
any Core ML model.


737
00:22:08,896 --> 00:22:12,176
It takes an input image, and as


738
00:22:12,176 --> 00:22:14,526
output we get confidence and


739
00:22:14,526 --> 00:22:15,206
coordinates.


740
00:22:15,616 --> 00:22:16,706
And that's going to tell us the


741
00:22:16,706 --> 00:22:18,336
predicted bounding box and label


742
00:22:18,336 --> 00:22:19,436
for the image that we have.


743
00:22:20,376 --> 00:22:22,206
Now let's switch over to the


744
00:22:22,246 --> 00:22:23,646
iPhone app where we're going to


745
00:22:23,646 --> 00:22:24,616
consume this model.


746
00:22:25,186 --> 00:22:30,306
So here on my iPhone, I've got


747
00:22:30,306 --> 00:22:31,716
an app called Food Predictor.


748
00:22:32,356 --> 00:22:33,336
And this is going to use the


749
00:22:33,336 --> 00:22:34,456
model that we just trained.


750
00:22:35,356 --> 00:22:36,646
Here I'm going to choose from


751
00:22:36,646 --> 00:22:37,096
photos.


752
00:22:37,416 --> 00:22:39,026
And I've got a picture of this


753
00:22:39,026 --> 00:22:40,036
morning's breakfast.


754
00:22:40,546 --> 00:22:41,506
This is a pretty typical


755
00:22:41,506 --> 00:22:42,916
breakfast for me: coffee and a


756
00:22:42,916 --> 00:22:43,326
banana.


757
00:22:43,796 --> 00:22:45,546
Well, often I skip the banana.


758
00:22:46,316 --> 00:22:48,856
But suppose I ate a banana this


759
00:22:48,856 --> 00:22:49,346
morning.


760
00:22:50,456 --> 00:22:53,316
We can just tap right on the


761
00:22:53,316 --> 00:22:53,796
image.


762
00:22:53,796 --> 00:22:54,976
And because we know the bounding


763
00:22:54,976 --> 00:22:57,196
box, we can identify the object


764
00:22:57,196 --> 00:22:58,386
within that bounding box.


765
00:22:58,386 --> 00:22:59,716
And here we see the model tells


766
00:22:59,716 --> 00:23:02,296
us this is a banana, and this is


767
00:23:02,296 --> 00:23:02,976
a cup of coffee.


768
00:23:03,516 --> 00:23:09,500
[ Applause ]


769
00:23:16,136 --> 00:23:17,886
So let's recap what we just saw.


770
00:23:19,886 --> 00:23:21,756
First, we loaded images and


771
00:23:21,756 --> 00:23:23,896
annotations into SFrame format


772
00:23:24,146 --> 00:23:25,626
and joined them together with a


773
00:23:25,626 --> 00:23:26,556
simple function call.


774
00:23:27,296 --> 00:23:28,976
We interactively explored that


775
00:23:28,976 --> 00:23:30,786
data using the explore method.


776
00:23:31,826 --> 00:23:33,616
We created a model just with a


777
00:23:33,616 --> 00:23:35,606
simple high-level API< passing


778
00:23:35,606 --> 00:23:37,286
in that data object containing


779
00:23:37,286 --> 00:23:38,756
both the images and the bounding


780
00:23:38,756 --> 00:23:39,936
boxes and labels.


781
00:23:40,906 --> 00:23:42,676
We then evaluated that model


782
00:23:42,836 --> 00:23:43,956
both qualitatively,


783
00:23:44,026 --> 00:23:45,596
spot-checking the output as a


784
00:23:45,596 --> 00:23:46,176
human would.


785
00:23:46,556 --> 00:23:48,566
And quantitatively, asking for a


786
00:23:48,566 --> 00:23:50,486
specific metric that applies to


787
00:23:50,486 --> 00:23:51,526
the task that we're doing.


788
00:23:52,326 --> 00:23:54,206
Then we exported that model to


789
00:23:54,206 --> 00:23:56,886
Core ML format for use in an


790
00:23:58,366 --> 00:23:58,446
app.


791
00:23:58,726 --> 00:24:00,306
Next, I'd like to switch gears


792
00:24:00,576 --> 00:24:01,976
and talk about some exciting new


793
00:24:01,976 --> 00:24:04,836
features in Turi Create 5.0.


794
00:24:06,776 --> 00:24:09,806
Turi Create 5.0 has a new task


795
00:24:10,076 --> 00:24:11,186
called style transfer.


796
00:24:12,556 --> 00:24:13,716
We have major performance


797
00:24:13,716 --> 00:24:16,126
improvements from native GPU


798
00:24:16,126 --> 00:24:18,166
acceleration on your Mac.


799
00:24:19,016 --> 00:24:20,626
And we have new deployment


800
00:24:20,626 --> 00:24:22,516
options including recommender


801
00:24:22,516 --> 00:24:24,626
models for personalization and


802
00:24:24,676 --> 00:24:25,956
vision feature print-powered


803
00:24:25,956 --> 00:24:27,466
models so that you can reduce


804
00:24:27,466 --> 00:24:28,386
the size of your app.


805
00:24:28,676 --> 00:24:29,956
Taking advantage of models that


806
00:24:29,956 --> 00:24:30,986
are already in the operating


807
00:24:30,986 --> 00:24:31,386
system.


808
00:24:31,906 --> 00:24:34,696
Let's talk a little bit more


809
00:24:34,696 --> 00:24:36,176
about that style transfer task.


810
00:24:37,116 --> 00:24:39,186
Imagine we've got some style


811
00:24:39,186 --> 00:24:41,296
images and these are really cool


812
00:24:41,296 --> 00:24:43,836
looking recognizable stylistic


813
00:24:43,836 --> 00:24:44,376
images.


814
00:24:45,016 --> 00:24:46,826
Here we've got sort of a light


815
00:24:46,826 --> 00:24:48,156
honeycomb pattern and a very


816
00:24:48,156 --> 00:24:49,426
colorful flower pattern.


817
00:24:49,666 --> 00:24:51,406
And we want apply those as


818
00:24:51,406 --> 00:24:53,416
filters to our own images that


819
00:24:53,416 --> 00:24:54,246
we take with a camera.


820
00:24:54,836 --> 00:24:57,846
We've got a dog photo here and


821
00:24:57,896 --> 00:24:59,186
what it would look like to apply


822
00:24:59,186 --> 00:25:01,496
those styles to that dog is


823
00:25:01,496 --> 00:25:02,236
something like that.


824
00:25:02,586 --> 00:25:05,006
And with a style transfer model,


825
00:25:05,196 --> 00:25:06,956
we can take the same styles and


826
00:25:06,956 --> 00:25:08,296
apply them to more photos.


827
00:25:08,646 --> 00:25:10,246
Let's say a cat and another dog.


828
00:25:10,916 --> 00:25:12,046
And that's the sort of effect we


829
00:25:12,046 --> 00:25:13,000
would get.


830
00:25:16,046 --> 00:25:17,566
Here's an example of an app that


831
00:25:17,566 --> 00:25:19,646
uses style transfer for filters


832
00:25:19,816 --> 00:25:21,216
on photos that a user would


833
00:25:21,846 --> 00:25:21,946
take.


834
00:25:24,556 --> 00:25:26,526
The code to create the style


835
00:25:26,526 --> 00:25:28,386
transfer model follows the same


836
00:25:28,516 --> 00:25:30,466
five-step recipe as any other


837
00:25:30,466 --> 00:25:32,046
high-level task in Turi Create.


838
00:25:32,296 --> 00:25:33,956
So you can start by importing


839
00:25:33,956 --> 00:25:36,076
Turi Create, loading data into


840
00:25:36,076 --> 00:25:38,166
the SFrame format, creating the


841
00:25:38,166 --> 00:25:39,906
model with a simple high-level


842
00:25:39,906 --> 00:25:40,176
API.


843
00:25:41,326 --> 00:25:42,906
Then we make predictions, in


844
00:25:42,906 --> 00:25:44,166
this case with a function called


845
00:25:44,166 --> 00:25:46,186
stylize to take an image and


846
00:25:46,186 --> 00:25:47,536
apply that style filter.


847
00:25:48,166 --> 00:25:49,746
Finally, we can export it for


848
00:25:49,746 --> 00:25:51,576
deployment into Core ML format,


849
00:25:51,576 --> 00:25:52,726
just like any other model in


850
00:25:52,726 --> 00:25:53,000
Turi Create.


851
00:25:56,266 --> 00:25:57,506
So let's take a look at another


852
00:25:57,506 --> 00:25:57,926
demo.


853
00:25:58,146 --> 00:26:00,106
This time, we're going to build


854
00:26:00,106 --> 00:26:02,000
a style-transfer model.


855
00:26:14,476 --> 00:26:15,926
So switching back over to that


856
00:26:15,926 --> 00:26:17,196
Jupyter notebook environment.


857
00:26:17,546 --> 00:26:19,386
I'm going to start once again by


858
00:26:19,386 --> 00:26:23,476
importing Turi Create.


859
00:26:23,936 --> 00:26:25,000
As TC.


860
00:26:29,056 --> 00:26:30,556
Then, I'm going to load up two


861
00:26:30,556 --> 00:26:32,836
SFrames, each containing images.


862
00:26:33,276 --> 00:26:35,236
One, is the style images I'm


863
00:26:35,236 --> 00:26:36,766
going to call tc.loadimages, and


864
00:26:36,766 --> 00:26:37,766
I'm going to give it a directory


865
00:26:37,766 --> 00:26:38,416
name, styles.


866
00:26:39,106 --> 00:26:40,876
And then the other is content


867
00:26:40,876 --> 00:26:41,466
images.


868
00:26:42,956 --> 00:26:44,226
And the way that this works is


869
00:26:44,266 --> 00:26:46,106
the style images are the styles


870
00:26:46,106 --> 00:26:47,236
that you want to turn into


871
00:26:47,236 --> 00:26:48,376
filters you can apply.


872
00:26:48,376 --> 00:26:50,586
And the content images can be


873
00:26:50,686 --> 00:26:51,596
any images that are


874
00:26:51,596 --> 00:26:53,286
representative of the types of


875
00:26:53,286 --> 00:26:54,346
photograph that you would want


876
00:26:54,346 --> 00:26:55,836
to apply those filters to.


877
00:26:56,266 --> 00:26:57,596
So in this case, it's just a


878
00:26:57,596 --> 00:26:58,896
variety of photographs.


879
00:26:59,796 --> 00:27:01,776
We're going to load a folder


880
00:27:01,776 --> 00:27:03,546
called content into an SFrame


881
00:27:03,546 --> 00:27:04,146
for that one.


882
00:27:05,226 --> 00:27:06,786
And then we're ready to go ahead


883
00:27:06,786 --> 00:27:07,556
and train a model.


884
00:27:08,386 --> 00:27:10,276
So I'm going to say model equals


885
00:27:10,846 --> 00:27:13,366
tc.styletransfer.create.


886
00:27:13,786 --> 00:27:15,986
And I'm going to pass in style


887
00:27:16,226 --> 00:27:18,886
and content and that's all we


888
00:27:18,886 --> 00:27:19,116
need.


889
00:27:19,486 --> 00:27:21,096
But that's going to take a bit


890
00:27:21,096 --> 00:27:22,446
too long to train for today's


891
00:27:22,446 --> 00:27:22,806
demo.


892
00:27:23,276 --> 00:27:24,796
So once again, I'm going to do


893
00:27:24,796 --> 00:27:25,746
it like a cooking show, and


894
00:27:25,746 --> 00:27:26,596
we're going to load up one that


895
00:27:26,596 --> 00:27:27,766
we've had in the oven already.


896
00:27:28,526 --> 00:27:29,936
I'm going to say model equals


897
00:27:29,936 --> 00:27:32,426
tc.loadmodel and I'm going to


898
00:27:32,426 --> 00:27:34,576
load up my already trained style


899
00:27:34,576 --> 00:27:35,296
transfer model.


900
00:27:35,826 --> 00:27:38,546
Let's take a look at some of


901
00:27:38,546 --> 00:27:40,026
these style images to see what


902
00:27:40,026 --> 00:27:41,306
we should expect this model to


903
00:27:41,306 --> 00:27:41,876
produce.


904
00:27:42,876 --> 00:27:45,516
We have a style image col-- we


905
00:27:45,516 --> 00:27:46,476
have an image column in our


906
00:27:46,476 --> 00:27:47,336
style SFrame.


907
00:27:47,746 --> 00:27:49,026
And let's take a look at just


908
00:27:49,026 --> 00:27:50,336
style number three and see what


909
00:27:50,336 --> 00:27:50,946
that looks like.


910
00:27:51,796 --> 00:27:53,486
It-- sort of like a pile of


911
00:27:53,486 --> 00:27:54,056
firewood.


912
00:27:54,416 --> 00:27:57,036
And this is pretty stylistic.


913
00:27:57,266 --> 00:27:57,966
I think this would be


914
00:27:57,966 --> 00:27:59,626
recognizable if we were to apply


915
00:27:59,626 --> 00:28:01,326
it as a filter to another image.


916
00:28:02,676 --> 00:28:04,666
Now let's take a look at some


917
00:28:04,666 --> 00:28:05,566
content images.


918
00:28:06,016 --> 00:28:07,616
I'm going to load up a test data


919
00:28:07,616 --> 00:28:07,916
set.


920
00:28:08,126 --> 00:28:10,566
And once again this is a data


921
00:28:10,566 --> 00:28:12,096
set that is representative of


922
00:28:12,156 --> 00:28:13,936
the types of images that users


923
00:28:13,936 --> 00:28:15,136
will have at runtime in your


924
00:28:15,136 --> 00:28:15,326
app.


925
00:28:15,776 --> 00:28:16,906
And the important thing is that


926
00:28:16,906 --> 00:28:18,606
the model never saw these at


927
00:28:18,606 --> 00:28:19,346
training time.


928
00:28:19,656 --> 00:28:21,366
So by evaluating with the test


929
00:28:21,366 --> 00:28:22,836
images, we'll know whether the


930
00:28:22,836 --> 00:28:24,786
model can generalize to users'


931
00:28:24,786 --> 00:28:25,096
data.


932
00:28:26,206 --> 00:28:28,636
I'm going to load up a test data


933
00:28:29,166 --> 00:28:30,496
set now.


934
00:28:30,606 --> 00:28:32,746
With tc.loadimages function once


935
00:28:32,746 --> 00:28:33,086
again.


936
00:28:33,656 --> 00:28:34,906
And we're going to call that


937
00:28:34,906 --> 00:28:36,006
folder test.


938
00:28:37,046 --> 00:28:38,406
And I'm going to pull out one


939
00:28:38,406 --> 00:28:39,696
image from the test data set


940
00:28:39,696 --> 00:28:40,736
called ample image.


941
00:28:41,216 --> 00:28:43,666
And I'm just going to take the


942
00:28:43,666 --> 00:28:44,576
first image there.


943
00:28:45,156 --> 00:28:48,016
And I'm going to call .show.


944
00:28:48,016 --> 00:28:51,446
So that we can we see what that


945
00:28:51,446 --> 00:28:52,526
image looks like without any


946
00:28:52,526 --> 00:28:53,256
filters applied.


947
00:28:54,016 --> 00:28:58,216
That's my cat, seven of nine.


948
00:28:59,046 --> 00:29:02,306
She always looks like that.


949
00:29:02,306 --> 00:29:04,546
And we're going to go ahead and


950
00:29:04,546 --> 00:29:06,096
stylize that image using the


951
00:29:06,096 --> 00:29:07,036
model that we just trained.


952
00:29:08,516 --> 00:29:10,526
So I'm going to say stylized


953
00:29:10,526 --> 00:29:13,236
image equals model.stylize.


954
00:29:13,956 --> 00:29:15,876
And in this case, the function


955
00:29:15,876 --> 00:29:17,486
is called stylize because the


956
00:29:17,486 --> 00:29:19,386
model is specific to the task of


957
00:29:19,386 --> 00:29:20,186
style transfer.


958
00:29:20,416 --> 00:29:22,806
And we're going to pass in that


959
00:29:22,806 --> 00:29:23,606
sample image.


960
00:29:23,956 --> 00:29:25,416
And I'm going to say style


961
00:29:25,416 --> 00:29:27,206
equals three because that's the


962
00:29:27,206 --> 00:29:28,956
style that we picked earlier


963
00:29:28,956 --> 00:29:30,146
that looks like firewood here.


964
00:29:32,116 --> 00:29:33,956
So let's see what that stylized


965
00:29:33,956 --> 00:29:34,656
image looks like.


966
00:29:35,196 --> 00:29:38,646
I can call .show on that, and


967
00:29:38,646 --> 00:29:39,976
here is my cat looking like a


968
00:29:39,976 --> 00:29:40,746
pile of firewood.


969
00:29:41,516 --> 00:29:46,426
[ Applause ]


970
00:29:46,926 --> 00:29:48,376
Let's make sure this works on


971
00:29:48,376 --> 00:29:49,256
other styles, too.


972
00:29:49,946 --> 00:29:52,336
I'm going to go ahead and make a


973
00:29:52,336 --> 00:29:58,496
stylized image out of that


974
00:29:58,496 --> 00:29:59,256
sample image.


975
00:29:59,576 --> 00:30:02,276
And I'm going to specify a style


976
00:30:02,276 --> 00:30:02,966
equals seven.


977
00:30:03,556 --> 00:30:05,986
And then let's see what that


978
00:30:05,986 --> 00:30:07,000
looks like.


979
00:30:13,056 --> 00:30:13,896
That looks pretty good.


980
00:30:13,896 --> 00:30:15,236
I wonder what the style was that


981
00:30:15,236 --> 00:30:16,236
we just applied to that.


982
00:30:16,716 --> 00:30:18,496
Let's take a look at style


983
00:30:20,826 --> 00:30:21,000
images.


984
00:30:25,306 --> 00:30:26,516
Style image seven.


985
00:30:27,046 --> 00:30:30,066
And once again we can just call


986
00:30:30,066 --> 00:30:31,436
.show to see what that style


987
00:30:31,436 --> 00:30:33,496
image looks like and yeah, that


988
00:30:33,496 --> 00:30:34,736
looks like the filter that we


989
00:30:34,736 --> 00:30:35,746
just applied to my cat.


990
00:30:36,426 --> 00:30:38,696
Now that we've got a good style


991
00:30:38,696 --> 00:30:40,886
transfer model, we can just call


992
00:30:41,216 --> 00:30:43,716
model.exportcoreml exactly the


993
00:30:43,716 --> 00:30:45,206
same as any other model, and


994
00:30:45,206 --> 00:30:47,000
save it into Core ML format.


995
00:30:52,296 --> 00:30:54,126
Now, let's switch over to the


996
00:30:54,126 --> 00:30:55,436
iPhone where we have a style


997
00:30:55,436 --> 00:30:57,306
transfer app ready to apply the


998
00:30:57,306 --> 00:30:58,306
filters in this model.


999
00:30:58,886 --> 00:31:03,446
So here I've got my iPhone once


1000
00:31:03,446 --> 00:31:03,726
again.


1001
00:31:03,726 --> 00:31:05,426
And I have an app called style


1002
00:31:05,426 --> 00:31:05,936
transfer.


1003
00:31:06,696 --> 00:31:08,066
I'm going to choose a photo from


1004
00:31:08,066 --> 00:31:09,946
my photo library to apply these


1005
00:31:09,946 --> 00:31:11,256
styles to.


1006
00:31:11,796 --> 00:31:13,846
These are my dogs.


1007
00:31:16,136 --> 00:31:19,696
This is Ryker and we're going to


1008
00:31:19,696 --> 00:31:20,656
see what styles we have


1009
00:31:20,656 --> 00:31:21,696
available in this app.


1010
00:31:22,206 --> 00:31:23,706
We can scroll through all of the


1011
00:31:23,706 --> 00:31:26,126
styles here and what's important


1012
00:31:26,126 --> 00:31:27,766
to note is that a single style


1013
00:31:27,766 --> 00:31:29,596
transfer model was trained on


1014
00:31:29,596 --> 00:31:30,636
all of these files.


1015
00:31:30,976 --> 00:31:32,836
And one model can include any


1016
00:31:32,836 --> 00:31:33,676
number of styles.


1017
00:31:34,126 --> 00:31:35,636
So to have multiple filters, you


1018
00:31:35,636 --> 00:31:37,116
don't need to greatly increase


1019
00:31:37,166 --> 00:31:37,976
the size of your app.


1020
00:31:39,156 --> 00:31:40,376
Let's see what those styles look


1021
00:31:40,376 --> 00:31:43,036
like applied to Ryker.


1022
00:31:43,716 --> 00:31:46,000
Pretty cool.


1023
00:31:52,646 --> 00:31:52,976
So--


1024
00:31:53,516 --> 00:31:58,316
[ Applause ]


1025
00:31:58,816 --> 00:32:01,266
So to recap what we just saw, we


1026
00:32:01,266 --> 00:32:02,886
loaded images into SFrame


1027
00:32:02,886 --> 00:32:03,336
format.


1028
00:32:03,646 --> 00:32:05,576
This time style and content


1029
00:32:05,576 --> 00:32:07,346
images into two SFrames.


1030
00:32:07,836 --> 00:32:09,656
We created a model using a


1031
00:32:09,656 --> 00:32:10,966
high-level API for style


1032
00:32:10,966 --> 00:32:12,816
transfer that operates directly


1033
00:32:12,946 --> 00:32:14,576
on a set of style images and a


1034
00:32:14,576 --> 00:32:15,646
set of content images.


1035
00:32:16,436 --> 00:32:18,956
We then stylize images to check


1036
00:32:19,256 --> 00:32:20,546
whether the model is performing


1037
00:32:20,546 --> 00:32:20,836
well.


1038
00:32:21,356 --> 00:32:22,876
We visualized those predictions


1039
00:32:22,876 --> 00:32:23,706
in Turi Create.


1040
00:32:24,226 --> 00:32:25,686
And finally we exported the


1041
00:32:25,686 --> 00:32:27,566
model in Core ML format for use


1042
00:32:27,566 --> 00:32:29,996
in our app.


1043
00:32:30,636 --> 00:32:31,566
Switching gears a bit.


1044
00:32:31,616 --> 00:32:32,656
I want to talk about some other


1045
00:32:32,656 --> 00:32:34,336
features in Turi Create 5.0.


1046
00:32:35,066 --> 00:32:37,186
We now have Mac GPU acceleration


1047
00:32:37,536 --> 00:32:39,626
offering up to a 12x performance


1048
00:32:39,626 --> 00:32:40,726
increase in image


1049
00:32:40,726 --> 00:32:41,586
classification.


1050
00:32:41,756 --> 00:32:43,966
And 9x in object detection, and


1051
00:32:43,966 --> 00:32:45,226
that's on an iMac Pro.


1052
00:32:46,516 --> 00:32:50,586
[ Applause ]


1053
00:32:51,086 --> 00:32:53,096
We have a new task available for


1054
00:32:53,096 --> 00:32:54,616
export into Core ML format.


1055
00:32:54,876 --> 00:32:55,776
Personalization.


1056
00:32:56,466 --> 00:32:58,096
The task here is to recommend


1057
00:32:58,096 --> 00:33:00,496
items for users based on user's


1058
00:33:00,496 --> 00:33:01,686
historical preferences.


1059
00:33:02,896 --> 00:33:04,636
This type of model is deployed


1060
00:33:04,636 --> 00:33:06,506
using Core ML's new custom model


1061
00:33:06,506 --> 00:33:08,586
support that's available on


1062
00:33:08,586 --> 00:33:11,026
macOS Mojave and on iOS 12.


1063
00:33:11,686 --> 00:33:12,966
This has been a top community


1064
00:33:12,966 --> 00:33:14,576
feature request since we open


1065
00:33:14,576 --> 00:33:15,546
sourced Turi Create.


1066
00:33:15,806 --> 00:33:16,956
So I'm really excited to bring


1067
00:33:16,956 --> 00:33:17,576
it to you today.


1068
00:33:18,516 --> 00:33:23,546
[ Applause ]


1069
00:33:24,046 --> 00:33:25,846
The recommender model in Core ML


1070
00:33:26,076 --> 00:33:27,376
looks just like any other Core


1071
00:33:27,376 --> 00:33:27,956
ML model.


1072
00:33:28,266 --> 00:33:29,656
But what's worth noting is


1073
00:33:29,656 --> 00:33:30,876
there's a section at the bottom


1074
00:33:30,876 --> 00:33:32,496
here called Dependencies.


1075
00:33:33,046 --> 00:33:34,416
And in this section, you can see


1076
00:33:34,416 --> 00:33:36,156
that this model uses a custom


1077
00:33:36,156 --> 00:33:37,986
model and that model is called


1078
00:33:37,986 --> 00:33:39,006
TC recommender.


1079
00:33:39,506 --> 00:33:40,886
And this is just Turi Create


1080
00:33:41,036 --> 00:33:42,056
providing support for


1081
00:33:42,056 --> 00:33:44,206
recommenders in Core ML through


1082
00:33:44,206 --> 00:33:45,346
that custom model API.


1083
00:33:46,016 --> 00:33:49,476
Using that model in Core ML look


1084
00:33:49,536 --> 00:33:50,916
very similar to any other Core


1085
00:33:50,916 --> 00:33:51,776
ML model as well.


1086
00:33:52,316 --> 00:33:53,506
You can just instantiate the


1087
00:33:53,506 --> 00:33:55,696
model, create your input.


1088
00:33:55,776 --> 00:33:57,696
So in this case, we've got that


1089
00:33:57,696 --> 00:33:59,046
avatar creation app.


1090
00:33:59,386 --> 00:34:01,066
And a user might have picked a


1091
00:34:01,066 --> 00:34:02,626
brown beard and a brown


1092
00:34:02,626 --> 00:34:04,276
handlebar moustache and brown


1093
00:34:04,276 --> 00:34:05,966
long hair for their avatar.


1094
00:34:06,346 --> 00:34:07,956
And we can make predictions from


1095
00:34:07,956 --> 00:34:08,426
the model.


1096
00:34:08,626 --> 00:34:10,246
By providing those interactions


1097
00:34:10,246 --> 00:34:10,886
as input.


1098
00:34:11,315 --> 00:34:13,416
And where we say k10 means we'll


1099
00:34:13,416 --> 00:34:14,996
get the top ten predictions


1100
00:34:15,346 --> 00:34:16,426
given those inputs.


1101
00:34:17,045 --> 00:34:20,686
So to recap what we've learned


1102
00:34:20,686 --> 00:34:21,116
today.


1103
00:34:22,286 --> 00:34:24,255
Turi Create allows you to create


1104
00:34:24,255 --> 00:34:26,196
Core ML models to power


1105
00:34:26,196 --> 00:34:27,755
intelligent features in your


1106
00:34:27,985 --> 00:34:28,286
apps.


1107
00:34:28,606 --> 00:34:30,775
It uses a simple five-step


1108
00:34:30,775 --> 00:34:33,235
recipe starting with identifying


1109
00:34:33,235 --> 00:34:34,275
the task that you're doing.


1110
00:34:34,485 --> 00:34:35,735
And mapping it to a machine


1111
00:34:35,735 --> 00:34:36,496
learning task.


1112
00:34:37,025 --> 00:34:39,045
Gathering and annotating data


1113
00:34:39,226 --> 00:34:41,126
for use in training that model.


1114
00:34:42,146 --> 00:34:43,946
Training the model itself using


1115
00:34:43,946 --> 00:34:45,246
a simple, high-level API


1116
00:34:45,755 --> 00:34:47,096
specific to the task that you're


1117
00:34:47,096 --> 00:34:47,505
doing.


1118
00:34:48,466 --> 00:34:50,235
Evaluating that model in Turi


1119
00:34:50,235 --> 00:34:51,996
Create both qualitatively and


1120
00:34:51,996 --> 00:34:52,826
quantitatively.


1121
00:34:53,366 --> 00:34:55,755
And finally, deploying in Core


1122
00:34:55,755 --> 00:34:56,406
ML format.


1123
00:34:58,936 --> 00:35:01,196
That five-step recipe maps to


1124
00:35:01,196 --> 00:35:03,266
code starting with import Turi


1125
00:35:03,266 --> 00:35:03,646
Create.


1126
00:35:04,406 --> 00:35:05,726
You can load data into the


1127
00:35:05,726 --> 00:35:06,526
SFrame format.


1128
00:35:07,026 --> 00:35:08,566
Create a model using that


1129
00:35:08,596 --> 00:35:10,026
task-specific API.


1130
00:35:11,126 --> 00:35:12,726
Evaluate the model with an


1131
00:35:12,726 --> 00:35:14,076
evaluate function that's once


1132
00:35:14,076 --> 00:35:15,576
again specific to the task that


1133
00:35:15,576 --> 00:35:16,086
you're doing.


1134
00:35:16,646 --> 00:35:18,096
And export for deployment,


1135
00:35:18,356 --> 00:35:19,666
calling the export Core ML


1136
00:35:19,666 --> 00:35:20,066
function.


1137
00:35:20,536 --> 00:35:23,576
Turi Create supports a broad


1138
00:35:23,576 --> 00:35:24,736
variety of machine learning


1139
00:35:24,736 --> 00:35:25,296
tasks.


1140
00:35:25,736 --> 00:35:27,196
Ranging from high-level tasks


1141
00:35:27,196 --> 00:35:29,286
like image classification and


1142
00:35:29,286 --> 00:35:31,296
text classification, all the way


1143
00:35:31,296 --> 00:35:32,896
to low-level machine learning


1144
00:35:32,896 --> 00:35:33,436
essentials.


1145
00:35:33,436 --> 00:35:34,186
Like regression and


1146
00:35:34,186 --> 00:35:35,976
classification on any type of


1147
00:35:35,976 --> 00:35:36,246
data.


1148
00:35:38,006 --> 00:35:39,806
And using the resulting models,


1149
00:35:40,106 --> 00:35:41,266
you can power intelligent


1150
00:35:41,266 --> 00:35:42,986
features in your apps like


1151
00:35:42,986 --> 00:35:45,036
object detection or style


1152
00:35:45,036 --> 00:35:47,196
transfer for use as a filter.


1153
00:35:48,216 --> 00:35:50,306
For more information, please see


1154
00:35:50,306 --> 00:35:52,606
the Developer.Apple.com session


1155
00:35:52,806 --> 00:35:53,306
URL.


1156
00:35:53,716 --> 00:35:55,316
And please come to our labs.


1157
00:35:55,316 --> 00:35:56,736
We've got a lab this afternoon


1158
00:35:56,886 --> 00:35:58,056
and Friday afternoon.


1159
00:35:58,306 --> 00:35:59,726
And we welcome your feedback.


1160
00:36:00,096 --> 00:36:01,276
We're happy to answer any


1161
00:36:01,276 --> 00:36:02,126
questions you have.


1162
00:36:02,386 --> 00:36:04,136
And we'll have all of the demos


1163
00:36:04,136 --> 00:36:05,936
we showed today available to


1164
00:36:05,936 --> 00:36:06,376
explore.


1165
00:36:07,186 --> 00:36:07,506
Thank you.


1166
00:36:08,516 --> 00:36:11,500
[ Applause ]

